"""
æ™‚é–“è»¸è‡ªå‹•é›†è¨ˆã‚µãƒ¼ãƒ“ã‚¹

è²¬ä»»:
- 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1æ™‚é–“è¶³ãƒ»4æ™‚é–“è¶³ã¸ã®è‡ªå‹•é›†è¨ˆ
- é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
- é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®é˜²æ­¢
- é›†è¨ˆå“è³ªã®ç›£è¦–

ç‰¹å¾´:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é›†è¨ˆå‡¦ç†
- åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ä¿è¨¼
- è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import pandas as pd

from sqlalchemy.ext.asyncio import AsyncSession

from src.infrastructure.database.models.price_data_model import PriceDataModel
from src.infrastructure.database.repositories.price_data_repository_impl import PriceDataRepositoryImpl

logger = logging.getLogger(__name__)


class TimeframeAggregatorService:
    """
    æ™‚é–“è»¸è‡ªå‹•é›†è¨ˆã‚µãƒ¼ãƒ“ã‚¹

    è²¬ä»»:
    - 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1æ™‚é–“è¶³ãƒ»4æ™‚é–“è¶³ã¸ã®è‡ªå‹•é›†è¨ˆ
    - é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
    - é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®é˜²æ­¢
    - é›†è¨ˆå“è³ªã®ç›£è¦–
    """

    def __init__(self, session: AsyncSession):
        self.session = session
        self.price_repo = PriceDataRepositoryImpl(session)
        self.currency_pair = "USD/JPY"

        # é›†è¨ˆè¨­å®š
        self.aggregation_rules = {
            "1h": {"minutes": 60, "description": "1æ™‚é–“è¶³"},
            "4h": {"minutes": 240, "description": "4æ™‚é–“è¶³"}
        }

        # é›†è¨ˆå“è³ªè¨­å®š
        self.quality_thresholds = {
            "min_data_points": {"1h": 12, "4h": 48},  # 5åˆ†è¶³ã®å¿…è¦ä»¶æ•°
            "max_gap_minutes": {"1h": 15, "4h": 30}   # æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—ï¼ˆåˆ†ï¼‰
        }

    async def aggregate_1h_data(self) -> List[PriceDataModel]:
        """
        5åˆ†è¶³ã‹ã‚‰1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ

        Returns:
            List[PriceDataModel]: é›†è¨ˆã•ã‚ŒãŸ1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info("ğŸ“Š 1æ™‚é–“è¶³é›†è¨ˆé–‹å§‹")

            # éå»1æ™‚é–“ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            end_date = datetime.now()
            start_date = end_date - timedelta(hours=1)

            m5_data = await self.price_repo.find_by_date_range_and_timeframe(
                start_date, end_date, self.currency_pair, "5m", 1000
            )

            if len(m5_data) < self.quality_thresholds["min_data_points"]["1h"]:
                logger.warning(
                    f"1æ™‚é–“è¶³é›†è¨ˆã«å¿…è¦ãª5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {len(m5_data)}/"
                    f"{self.quality_thresholds['min_data_points']['1h']}"
                )
                return []

            # DataFrameã«å¤‰æ›
            df = self._convert_to_dataframe(m5_data)

            # 1æ™‚é–“è¶³ã«é›†è¨ˆ
            h1_df = self._aggregate_timeframe_data(df, "1H")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            saved_data = await self._save_aggregated_data(h1_df, "1h")

            logger.info(f"âœ… 1æ™‚é–“è¶³é›†è¨ˆå®Œäº†: {len(saved_data)}ä»¶")
            return saved_data

        except Exception as e:
            logger.error(f"1æ™‚é–“è¶³é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def aggregate_4h_data(self) -> List[PriceDataModel]:
        """
        5åˆ†è¶³ã‹ã‚‰4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ

        Returns:
            List[PriceDataModel]: é›†è¨ˆã•ã‚ŒãŸ4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info("ğŸ“Š 4æ™‚é–“è¶³é›†è¨ˆé–‹å§‹")

            # éå»4æ™‚é–“ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            end_date = datetime.now()
            start_date = end_date - timedelta(hours=4)

            m5_data = await self.price_repo.find_by_date_range_and_timeframe(
                start_date, end_date, self.currency_pair, "5m", 1000
            )

            if len(m5_data) < self.quality_thresholds["min_data_points"]["4h"]:
                logger.warning(
                    f"4æ™‚é–“è¶³é›†è¨ˆã«å¿…è¦ãª5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {len(m5_data)}/"
                    f"{self.quality_thresholds['min_data_points']['4h']}"
                )
                return []

            # DataFrameã«å¤‰æ›
            df = self._convert_to_dataframe(m5_data)

            # 4æ™‚é–“è¶³ã«é›†è¨ˆ
            h4_df = self._aggregate_timeframe_data(df, "4H")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            saved_data = await self._save_aggregated_data(h4_df, "4h")

            logger.info(f"âœ… 4æ™‚é–“è¶³é›†è¨ˆå®Œäº†: {len(saved_data)}ä»¶")
            return saved_data

        except Exception as e:
            logger.error(f"4æ™‚é–“è¶³é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def aggregate_all_timeframes(self) -> Dict[str, int]:
        """
        å…¨æ™‚é–“è»¸ã®é›†è¨ˆã‚’å®Ÿè¡Œ

        Returns:
            Dict[str, int]: å„æ™‚é–“è»¸ã®é›†è¨ˆä»¶æ•°
        """
        try:
            logger.info("ğŸ”„ å…¨æ™‚é–“è»¸é›†è¨ˆé–‹å§‹")

            results = {}

            # 1æ™‚é–“è¶³é›†è¨ˆ
            h1_data = await self.aggregate_1h_data()
            results["1h"] = len(h1_data)

            # 4æ™‚é–“è¶³é›†è¨ˆ
            h4_data = await self.aggregate_4h_data()
            results["4h"] = len(h4_data)

            total_aggregated = sum(results.values())
            logger.info(f"âœ… å…¨æ™‚é–“è»¸é›†è¨ˆå®Œäº†: {total_aggregated}ä»¶")

            return results

        except Exception as e:
            logger.error(f"å…¨æ™‚é–“è»¸é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"1h": 0, "4h": 0}

    def _convert_to_dataframe(self, price_data_list: List[PriceDataModel]) -> pd.DataFrame:
        """
        ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’DataFrameã«å¤‰æ›

        Args:
            price_data_list: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ

        Returns:
            pd.DataFrame: å¤‰æ›ã•ã‚ŒãŸDataFrame
        """
        try:
            data = []
            for price_data in price_data_list:
                data.append({
                    "timestamp": price_data.timestamp,
                    "open": float(price_data.open_price),
                    "high": float(price_data.high_price),
                    "low": float(price_data.low_price),
                    "close": float(price_data.close_price),
                    "volume": int(price_data.volume)
                })

            df = pd.DataFrame(data)
            df.set_index("timestamp", inplace=True)
            df.sort_index(inplace=True)

            return df

        except Exception as e:
            logger.error(f"DataFrameå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    def _aggregate_timeframe_data(self, df: pd.DataFrame, timeframe: str) -> pd.DataFrame:
        """
        æŒ‡å®šæ™‚é–“è»¸ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ

        Args:
            df: 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®DataFrame
            timeframe: é›†è¨ˆæ™‚é–“è»¸ï¼ˆ1H, 4Hï¼‰

        Returns:
            pd.DataFrame: é›†è¨ˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            if df.empty:
                return df

            # æ™‚é–“è»¸ã§ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            resampled = df.resample(timeframe).agg({
                "open": "first",
                "high": "max",
                "low": "min",
                "close": "last",
                "volume": "sum"
            })

            # NaNå€¤ã‚’å‰Šé™¤
            resampled = resampled.dropna()

            return resampled

        except Exception as e:
            logger.error(f"æ™‚é–“è»¸é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    async def _save_aggregated_data(
        self, 
        df: pd.DataFrame, 
        timeframe: str
    ) -> List[PriceDataModel]:
        """
        é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜

        Args:
            df: é›†è¨ˆã•ã‚ŒãŸDataFrame
            timeframe: æ™‚é–“è»¸ï¼ˆ1h, 4hï¼‰

        Returns:
            List[PriceDataModel]: ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            saved_data = []

            for timestamp, row in df.iterrows():
                price_data = PriceDataModel(
                    currency_pair=self.currency_pair,
                    timestamp=timestamp,
                    open_price=float(row["open"]),
                    high_price=float(row["high"]),
                    low_price=float(row["low"]),
                    close_price=float(row["close"]),
                    volume=int(row["volume"]),
                    data_source=f"Aggregated from 5m to {timeframe}"
                )

                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                existing = await self.price_repo.find_by_timestamp(
                    timestamp, self.currency_pair
                )
                if not existing:
                    saved_data.append(await self.price_repo.save(price_data))

            return saved_data

        except Exception as e:
            logger.error(f"é›†è¨ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def get_aggregation_status(self) -> Dict[str, Any]:
        """
        é›†è¨ˆçŠ¶æ…‹ã‚’å–å¾—

        Returns:
            Dict[str, Any]: é›†è¨ˆçŠ¶æ…‹
        """
        try:
            status = {
                "last_aggregation": {},
                "total_aggregated": 0
            }

            # å„æ™‚é–“è»¸ã®æœ€æ–°é›†è¨ˆçŠ¶æ³ã‚’ç¢ºèª
            for timeframe in ["1h", "4h"]:
                # æœ€æ–°ã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                latest_data = await self.price_repo.find_latest(
                    self.currency_pair, 1
                )

                if latest_data:
                    status["last_aggregation"][timeframe] = {
                        "timestamp": latest_data[0].timestamp,
                        "data_source": latest_data[0].data_source
                    }

            # ç·é›†è¨ˆä»¶æ•°ã‚’è¨ˆç®—
            total_count = await self.price_repo.count_by_date_range(
                datetime.now() - timedelta(days=7),
                datetime.now(),
                self.currency_pair
            )
            status["total_aggregated"] = total_count

            return status

        except Exception as e:
            logger.error(f"é›†è¨ˆçŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
