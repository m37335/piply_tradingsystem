#!/usr/bin/env python3
"""
å …ç‰¢ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚µãƒ¼ãƒ“ã‚¹
ãƒ‡ãƒ¼ã‚¿æ¬ æã‚’è€ƒæ…®ã—ãŸå¤šå±¤è£œå®Œæˆ¦ç•¥
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import pandas as pd
from sqlalchemy.ext.asyncio import AsyncSession

from ...external_apis.yahoo_finance_client import YahooFinanceClient
from ...database.models.price_data_model import PriceDataModel
from ...database.repositories.price_data_repository_impl import PriceDataRepositoryImpl
from ...database.services.timeframe_aggregator_service import TimeframeAggregatorService
from ...utils.logging_config import get_infrastructure_logger

logger = get_infrastructure_logger()


class RobustHybridDataFetcherService:
    """
    å …ç‰¢ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚µãƒ¼ãƒ“ã‚¹
    
    è²¬ä»»:
    - å¤šå±¤ã®ãƒ‡ãƒ¼ã‚¿å–å¾—æˆ¦ç•¥
    - æ¬ æãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•è£œå®Œ
    - ä»£æ›¿é›†è¨ˆå…ƒã®æ´»ç”¨
    """

    def __init__(self, session: AsyncSession, currency_pair: str = "USD/JPY"):
        self.session = session
        self.currency_pair = currency_pair
        self.yahoo_client = YahooFinanceClient()
        self.price_repo = PriceDataRepositoryImpl(session)
        self.aggregator = TimeframeAggregatorService(session, currency_pair)

        # æ™‚é–“è¶³è¨­å®šï¼ˆå……è¶³ç‡ã«åŸºã¥ãå„ªå…ˆé †ä½ï¼‰
        self.timeframes = {
            "4h": {"period": "60d", "interval": "4h", "description": "4æ™‚é–“è¶³", "priority": 1},
            "1d": {"period": "365d", "interval": "1d", "description": "æ—¥è¶³", "priority": 2},
            "1h": {"period": "30d", "interval": "1h", "description": "1æ™‚é–“è¶³", "priority": 3},
            "5m": {"period": "7d", "interval": "5m", "description": "5åˆ†è¶³", "priority": 4},
        }

        # å¤šå±¤è£œå®Œæˆ¦ç•¥
        self.completion_strategy = {
            "4h": {
                "primary": "direct",  # ç›´æ¥å–å¾—å„ªå…ˆï¼ˆå……è¶³ç‡99.4%ï¼‰
                "fallback": ["from_1h", "from_5m"],  # 1æ™‚é–“è¶³â†’5åˆ†è¶³ã®é †ã§è£œå®Œ
                "min_data_points": {"from_1h": 4, "from_5m": 48}
            },
            "1d": {
                "primary": "direct",  # ç›´æ¥å–å¾—å„ªå…ˆï¼ˆå……è¶³ç‡99.2%ï¼‰
                "fallback": ["from_4h", "from_1h", "from_5m"],  # 4æ™‚é–“è¶³â†’1æ™‚é–“è¶³â†’5åˆ†è¶³ã®é †ã§è£œå®Œ
                "min_data_points": {"from_4h": 6, "from_1h": 24, "from_5m": 288}
            },
            "1h": {
                "primary": "direct",  # ç›´æ¥å–å¾—å„ªå…ˆï¼ˆå……è¶³ç‡96.8%ï¼‰
                "fallback": ["from_5m"],  # 5åˆ†è¶³ã§è£œå®Œ
                "min_data_points": {"from_5m": 12}
            },
            "5m": {
                "primary": "direct",  # ç›´æ¥å–å¾—ã®ã¿ï¼ˆå……è¶³ç‡91.7%ã ãŒä»–ã‹ã‚‰é›†è¨ˆä¸å¯ï¼‰
                "fallback": [],
                "min_data_points": {}
            }
        }

        logger.info(f"Initialized RobustHybridDataFetcherService for {currency_pair}")

    async def fetch_all_timeframes_robust(self) -> Dict[str, Dict]:
        """
        å …ç‰¢ãªæ–¹å¼ã§å…¨æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—
        
        Returns:
            Dict[str, Dict]: å„æ™‚é–“è¶³ã®å–å¾—çµæœè©³ç´°
        """
        results = {}
        
        try:
            logger.info("ğŸš€ å …ç‰¢ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼ã§å…¨æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            
            # å„ªå…ˆé †ä½é †ã«å‡¦ç†
            sorted_timeframes = sorted(
                self.timeframes.items(), 
                key=lambda x: x[1]["priority"]
            )
            
            for timeframe, config in sorted_timeframes:
                logger.info(f"ğŸ“Š {timeframe}æ™‚é–“è¶³å‡¦ç†é–‹å§‹ï¼ˆå„ªå…ˆåº¦: {config['priority']}ï¼‰")
                
                result = await self._fetch_timeframe_robust(timeframe)
                results[timeframe] = result
                
                logger.info(f"âœ… {timeframe}å‡¦ç†å®Œäº†: {result['total_count']}ä»¶")
            
            logger.info(f"ğŸ‰ å …ç‰¢ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å–å¾—å®Œäº†")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å …ç‰¢ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return results

    async def _fetch_timeframe_robust(self, timeframe: str) -> Dict:
        """
        ç‰¹å®šæ™‚é–“è¶³ã‚’å …ç‰¢ãªæ–¹å¼ã§å–å¾—
        
        Args:
            timeframe: æ™‚é–“è¶³
            
        Returns:
            Dict: å–å¾—çµæœè©³ç´°
        """
        result = {
            "timeframe": timeframe,
            "direct_count": 0,
            "fallback_counts": {},
            "total_count": 0,
            "strategy_used": [],
            "errors": []
        }
        
        try:
            strategy = self.completion_strategy[timeframe]
            
            # 1. ãƒ—ãƒ©ã‚¤ãƒãƒªæˆ¦ç•¥ï¼ˆç›´æ¥å–å¾—ï¼‰
            if strategy["primary"] == "direct":
                direct_count = await self._fetch_direct_timeframe(timeframe)
                result["direct_count"] = direct_count
                result["strategy_used"].append("direct")
                
                if direct_count > 0:
                    logger.info(f"   âœ… {timeframe}ç›´æ¥å–å¾—æˆåŠŸ: {direct_count}ä»¶")
                else:
                    logger.warning(f"   âš ï¸ {timeframe}ç›´æ¥å–å¾—å¤±æ•—")
            
            # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
            for fallback_method in strategy["fallback"]:
                try:
                    fallback_count = await self._execute_fallback_strategy(
                        timeframe, fallback_method, strategy["min_data_points"]
                    )
                    
                    if fallback_count > 0:
                        result["fallback_counts"][fallback_method] = fallback_count
                        result["strategy_used"].append(fallback_method)
                        logger.info(f"   ğŸ”§ {timeframe}{fallback_method}è£œå®ŒæˆåŠŸ: {fallback_count}ä»¶")
                    else:
                        logger.warning(f"   âš ï¸ {timeframe}{fallback_method}è£œå®Œå¤±æ•—")
                        
                except Exception as e:
                    error_msg = f"{fallback_method}è£œå®Œã‚¨ãƒ©ãƒ¼: {str(e)}"
                    result["errors"].append(error_msg)
                    logger.error(f"   âŒ {timeframe}{error_msg}")
            
            # 3. åˆè¨ˆè¨ˆç®—
            result["total_count"] = (
                result["direct_count"] + 
                sum(result["fallback_counts"].values())
            )
            
            return result
            
        except Exception as e:
            error_msg = f"å …ç‰¢å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            result["errors"].append(error_msg)
            logger.error(f"âŒ {timeframe}{error_msg}")
            return result

    async def _execute_fallback_strategy(
        self, 
        target_timeframe: str, 
        method: str, 
        min_data_points: Dict[str, int]
    ) -> int:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã‚’å®Ÿè¡Œ
        
        Args:
            target_timeframe: å¯¾è±¡æ™‚é–“è¶³
            method: è£œå®Œæ–¹æ³•
            min_data_points: æœ€å°ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆè¦ä»¶
            
        Returns:
            int: è£œå®Œä»¶æ•°
        """
        try:
            if method == "from_5m":
                return await self._aggregate_from_5m(target_timeframe, min_data_points.get("from_5m", 0))
            elif method == "from_1h":
                return await self._aggregate_from_1h(target_timeframe, min_data_points.get("from_1h", 0))
            elif method == "from_4h":
                return await self._aggregate_from_4h(target_timeframe, min_data_points.get("from_4h", 0))
            else:
                logger.warning(f"âš ï¸ æœªå¯¾å¿œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹æ³•: {method}")
                return 0
                
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def _aggregate_from_5m(self, target_timeframe: str, min_points: int) -> int:
        """5åˆ†è¶³ã‹ã‚‰é›†è¨ˆ"""
        try:
            # 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            m5_data = await self.price_repo.find_by_date_range_and_timeframe(
                datetime.now() - timedelta(days=7),
                datetime.now(),
                self.currency_pair,
                "5m",
                1000
            )
            
            if len(m5_data) < min_points:
                logger.warning(f"âš ï¸ {target_timeframe}é›†è¨ˆç”¨5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(m5_data)}ä»¶ < {min_points}ä»¶")
                return 0
            
            # é›†è¨ˆå®Ÿè¡Œ
            if target_timeframe == "1h":
                aggregated_data = await self.aggregator.aggregate_1h_data(m5_data)
            elif target_timeframe == "4h":
                aggregated_data = await self.aggregator.aggregate_4h_data(m5_data)
            elif target_timeframe == "1d":
                aggregated_data = await self.aggregator.aggregate_1d_data(m5_data)
            else:
                return 0
            
            return await self._save_aggregated_data(aggregated_data, target_timeframe, "from_5m")
            
        except Exception as e:
            logger.error(f"âŒ 5åˆ†è¶³ã‹ã‚‰ã®é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def _aggregate_from_1h(self, target_timeframe: str, min_points: int) -> int:
        """1æ™‚é–“è¶³ã‹ã‚‰é›†è¨ˆ"""
        try:
            # 1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            h1_data = await self.price_repo.find_by_date_range_and_timeframe(
                datetime.now() - timedelta(days=30),
                datetime.now(),
                self.currency_pair,
                "1h",
                1000
            )
            
            if len(h1_data) < min_points:
                logger.warning(f"âš ï¸ {target_timeframe}é›†è¨ˆç”¨1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(h1_data)}ä»¶ < {min_points}ä»¶")
                return 0
            
            # 4æ™‚é–“è¶³ã¸ã®é›†è¨ˆã®ã¿å¯¾å¿œ
            if target_timeframe == "4h":
                aggregated_data = await self._aggregate_1h_to_4h(h1_data)
                return await self._save_aggregated_data(aggregated_data, target_timeframe, "from_1h")
            
            return 0
            
        except Exception as e:
            logger.error(f"âŒ 1æ™‚é–“è¶³ã‹ã‚‰ã®é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def _aggregate_from_4h(self, target_timeframe: str, min_points: int) -> int:
        """4æ™‚é–“è¶³ã‹ã‚‰é›†è¨ˆ"""
        try:
            # 4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            h4_data = await self.price_repo.find_by_date_range_and_timeframe(
                datetime.now() - timedelta(days=60),
                datetime.now(),
                self.currency_pair,
                "4h",
                1000
            )
            
            if len(h4_data) < min_points:
                logger.warning(f"âš ï¸ {target_timeframe}é›†è¨ˆç”¨4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(h4_data)}ä»¶ < {min_points}ä»¶")
                return 0
            
            # æ—¥è¶³ã¸ã®é›†è¨ˆã®ã¿å¯¾å¿œ
            if target_timeframe == "1d":
                aggregated_data = await self._aggregate_4h_to_1d(h4_data)
                return await self._save_aggregated_data(aggregated_data, target_timeframe, "from_4h")
            
            return 0
            
        except Exception as e:
            logger.error(f"âŒ 4æ™‚é–“è¶³ã‹ã‚‰ã®é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def _aggregate_1h_to_4h(self, h1_data: List[PriceDataModel]) -> List[PriceDataModel]:
        """1æ™‚é–“è¶³ã‹ã‚‰4æ™‚é–“è¶³ã¸ã®é›†è¨ˆ"""
        # å®Ÿè£…ã¯ç°¡ç•¥åŒ–ï¼ˆå®Ÿéš›ã¯TimeframeAggregatorServiceã«è¿½åŠ ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
        return []

    async def _aggregate_4h_to_1d(self, h4_data: List[PriceDataModel]) -> List[PriceDataModel]:
        """4æ™‚é–“è¶³ã‹ã‚‰æ—¥è¶³ã¸ã®é›†è¨ˆ"""
        # å®Ÿè£…ã¯ç°¡ç•¥åŒ–ï¼ˆå®Ÿéš›ã¯TimeframeAggregatorServiceã«è¿½åŠ ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
        return []

    async def _save_aggregated_data(
        self, 
        aggregated_data: List[PriceDataModel], 
        timeframe: str, 
        source_method: str
    ) -> int:
        """é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        if not aggregated_data:
            return 0
        
        saved_count = 0
        for data in aggregated_data:
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ›´æ–°
            data.data_source = f"Yahoo Finance ({timeframe.upper()}) Aggregated ({source_method})"
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            existing = await self.price_repo.find_by_timestamp_and_source(
                data.timestamp,
                self.currency_pair,
                data.data_source
            )
            
            if not existing:
                await self.price_repo.save(data)
                saved_count += 1
        
        return saved_count

    async def _fetch_direct_timeframe(self, timeframe: str) -> int:
        """æ™‚é–“è¶³ã‚’ç›´æ¥å–å¾—"""
        try:
            config = self.timeframes[timeframe]
            
            data = await self.yahoo_client.get_historical_data(
                self.currency_pair,
                period=config["period"],
                interval=config["interval"]
            )
            
            if data is None or data.empty:
                return 0
            
            saved_count = 0
            for _, row in data.iterrows():
                price_data = self._create_price_data_model(row, timeframe, "direct")
                
                existing = await self.price_repo.find_by_timestamp_and_source(
                    price_data.timestamp,
                    self.currency_pair,
                    price_data.data_source
                )
                
                if not existing:
                    await self.price_repo.save(price_data)
                    saved_count += 1
            
            return saved_count
            
        except Exception as e:
            logger.error(f"âŒ {timeframe}ç›´æ¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def _create_price_data_model(
        self, row: pd.Series, timeframe: str, source_type: str
    ) -> PriceDataModel:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        return PriceDataModel(
            currency_pair=self.currency_pair,
            timestamp=row.name,
            open_price=row["Open"],
            high_price=row["High"],
            low_price=row["Low"],
            close_price=row["Close"],
            volume=row.get("Volume", 1000000),
            data_source=f"Yahoo Finance ({timeframe.upper()}) {source_type.title()}",
            data_timestamp=row.name,
            fetched_at=datetime.now(),
        )
