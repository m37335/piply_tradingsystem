# æ™‚é–“è¶³é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ä»•æ§˜æ›¸

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: Exchange Analytics System - æ™‚é–“è¶³é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ä»•æ§˜æ›¸  
**ä½œæˆæ—¥**: 2025 å¹´ 8 æœˆ 15 æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**ç›®çš„**: è¨­è¨ˆæ›¸ã«åŸºã¥ãå…·ä½“çš„ãªå®Ÿè£…ä»•æ§˜ã®å®šç¾©

---

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ä¾å­˜é–¢ä¿‚å›³

```
hourly_aggregator.py
â”œâ”€â”€ src/infrastructure/database/
â”‚   â”œâ”€â”€ connection.py (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š)
â”‚   â”œâ”€â”€ models/price_data_model.py (ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«)
â”‚   â””â”€â”€ repositories/price_data_repository_impl.py (ãƒªãƒã‚¸ãƒˆãƒª)
â”œâ”€â”€ src/infrastructure/external_apis/
â”‚   â””â”€â”€ yahoo_finance_client.py (å¤–éƒ¨API)
â””â”€â”€ src/utils/
    â””â”€â”€ logging_config.py (ãƒ­ã‚°è¨­å®š)

four_hour_aggregator.py
â””â”€â”€ (åŒä¸Šã®ä¾å­˜é–¢ä¿‚)

daily_aggregator.py
â””â”€â”€ (åŒä¸Šã®ä¾å­˜é–¢ä¿‚)
```

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
/app/
â”œâ”€â”€ scripts/cron/
â”‚   â”œâ”€â”€ hourly_aggregator.py (æ–°è¦)
â”‚   â”œâ”€â”€ four_hour_aggregator.py (æ–°è¦)
â”‚   â”œâ”€â”€ daily_aggregator.py (æ–°è¦)
â”‚   â””â”€â”€ simple_data_fetcher.py (æ—¢å­˜ãƒ»å‚è€ƒ)
â”œâ”€â”€ src/infrastructure/database/
â”‚   â”œâ”€â”€ connection.py (æ—¢å­˜)
â”‚   â”œâ”€â”€ models/price_data_model.py (æ—¢å­˜)
â”‚   â””â”€â”€ repositories/price_data_repository_impl.py (æ—¢å­˜)
â”œâ”€â”€ src/infrastructure/external_apis/
â”‚   â””â”€â”€ yahoo_finance_client.py (æ—¢å­˜)
â”œâ”€â”€ src/utils/
â”‚   â””â”€â”€ logging_config.py (æ—¢å­˜)
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ hourly_aggregator.log (æ–°è¦)
â”‚   â”œâ”€â”€ four_hour_aggregator.log (æ–°è¦)
â”‚   â””â”€â”€ daily_aggregator.log (æ–°è¦)
â””â”€â”€ current_crontab.txt (æ›´æ–°)
```

---

## ğŸ“Š ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

### BaseAggregator (åŸºåº•ã‚¯ãƒ©ã‚¹)

```python
class BaseAggregator:
    """
    æ™‚é–“è¶³é›†è¨ˆã®åŸºåº•ã‚¯ãƒ©ã‚¹

    è²¬ä»»:
    - å…±é€šã®é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç®¡ç†
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - ãƒ­ã‚°å‡ºåŠ›
    """

    def __init__(self, timeframe: str, data_source: str):
        self.timeframe = timeframe  # "1h", "4h", "1d"
        self.data_source = data_source  # "yahoo_finance_1h_aggregated"
        self.currency_pair = "USD/JPY"
        self.db_url = None
        self.engine = None
        self.session_factory = None
        self.session = None
        self.price_repo = None

    async def initialize_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆæœŸåŒ–"""

    async def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""

    async def aggregate_and_save(self):
        """é›†è¨ˆã¨ä¿å­˜ã‚’å®Ÿè¡Œï¼ˆæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        raise NotImplementedError

    async def get_aggregation_period(self) -> tuple[datetime, datetime]:
        """é›†è¨ˆæœŸé–“ã‚’å–å¾—ï¼ˆæŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        raise NotImplementedError
```

### HourlyAggregator (1 æ™‚é–“è¶³é›†è¨ˆ)

```python
class HourlyAggregator(BaseAggregator):
    """
    1æ™‚é–“è¶³é›†è¨ˆã‚¯ãƒ©ã‚¹

    è²¬ä»»:
    - 1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
    - å‰1æ™‚é–“ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰OHLCVè¨ˆç®—
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
    """

    def __init__(self):
        super().__init__("1h", "yahoo_finance_1h_aggregated")

    async def get_aggregation_period(self) -> tuple[datetime, datetime]:
        """
        é›†è¨ˆæœŸé–“ã‚’å–å¾—

        Returns:
            tuple: (start_time, end_time) å‰1æ™‚é–“ã®æœŸé–“
        """
        # ç¾åœ¨æ™‚åˆ»ã‹ã‚‰1æ™‚é–“å‰ã‚’è¨ˆç®—
        # ä¾‹: 01:05å®Ÿè¡Œæ™‚ â†’ 00:00-00:55ã®æœŸé–“

    async def aggregate_and_save(self):
        """
        1æ™‚é–“è¶³é›†è¨ˆã¨ä¿å­˜ã‚’å®Ÿè¡Œ

        Workflow:
        1. é›†è¨ˆæœŸé–“ã®æ±ºå®š
        2. 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        3. OHLCVè¨ˆç®—
        4. é‡è¤‡ãƒã‚§ãƒƒã‚¯
        5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        """
```

### FourHourAggregator (4 æ™‚é–“è¶³é›†è¨ˆ)

```python
class FourHourAggregator(BaseAggregator):
    """
    4æ™‚é–“è¶³é›†è¨ˆã‚¯ãƒ©ã‚¹

    è²¬ä»»:
    - 4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
    - å‰4æ™‚é–“ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰OHLCVè¨ˆç®—
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
    """

    def __init__(self):
        super().__init__("4h", "yahoo_finance_4h_aggregated")

    async def get_aggregation_period(self) -> tuple[datetime, datetime]:
        """
        é›†è¨ˆæœŸé–“ã‚’å–å¾—

        Returns:
            tuple: (start_time, end_time) å‰4æ™‚é–“ã®æœŸé–“
        """
        # 4æ™‚é–“å˜ä½ã§ã®æœŸé–“è¨ˆç®—
        # ä¾‹: 04:05å®Ÿè¡Œæ™‚ â†’ 00:00-03:55ã®æœŸé–“
```

### DailyAggregator (æ—¥è¶³é›†è¨ˆ)

```python
class DailyAggregator(BaseAggregator):
    """
    æ—¥è¶³é›†è¨ˆã‚¯ãƒ©ã‚¹

    è²¬ä»»:
    - æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
    - å‰æ—¥ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰OHLCVè¨ˆç®—
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
    """

    def __init__(self):
        super().__init__("1d", "yahoo_finance_1d_aggregated")

    async def get_aggregation_period(self) -> tuple[datetime, datetime]:
        """
        é›†è¨ˆæœŸé–“ã‚’å–å¾—

        Returns:
            tuple: (start_time, end_time) å‰æ—¥ã®æœŸé–“
        """
        # å‰æ—¥ã®æœŸé–“è¨ˆç®—
        # ä¾‹: 00:05å®Ÿè¡Œæ™‚ â†’ å‰æ—¥00:00-23:55ã®æœŸé–“
```

---

## ğŸ”„ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è©³ç´°

### 1 æ™‚é–“è¶³é›†è¨ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
async def hourly_aggregation_workflow():
    """
    1æ™‚é–“è¶³é›†è¨ˆã®å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

    Steps:
    1. åˆæœŸåŒ–
    2. é›†è¨ˆæœŸé–“æ±ºå®š
    3. ãƒ‡ãƒ¼ã‚¿å–å¾—
    4. é›†è¨ˆè¨ˆç®—
    5. é‡è¤‡ãƒã‚§ãƒƒã‚¯
    6. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    7. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    """

    # Step 1: åˆæœŸåŒ–
    aggregator = HourlyAggregator()
    await aggregator.initialize_database()

    try:
        # Step 2: é›†è¨ˆæœŸé–“æ±ºå®š
        start_time, end_time = await aggregator.get_aggregation_period()
        logger.info(f"é›†è¨ˆæœŸé–“: {start_time} - {end_time}")

        # Step 3: ãƒ‡ãƒ¼ã‚¿å–å¾—
        five_min_data = await aggregator.get_five_min_data(start_time, end_time)
        if not five_min_data:
            logger.warning("é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        # Step 4: é›†è¨ˆè¨ˆç®—
        aggregated_data = await aggregator.calculate_ohlcv(five_min_data)

        # Step 5: é‡è¤‡ãƒã‚§ãƒƒã‚¯
        existing = await aggregator.check_duplicate(aggregated_data.timestamp)
        if existing:
            logger.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return

        # Step 6: ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        await aggregator.save_aggregated_data(aggregated_data)
        logger.info(f"1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {aggregated_data.timestamp}")

    except Exception as e:
        logger.error(f"é›†è¨ˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise
    finally:
        # Step 7: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await aggregator.cleanup()
```

### é›†è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯

```python
async def calculate_ohlcv(self, five_min_data: List[PriceDataModel]) -> PriceDataModel:
    """
    OHLCVè¨ˆç®—

    Args:
        five_min_data: 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

    Returns:
        PriceDataModel: é›†è¨ˆã•ã‚ŒãŸOHLCVãƒ‡ãƒ¼ã‚¿
    """

    if not five_min_data:
        raise ValueError("é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_data = sorted(five_min_data, key=lambda x: x.timestamp)

    # OHLCVè¨ˆç®—
    open_price = sorted_data[0].open_price  # æœ€åˆã®å§‹å€¤
    high_price = max(d.high_price for d in sorted_data)  # æœ€é«˜å€¤
    low_price = min(d.low_price for d in sorted_data)    # æœ€ä½å€¤
    close_price = sorted_data[-1].close_price  # æœ€å¾Œã®çµ‚å€¤
    volume = sum(d.volume or 0 for d in sorted_data)     # å–å¼•é‡åˆè¨ˆ

    # é›†è¨ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆæœŸé–“ã®é–‹å§‹æ™‚åˆ»ï¼‰
    aggregated_timestamp = sorted_data[0].timestamp.replace(
        minute=0, second=0, microsecond=0
    )

    return PriceDataModel(
        currency_pair=self.currency_pair,
        timestamp=aggregated_timestamp,
        data_timestamp=aggregated_timestamp,
        fetched_at=datetime.now(pytz.timezone("Asia/Tokyo")),
        open_price=open_price,
        high_price=high_price,
        low_price=low_price,
        close_price=close_price,
        volume=volume,
        data_source=self.data_source
    )
```

---

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ä»•æ§˜

### ä¿å­˜ãƒ‡ãƒ¼ã‚¿ä»•æ§˜

```python
# 1æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¾‹
{
    "id": è‡ªå‹•æ¡ç•ª,
    "currency_pair": "USD/JPY",
    "timestamp": "2025-08-15 00:00:00+09:00",  # 1æ™‚é–“ã®é–‹å§‹æ™‚åˆ»
    "data_timestamp": "2025-08-15 00:00:00+09:00",
    "fetched_at": "2025-08-15 01:05:30+09:00",  # é›†è¨ˆå®Ÿè¡Œæ™‚åˆ»
    "open_price": 146.92500,  # 00:00ã®å§‹å€¤
    "high_price": 146.97000,  # æœŸé–“å†…æœ€é«˜å€¤
    "low_price": 146.92200,   # æœŸé–“å†…æœ€ä½å€¤
    "close_price": 146.94099, # 00:55ã®çµ‚å€¤
    "volume": 0,              # æœŸé–“å†…å–å¼•é‡åˆè¨ˆ
    "data_source": "yahoo_finance_1h_aggregated",
    "created_at": "2025-08-15 01:05:30+09:00",
    "updated_at": "2025-08-15 01:05:30+09:00",
    "version": 1
}
```

### é‡è¤‡å›é¿ãƒ­ã‚¸ãƒƒã‚¯

```python
async def check_duplicate(self, timestamp: datetime) -> Optional[PriceDataModel]:
    """
    é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯

    Args:
        timestamp: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—

    Returns:
        Optional[PriceDataModel]: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    """
    try:
        existing = await self.price_repo.find_by_timestamp_and_source(
            timestamp, self.currency_pair, self.data_source
        )
        return existing
    except Exception as e:
        logger.error(f"é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return None
```

### ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯

```python
async def save_aggregated_data(self, aggregated_data: PriceDataModel):
    """
    é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜

    Args:
        aggregated_data: ä¿å­˜ã™ã‚‹é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    """
    try:
        # ãƒªãƒã‚¸ãƒˆãƒªã®saveãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯å«ã‚€ï¼‰
        saved_data = await self.price_repo.save(aggregated_data)
        logger.info(f"é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {saved_data.timestamp}")
        return saved_data
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        raise
```

---

## ğŸ“Š é›†è¨ˆæœŸé–“è¨ˆç®—ä»•æ§˜

### 1 æ™‚é–“è¶³é›†è¨ˆæœŸé–“

```python
def calculate_hourly_period(self) -> tuple[datetime, datetime]:
    """
    1æ™‚é–“è¶³é›†è¨ˆæœŸé–“ã‚’è¨ˆç®—

    Returns:
        tuple: (start_time, end_time)
    """
    # ç¾åœ¨æ™‚åˆ»ã‹ã‚‰1æ™‚é–“å‰ã®æœŸé–“ã‚’è¨ˆç®—
    now = datetime.now(pytz.timezone("Asia/Tokyo"))

    # å‰1æ™‚é–“ã®é–‹å§‹æ™‚åˆ»ï¼ˆ00åˆ†ã«ä¸¸ã‚ã‚‹ï¼‰
    start_time = now.replace(minute=0, second=0, microsecond=0) - timedelta(hours=1)

    # å‰1æ™‚é–“ã®çµ‚äº†æ™‚åˆ»ï¼ˆ55åˆ†ã¾ã§ï¼‰
    end_time = start_time + timedelta(hours=1) - timedelta(minutes=5)

    return start_time, end_time
```

### 4 æ™‚é–“è¶³é›†è¨ˆæœŸé–“

```python
def calculate_four_hour_period(self) -> tuple[datetime, datetime]:
    """
    4æ™‚é–“è¶³é›†è¨ˆæœŸé–“ã‚’è¨ˆç®—

    Returns:
        tuple: (start_time, end_time)
    """
    now = datetime.now(pytz.timezone("Asia/Tokyo"))

    # 4æ™‚é–“å˜ä½ã§ã®é–‹å§‹æ™‚åˆ»ã‚’è¨ˆç®—
    hour = (now.hour // 4) * 4
    start_time = now.replace(hour=hour, minute=0, second=0, microsecond=0) - timedelta(hours=4)

    # 4æ™‚é–“å¾Œã®çµ‚äº†æ™‚åˆ»ï¼ˆ55åˆ†ã¾ã§ï¼‰
    end_time = start_time + timedelta(hours=4) - timedelta(minutes=5)

    return start_time, end_time
```

### æ—¥è¶³é›†è¨ˆæœŸé–“

```python
def calculate_daily_period(self) -> tuple[datetime, datetime]:
    """
    æ—¥è¶³é›†è¨ˆæœŸé–“ã‚’è¨ˆç®—

    Returns:
        tuple: (start_time, end_time)
    """
    now = datetime.now(pytz.timezone("Asia/Tokyo"))

    # å‰æ—¥ã®é–‹å§‹æ™‚åˆ»
    start_time = (now - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

    # å‰æ—¥ã®çµ‚äº†æ™‚åˆ»ï¼ˆ23:55ã¾ã§ï¼‰
    end_time = start_time + timedelta(days=1) - timedelta(minutes=5)

    return start_time, end_time
```

---

## ğŸ”§ å®Ÿè£…è©³ç´°

### ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ§‹é€ 

```python
#!/usr/bin/env python3
"""
Hourly Aggregator - 1æ™‚é–“è¶³é›†è¨ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è²¬ä»»:
- 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1æ™‚é–“è¶³ã‚’é›†è¨ˆ
- PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°å‡ºåŠ›
"""

import asyncio
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
import pytz

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.infrastructure.database.models.price_data_model import PriceDataModel
from src.infrastructure.database.repositories.price_data_repository_impl import PriceDataRepositoryImpl

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("/app/logs/hourly_aggregator.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        aggregator = HourlyAggregator()
        await aggregator.aggregate_and_save()
        logger.info("1æ™‚é–“è¶³é›†è¨ˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"1æ™‚é–“è¶³é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»•æ§˜

```python
class AggregationError(Exception):
    """é›†è¨ˆå‡¦ç†ã‚¨ãƒ©ãƒ¼"""
    pass

class InsufficientDataError(AggregationError):
    """ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã‚¨ãƒ©ãƒ¼"""
    pass

class DatabaseError(AggregationError):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"""
    pass

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä¾‹
try:
    await aggregator.aggregate_and_save()
except InsufficientDataError:
    logger.warning("é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
    # æ­£å¸¸çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ï¼‰
except DatabaseError:
    logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    sys.exit(1)
except Exception as e:
    logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)
```

---

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä»•æ§˜

### å‡¦ç†æ™‚é–“ç›®æ¨™

- **ãƒ‡ãƒ¼ã‚¿å–å¾—**: 5 ç§’ä»¥å†…
- **é›†è¨ˆè¨ˆç®—**: 3 ç§’ä»¥å†…
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜**: 2 ç§’ä»¥å†…
- **åˆè¨ˆå‡¦ç†æ™‚é–“**: 10 ç§’ä»¥å†…

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›®æ¨™

- **ãƒ‡ãƒ¼ã‚¿å–å¾—**: 20MB ä»¥å†…
- **é›†è¨ˆå‡¦ç†**: 10MB ä»¥å†…
- **åˆè¨ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 50MB ä»¥å†…

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†é‡

- **1 æ™‚é–“è¶³**: 12 ä»¶ã® 5 åˆ†è¶³ â†’ 1 ä»¶ã® 1 æ™‚é–“è¶³
- **4 æ™‚é–“è¶³**: 48 ä»¶ã® 5 åˆ†è¶³ â†’ 1 ä»¶ã® 4 æ™‚é–“è¶³
- **æ—¥è¶³**: 288 ä»¶ã® 5 åˆ†è¶³ â†’ 1 ä»¶ã®æ—¥è¶³

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆä»•æ§˜

### å˜ä½“ãƒ†ã‚¹ãƒˆ

```python
class TestHourlyAggregator:
    """1æ™‚é–“è¶³é›†è¨ˆã®ãƒ†ã‚¹ãƒˆ"""

    async def test_calculate_ohlcv(self):
        """OHLCVè¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""

    async def test_get_aggregation_period(self):
        """é›†è¨ˆæœŸé–“è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""

    async def test_check_duplicate(self):
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ"""

    async def test_save_aggregated_data(self):
        """ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã®ãƒ†ã‚¹ãƒˆ"""
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```python
class TestHourlyAggregationIntegration:
    """1æ™‚é–“è¶³é›†è¨ˆã®çµ±åˆãƒ†ã‚¹ãƒˆ"""

    async def test_full_workflow(self):
        """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""

    async def test_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""

    async def test_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
```

---

## ğŸ“‹ å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: 1 æ™‚é–“è¶³é›†è¨ˆ

- [ ] `BaseAggregator`ã‚¯ãƒ©ã‚¹ä½œæˆ
- [ ] `HourlyAggregator`ã‚¯ãƒ©ã‚¹ä½œæˆ
- [ ] é›†è¨ˆæœŸé–“è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] OHLCV è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] é‡è¤‡ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£…
- [ ] ãƒ­ã‚°å‡ºåŠ›å®Ÿè£…
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆä½œæˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] crontab è¨­å®šè¿½åŠ 

### Phase 2: 4 æ™‚é–“è¶³é›†è¨ˆ

- [ ] `FourHourAggregator`ã‚¯ãƒ©ã‚¹ä½œæˆ
- [ ] 4 æ™‚é–“è¶³é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ãƒ†ã‚¹ãƒˆä½œæˆãƒ»å®Ÿè¡Œ
- [ ] crontab è¨­å®šè¿½åŠ 

### Phase 3: æ—¥è¶³é›†è¨ˆ

- [ ] `DailyAggregator`ã‚¯ãƒ©ã‚¹ä½œæˆ
- [ ] æ—¥è¶³é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ãƒ†ã‚¹ãƒˆä½œæˆãƒ»å®Ÿè¡Œ
- [ ] crontab è¨­å®šè¿½åŠ 

---

## ğŸ”„ æ›´æ–°å±¥æ­´

| æ—¥ä»˜       | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ›´æ–°å†…å®¹ | æ‹…å½“è€… |
| ---------- | ---------- | -------- | ------ |
| 2025-08-15 | 1.0.0      | åˆç‰ˆä½œæˆ | -      |

---

## ğŸ“ é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### è¨­è¨ˆæ›¸

- [æ™‚é–“è¶³é›†è¨ˆã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸](./timeframe_aggregation_system_design.md)

### æŠ€è¡“ä»•æ§˜

- [Exchange Analytics System CLI æ©Ÿèƒ½èª¬æ˜æ›¸](../docs/2025-08-15_CLIæ©Ÿèƒ½_ExchangeAnalyticsSystem_CLIæ©Ÿèƒ½èª¬æ˜æ›¸.md)
- [PostgreSQL ç§»è¡Œã‚¬ã‚¤ãƒ‰](../data/POSTGRESQL_BASE_DATA_README.md)

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **è¨€èª**: Python 3.9+
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: PostgreSQL 13+
- **ORM**: SQLAlchemy (asyncio)
- **ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼**: crontab
- **ãƒ­ã‚°**: Python logging

---

_ã“ã®å®Ÿè£…ä»•æ§˜æ›¸ã¯è¨­è¨ˆæ›¸ã«åŸºã¥ã„ã¦ä½œæˆã•ã‚Œã€å…·ä½“çš„ãªå®Ÿè£…æŒ‡é‡ã‚’æä¾›ã—ã¾ã™ã€‚_
