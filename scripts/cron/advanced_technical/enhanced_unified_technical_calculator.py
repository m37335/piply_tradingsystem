"""
EnhancedUnifiedTechnicalCalculator ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

çµ±åˆãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã€‚
3ã¤ã®æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã—ã€tqdmçµ±ä¸€ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

çµ±åˆå¯¾è±¡:
- UnifiedTechnicalCalculator: åŸºç›¤æ©Ÿèƒ½
- TALibTechnicalIndicators: åˆ†ææ©Ÿèƒ½  
- TechnicalIndicatorsAnalyzer: è¨­å®šæœ€é©åŒ–

Author: EnhancedUnifiedTechnicalCalculator Team
Created: 2025-08-15
"""

import asyncio
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
from sqlalchemy import and_, func, select

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.infrastructure.database.models.technical_indicator_model import (
    TechnicalIndicatorModel,
)
from src.infrastructure.database.repositories.technical_indicator_repository_impl import (
    TechnicalIndicatorRepositoryImpl,
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ProgressManagerã¯ä½¿ç”¨ã—ãªã„ãŸã‚å‰Šé™¤

logger = logging.getLogger(__name__)


class EnhancedUnifiedTechnicalCalculator:
    """
    çµ±åˆãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 

    ç¶™æ‰¿é–¢ä¿‚:
    - UnifiedTechnicalCalculator: åŸºç›¤æ©Ÿèƒ½
    - TALibTechnicalIndicators: åˆ†ææ©Ÿèƒ½
    - TechnicalIndicatorsAnalyzer: è¨­å®šæœ€é©åŒ–

    Attributes:
        currency_pair (str): é€šè²¨ãƒšã‚¢
        session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³
        indicator_repo: æŠ€è¡“æŒ‡æ¨™ãƒªãƒã‚¸ãƒˆãƒª
        indicators_config (dict): æŒ‡æ¨™è¨­å®š
        progress_config (dict): ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¨­å®š
    """

    def __init__(self, currency_pair: str = "USD/JPY"):
        """
        EnhancedUnifiedTechnicalCalculatorã‚’åˆæœŸåŒ–

        Args:
            currency_pair: é€šè²¨ãƒšã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "USD/JPY"ï¼‰
        """
        self.currency_pair = currency_pair
        self.session = None
        self.indicator_repo = None

        # åŸºç›¤è¨­å®šï¼ˆUnifiedTechnicalCalculatorï¼‰
        self.timeframes = {
            "M5": "5åˆ†è¶³",
            "H1": "1æ™‚é–“è¶³",  # noqa: E203
            "H4": "4æ™‚é–“è¶³",
            "D1": "æ—¥è¶³",
        }

        # æœ€é©åŒ–è¨­å®šï¼ˆTechnicalIndicatorsAnalyzerï¼‰
        self.indicators_config = {
            "RSI": {
                "short_term": {
                    "period": 30,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                    "overbought": 70,
                    "oversold": 30,
                    "description": "çŸ­æœŸã®éç†±ãƒ»éå†·æ„Ÿã‚’æ¸¬å®š",
                },
                "medium_term": {
                    "period": 50,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                    "overbought": 65,
                    "oversold": 35,
                    "description": "ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·å¼±ã‚’æ¸¬å®š",
                },
                "long_term": {
                    "period": 70,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                    "overbought": 60,
                    "oversold": 40,
                    "description": "é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§ã‚’æ¸¬å®š",
                },
            },
            "MACD": {
                "fast_period": 12,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                "slow_period": 26,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                "signal_period": 9,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                "analysis_features": [
                    "cross_signal",  # TechnicalIndicatorsAnalyzer ã‹ã‚‰
                    "zero_line_position",  # TechnicalIndicatorsAnalyzer ã‹ã‚‰
                ],
                "unified_save": True,
            },
            "BB": {
                "period": 20,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                "std_dev": 2.0,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                "analysis_features": [
                    "band_position",  # TechnicalIndicatorsAnalyzer ã‹ã‚‰
                    "band_walk",  # TechnicalIndicatorsAnalyzer ã‹ã‚‰
                    "band_width",  # TechnicalIndicatorsAnalyzer ã‹ã‚‰
                ],
                "unified_save": True,
            },
            "SMA": {
                "short": 20,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                "medium": 50,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                "long": 200,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                "description": "çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®3æœŸé–“ã§å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŠŠæ¡",
            },
            "EMA": {
                "short": 12,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "medium": 26,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "long": 50,  # TechnicalIndicatorsAnalyzer ã‹ã‚‰æ¡ç”¨
                "description": "MACDã¨é€£æºã™ã‚‹çŸ­æœŸãƒ»ä¸­æœŸã€é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ç”¨",
            },
            "STOCH": {
                "fastk_period": 14,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "slowk_period": 3,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "slowd_period": 3,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "analysis_features": [
                    "state_analysis"  # TALibTechnicalIndicators ã‹ã‚‰
                ],
                "unified_save": True,
            },
            "ATR": {
                "period": 14,  # UnifiedTechnicalCalculator ã‹ã‚‰æ¡ç”¨
                "analysis_features": [
                    "volatility_analysis"  # TALibTechnicalIndicators ã‹ã‚‰
                ],
            },
        }

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¨­å®šï¼ˆtqdmçµ±ä¸€ï¼‰
        self.progress_config = {
            "enable_progress": True,
            "show_detailed": True,
            "tqdm_config": {
                "ncols": 100,
                "bar_format": (
                    "{desc}: {percentage:3.0f}%|{bar:25}| "
                    "{n_fmt}/{total_fmt} [{elapsed}<{remaining}]"
                ),
                "unit": "æŒ‡æ¨™",
                "colour": "cyan",
                "leave": False,  # å®Œäº†å¾Œã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ®‹ã•ãªã„
                "dynamic_ncols": False,  # å›ºå®šåˆ—å¹…ã§æ”¹è¡Œã‚’é˜²ã
                "ascii": False,  # Unicodeæ–‡å­—ã‚’ä½¿ç”¨
                "smoothing": 0.3,  # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°åŠ¹æœ
            },
        }

        logger.info(f"EnhancedUnifiedTechnicalCalculatoråˆæœŸåŒ–å®Œäº†: {currency_pair}")

    async def initialize(self) -> bool:
        """
        ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–

        Returns:
            bool: åˆæœŸåŒ–æˆåŠŸæ™‚True
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®åˆæœŸåŒ–
            from src.infrastructure.database.connection import get_async_session

            self.session = await get_async_session()
            self.indicator_repo = TechnicalIndicatorRepositoryImpl(self.session)

            logger.info("EnhancedUnifiedTechnicalCalculatoråˆæœŸåŒ–å®Œäº†")
            return True

        except Exception as e:
            logger.error(f"EnhancedUnifiedTechnicalCalculatoråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼é–‹å§‹"""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼çµ‚äº†"""
        await self.cleanup()

    async def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            if self.session:
                await self.session.close()
                logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸ")

            # æ˜ç¤ºçš„ã«ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
            import gc

            gc.collect()

        except Exception as e:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    async def _get_price_data(
        self, timeframe: str, limit: Optional[int] = None
    ) -> pd.DataFrame:
        """
        ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            timeframe: æ™‚é–“è¶³
            limit: å–å¾—ä»¶æ•°åˆ¶é™ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶å–å¾—ï¼‰

        Returns:
            pd.DataFrame: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
        """
        data_loader = None
        try:
            # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
            from scripts.cron.advanced_data.data_loader import DataLoader

            data_loader = DataLoader()
            df = await data_loader.load_data(
                currency_pair=self.currency_pair,
                timeframe=timeframe,
                limit=limit,  # åˆ¶é™ä»˜ãã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            )

            if df.empty:
                logger.warning(f"{timeframe}ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return pd.DataFrame()

            logger.debug(f"{timeframe}ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(df)}ä»¶")
            print(f"ğŸ“Š {timeframe}ãƒ‡ãƒ¼ã‚¿å–å¾—: {len(df)}ä»¶")

            if limit:
                print(f"   ğŸ”’ åˆ¶é™ä»˜ãå®Ÿè¡Œ: æœ€æ–°{limit}ä»¶ã®ã¿")

            # DataFrameã®æ§‹é€ ã‚’ç¢ºèª
            print(f"   ğŸ“‹ ã‚«ãƒ©ãƒ : {list(df.columns)}")
            print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹: {df.dtypes.to_dict()}")

            if len(df) > 0:
                # timestampã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
                if "timestamp" in df.columns:
                    print(
                        f"   ğŸ“… æœŸé–“: {df['timestamp'].min()} ï½ {df['timestamp'].max()}"
                    )
                else:
                    print("   âš ï¸ timestampã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

                if "close" in df.columns:
                    print(
                        f"   ğŸ’° ä¾¡æ ¼ç¯„å›²: {df['close'].min():.2f} ï½ {df['close'].max():.2f}"
                    )
                else:
                    print("   âš ï¸ closeã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’å³åº§ã«å¤‰æ›
            df = self._convert_data_types(df)

            return df

        except Exception as e:
            logger.error(f"ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
        finally:
            # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if data_loader:
                try:
                    await data_loader.cleanup()
                except Exception as cleanup_error:
                    logger.warning(
                        f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {cleanup_error}"
                    )

    async def calculate_all_indicators(
        self, limit: Optional[int] = None
    ) -> Dict[str, int]:
        """
        å…¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆtqdmãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰

        Args:
            limit: å„æ™‚é–“è¶³ã®å–å¾—ä»¶æ•°åˆ¶é™ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶å–å¾—ï¼‰

        Returns:
            Dict[str, int]: å„æ™‚é–“è¶³ã®è¨ˆç®—ä»¶æ•°
        """
        results = {}
        total_calculated = 0

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–
        if not self.session:
            await self.initialize()

        # æ™‚é–“è¶³åˆ¥ã®å‡¦ç†
        timeframes = ["M5", "H1", "H4", "D1"]

        for i, timeframe in enumerate(timeframes):
            # æ™‚é–“è¶³ã®åŒºåˆ‡ã‚Šã‚’è¡¨ç¤º
            print(f"\n{'â”€' * 60}")
            print(f"ğŸ“Š {timeframe}æ™‚é–“è¶³ã®å‡¦ç†ã‚’é–‹å§‹")
            if limit:
                print(f"ğŸ”’ åˆ¶é™ä»˜ãå®Ÿè¡Œ: æœ€æ–°{limit}ä»¶ã®ã¿")
            print(f"{'â”€' * 60}\n")

            try:
                count = await self.calculate_timeframe_indicators(timeframe, limit)
                results[timeframe] = count
                total_calculated += count

            except Exception as e:
                print(f"âŒ {timeframe}æ™‚é–“è¶³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                results[timeframe] = 0

        # æœ€çµ‚çµæœã®è¡¨ç¤º
        print(f"\n{'â”€' * 60}")
        print(f"ğŸ“Š è¨ˆç®—çµæœã‚µãƒãƒªãƒ¼")
        if limit:
            print(f"ğŸ”’ åˆ¶é™ä»˜ãå®Ÿè¡Œ: å„æ™‚é–“è¶³{limit}ä»¶ã¾ã§")
        print(f"{'â”€' * 60}")
        print(f"ğŸ“Š è¨ˆç®—çµæœ: {results}")
        print(f"ğŸ“Š ç·è¨ˆç®—ä»¶æ•°: {total_calculated}ä»¶")
        print(f"{'â”€' * 60}")

        # å‡¦ç†å®Œäº†å¾Œã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await self.cleanup()

        return results

    async def calculate_timeframe_indicators(
        self, timeframe: str, limit: Optional[int] = None
    ) -> int:
        """
        ç‰¹å®šæ™‚é–“è¶³ã®æŒ‡æ¨™ã‚’è¨ˆç®—

        Args:
            timeframe: æ™‚é–“è¶³
            limit: å–å¾—ä»¶æ•°åˆ¶é™ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶å–å¾—ï¼‰

        Returns:
            int: è¨ˆç®—ä»¶æ•°
        """
        try:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›æ¸ˆã¿ï¼‰
            df = await self._get_price_data(timeframe, limit)

            if df.empty:
                return 0

            # ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ã‚’å–å¾—
            total_data_points = len(df)
            print(f"ğŸ“Š {timeframe}ãƒ‡ãƒ¼ã‚¿å–å¾—: {total_data_points}ä»¶")

            # å„æŒ‡æ¨™ã‚’è¨ˆç®—
            total_indicators = 0
            indicators = [
                ("RSI", self._calculate_enhanced_rsi),
                ("MACD", self._calculate_enhanced_macd),
                ("BB", self._calculate_enhanced_bb),
                ("MA", self._calculate_enhanced_ma),
                ("STOCH", self._calculate_enhanced_stoch),
                ("ATR", self._calculate_enhanced_atr),
            ]

            # æŒ‡æ¨™åˆ¥ã®æ­£ç¢ºãªåˆè¨ˆä»¶æ•°ã‚’è¨ˆç®—ï¼ˆæœ€å°æœŸé–“ã‚’è€ƒæ…®ï¼‰
            sma_periods = len(
                [
                    v
                    for v in self.indicators_config["SMA"].values()
                    if isinstance(v, int)
                ]
            )
            ema_periods = len(
                [
                    v
                    for v in self.indicators_config["EMA"].values()
                    if isinstance(v, int)
                ]
            )

            # å„æŒ‡æ¨™ã®æœ€å°æœŸé–“ã‚’å–å¾—
            fast_period = self.indicators_config["MACD"]["fast_period"]
            slow_period = self.indicators_config["MACD"]["slow_period"]
            signal_period = self.indicators_config["MACD"]["signal_period"]
            macd_min_period = max(fast_period, slow_period) + signal_period
            bb_min_period = self.indicators_config["BB"]["period"]
            stoch_min_period = self.indicators_config["STOCH"]["fastk_period"]
            atr_min_period = self.indicators_config["ATR"]["period"]

            # æœ€å°æœŸé–“ã‚’è€ƒæ…®ã—ãŸå®Ÿéš›ã®è¨ˆç®—å¯èƒ½ä»¶æ•°
            # RSI: å„æœŸé–“ã®æœ€å°æœŸé–“ã‚’è€ƒæ…®
            rsi_periods = [
                config["period"] for config in self.indicators_config["RSI"].values()
            ]
            rsi_min_period = max(rsi_periods) if rsi_periods else 70
            rsi_calculable = max(0, total_data_points - rsi_min_period)

            # MA: å„æœŸé–“ã®æœ€å°æœŸé–“ã‚’è€ƒæ…®
            ma_periods = []
            for period in self.indicators_config["SMA"].values():
                if isinstance(period, int):
                    ma_periods.append(period)
            for period in self.indicators_config["EMA"].values():
                if isinstance(period, int):
                    ma_periods.append(period)
            ma_min_period = max(ma_periods) if ma_periods else 200
            ma_calculable = max(0, total_data_points - ma_min_period)

            macd_calculable = max(0, total_data_points - macd_min_period)
            bb_calculable = max(0, total_data_points - bb_min_period)
            stoch_calculable = max(0, total_data_points - stoch_min_period)
            atr_calculable = max(0, total_data_points - atr_min_period)

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
            print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {total_data_points}ä»¶")
            print(
                f"   ğŸ“Š RSIè¨ˆç®—å¯èƒ½ä»¶æ•°: {rsi_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {rsi_min_period})"
            )
            print(
                f"   ğŸ“Š MAè¨ˆç®—å¯èƒ½ä»¶æ•°: {ma_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {ma_min_period})"
            )
            print(
                f"   ğŸ“Š MACDè¨ˆç®—å¯èƒ½ä»¶æ•°: {macd_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {macd_min_period})"
            )
            print(
                f"   ğŸ“Š BBè¨ˆç®—å¯èƒ½ä»¶æ•°: {bb_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {bb_min_period})"
            )
            print(
                f"   ğŸ“Š STOCHè¨ˆç®—å¯èƒ½ä»¶æ•°: {stoch_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {stoch_min_period})"
            )
            print(
                f"   ğŸ“Š ATRè¨ˆç®—å¯èƒ½ä»¶æ•°: {atr_calculable}ä»¶ "
                f"(æœ€å°æœŸé–“: {atr_min_period})"
            )

            # æœŸå¾…å€¤ã®è¡¨ç¤ºã‚’æ”¹å–„
            expected_ma_total = (sma_periods + ema_periods) * ma_calculable
            if expected_ma_total == 0:
                print(
                    f"   âš ï¸ MAè¨ˆç®—: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ (å¿…è¦æœŸé–“: {ma_min_period})"
                )
            else:
                print(f"   ğŸ“Š MAæœŸå¾…å€¤: {expected_ma_total}ä»¶")

            # å®Ÿéš›ã®è¨ˆç®—å¯èƒ½ä»¶æ•°ã‚’å†è¨ˆç®—ï¼ˆå„æœŸé–“åˆ¥ï¼‰
            actual_ma_calculable = {}
            for period in self.indicators_config["SMA"].values():
                if isinstance(period, int):
                    actual_ma_calculable[f"SMA_{period}"] = max(
                        0, total_data_points - period + 1
                    )

            for period in self.indicators_config["EMA"].values():
                if isinstance(period, int):
                    actual_ma_calculable[f"EMA_{period}"] = max(
                        0, total_data_points - period + 1
                    )

            # å®Ÿéš›ã®æœŸå¾…å€¤ã‚’è¨ˆç®—
            actual_expected_ma = sum(actual_ma_calculable.values())
            if actual_expected_ma > 0:
                print(f"   ğŸ“Š MAå®Ÿéš›æœŸå¾…å€¤: {actual_expected_ma}ä»¶")
                print(f"   ğŸ“Š MAè©³ç´°: {actual_ma_calculable}")

            indicator_totals = {
                "RSI": len(self.indicators_config["RSI"]) * rsi_calculable,
                "MACD": macd_calculable,
                "BB": bb_calculable,
                "MA": actual_expected_ma,  # å®Ÿéš›ã®è¨ˆç®—å¯èƒ½ä»¶æ•°ã‚’ä½¿ç”¨
                "STOCH": stoch_calculable,
                "ATR": atr_calculable,
            }

            # æ™‚é–“è¶³ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ï¼ˆé‡è¤‡ã‚’æ’é™¤ï¼‰
            from tqdm import tqdm

            with tqdm(
                total=len(indicators),
                desc=f"ğŸ“Š {timeframe} æŒ‡æ¨™è¨ˆç®—ä¸­",
                unit="æŒ‡æ¨™",
                ncols=80,
                bar_format="{desc}: {percentage:3.0f}%|{bar:30}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
                leave=False,  # å®Œäº†å¾Œã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ®‹ã•ãªã„
            ) as timeframe_pbar:
                for indicator_name, calculate_func in indicators:
                    try:
                        # æŒ‡æ¨™åˆ¥ã®æ­£ç¢ºãªåˆè¨ˆä»¶æ•°ã‚’ä½¿ç”¨
                        indicator_total = indicator_totals.get(
                            indicator_name, total_data_points
                        )

                        # ç¾åœ¨ã®æŒ‡æ¨™ã‚’è¡¨ç¤º
                        print(f"\nğŸ” {indicator_name}è¨ˆç®—ä¸­...")

                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®èª¬æ˜ã‚’æ›´æ–°
                        timeframe_pbar.set_description(
                            f"ğŸ“Š {timeframe} {indicator_name}è¨ˆç®—ä¸­"
                        )

                        # æŒ‡æ¨™è¨ˆç®—æ™‚ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ¸¡ã•ãªã„ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
                        result = await calculate_func(df, timeframe, None)

                        # æŒ‡æ¨™è¨ˆç®—å®Œäº†å¾Œã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
                        timeframe_pbar.update(1)
                        timeframe_pbar.refresh()  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’å¼·åˆ¶æ›´æ–°

                        # è¨ˆç®—çµæœã®è©³ç´°è¡¨ç¤º
                        if isinstance(result, dict):
                            if "error" in result:
                                print(f"âŒ {indicator_name}: {result['error']}")
                            elif "count" in result:
                                actual_count = result["count"]
                                expected_count = indicator_total

                                if expected_count > 0:
                                    completion_rate = (
                                        actual_count / expected_count * 100
                                    )
                                    print(
                                        f"âœ… {indicator_name}: {actual_count}/"
                                        f"{expected_count}ä»¶ ({completion_rate:.1f}%)"
                                    )

                                    # è¨ˆç®—ç‡ãŒä½ã„å ´åˆã®è­¦å‘Š
                                    if completion_rate < 80:
                                        print(
                                            f"   âš ï¸ {indicator_name}ã®è¨ˆç®—ç‡ãŒä½ã„ã§ã™"
                                        )
                                else:
                                    if indicator_name == "MA" and actual_count > 0:
                                        print(
                                            f"âœ… {indicator_name}: {actual_count}ä»¶ "
                                            f"(å®Ÿéš›è¨ˆç®—: å„æœŸé–“åˆ¥è¨ˆç®—ã«ã‚ˆã‚Š{actual_count}ä»¶)"
                                        )
                                    else:
                                        print(
                                            f"âœ… {indicator_name}: {actual_count}ä»¶ "
                                            "(æœŸå¾…å€¤: ãƒ‡ãƒ¼ã‚¿ä¸è¶³)"
                                        )
                            else:
                                print(f"âœ… {indicator_name}: å®Œäº†")
                        else:
                            print(f"âœ… {indicator_name}: å®Œäº†")

                        # çµæœã‚«ã‚¦ãƒ³ãƒˆ
                        if isinstance(result, dict) and "count" in result:
                            count = result["count"]
                        else:
                            count = 1 if result else 0

                        total_indicators += count

                    except Exception as e:
                        print(f"âŒ {indicator_name}è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                        import traceback

                        print(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
                        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
                        timeframe_pbar.update(1)

            return total_indicators

        except Exception as e:
            return 0

    def _convert_data_types(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’æ•°å€¤å‹ã«å¤‰æ›

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿

        Returns:
            pd.DataFrame: å‹å¤‰æ›å¾Œã®ãƒ‡ãƒ¼ã‚¿
        """
        try:
            # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’æ•°å€¤å‹ã«å¤‰æ›
            price_columns = ["open", "high", "low", "close"]
            for col in price_columns:
                if col in df.columns:
                    # æ–‡å­—åˆ—ã®å ´åˆã€ã‚«ãƒ³ãƒã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰å¤‰æ›
                    if df[col].dtype == "object":
                        df[col] = df[col].astype(str).str.replace(",", "")

                    # æ•°å€¤å‹ã«å¤‰æ›
                    df[col] = pd.to_numeric(df[col], errors="coerce")

                    # å¤‰æ›å¤±æ•—ã®ç¢ºèª
                    if df[col].isna().all():
                        print(f"   âš ï¸ {col}ã‚«ãƒ©ãƒ ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        print(f"   âœ… {col}ã‚«ãƒ©ãƒ ã‚’æ•°å€¤å‹ã«å¤‰æ›å®Œäº†")

            # å¤‰æ›çµæœã‚’ç¢ºèª
            print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›å¾Œ: {df[price_columns].dtypes.to_dict()}")

            return df

        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return df

    async def _calculate_enhanced_rsi(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        å¤šæœŸé–“RSIè¨ˆç®—ï¼ˆå‚è€ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: å¤šæœŸé–“RSIè¨ˆç®—çµæœ
        """
        try:
            import talib

            saved_count = 0

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºå®Ÿã«æ•°å€¤å‹ã«å¤‰æ›ï¼ˆæ—¢ã«å¤‰æ›æ¸ˆã¿ã ãŒå¿µã®ãŸã‚ï¼‰
            close_series = pd.to_numeric(df["close"], errors="coerce")
            close_values = close_series.values.astype(np.float64)

            # å„æœŸé–“ã®RSIã‚’è¨ˆç®—
            for period_type, config in self.indicators_config["RSI"].items():
                rsi_values = talib.RSI(close_values, timeperiod=config["period"])

                # æœ‰åŠ¹ãªå€¤ã®ã¿ã‚’ä¿å­˜ï¼ˆæœŸé–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                valid_count = 0
                for i, (timestamp, rsi_value) in enumerate(zip(df.index, rsi_values)):
                    if not np.isnan(rsi_value) and i >= config["period"] - 1:
                        # çŠ¶æ…‹åˆ¤å®š
                        state = self._analyze_rsi_state(rsi_value, config)

                        # çµ±åˆãƒ‡ãƒ¼ã‚¿æ§‹é€ 
                        additional_data = {
                            "period_type": period_type,
                            "period": config["period"],
                            "state": state,
                            "overbought": config["overbought"],
                            "oversold": config["oversold"],
                            "description": config["description"],
                            "analysis": {
                                "trend": "single_point",  # å˜ä¸€ç‚¹ã§ã®åˆ†æ
                                "momentum": "neutral",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                            },
                        }

                        # çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
                        unified_data = {
                            "indicator_type": "RSI",
                            "timeframe": timeframe,
                            "value": float(rsi_value),
                            "timestamp": timestamp,
                            "additional_data": additional_data,
                            "parameters": {
                                "period": config["period"],
                                "period_type": period_type,
                                "source": "enhanced_unified_technical_calculator",
                            },
                        }

                        if await self._save_unified_indicator_optimized(unified_data):
                            saved_count += 1
                            valid_count += 1

                print(
                    f"    ğŸ“Š RSI {period_type} ({config['period']}æœŸé–“): {valid_count}ä»¶"
                )

            print(f"  ğŸ“Š RSIè¨ˆç®—å®Œäº†: {saved_count}ä»¶")
            return {
                "indicator": "RSI",
                "timeframe": timeframe,
                "count": saved_count,
            }

        except Exception as e:
            print(f"âŒ RSIè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "count": 0}

    async def _calculate_enhanced_macd(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        çµ±åˆMACDè¨ˆç®—

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: çµ±åˆMACDè¨ˆç®—çµæœ
        """
        try:
            import talib

            config = self.indicators_config["MACD"]

            # TA-Libã§MACDè¨ˆç®—
            close_series = pd.to_numeric(df["close"], errors="coerce")
            close_values = close_series.values.astype(np.float64)
            macd, signal, hist = talib.MACD(
                close_values,
                fastperiod=config["fast_period"],
                slowperiod=config["slow_period"],
                signalperiod=config["signal_period"],
            )

            # æœ€æ–°å€¤ã‚’å–å¾—
            current_macd = macd[-1] if not np.isnan(macd[-1]) else None
            current_signal = signal[-1] if not np.isnan(signal[-1]) else None
            current_hist = hist[-1] if not np.isnan(hist[-1]) else None

            if current_macd is not None and current_signal is not None:
                # çŠ¶æ…‹åˆ¤å®š
                state = self._analyze_macd_state(
                    current_macd, current_signal, current_hist
                )

                # ã‚¯ãƒ­ã‚¹åˆ†æ
                cross_signal = self._analyze_macd_cross(macd, signal)

                # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ä½ç½®
                zero_line_position = self._analyze_zero_line_position(current_macd)

                # çµ±åˆãƒ‡ãƒ¼ã‚¿
                additional_data = {
                    "signal_line": round(current_signal, 4) if current_signal else None,
                    "histogram": round(current_hist, 4) if current_hist else None,
                    "state": state,
                    "analysis": {
                        "cross_signal": cross_signal,
                        "zero_line_position": zero_line_position,
                    },
                }

                # å…¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§è¨ˆç®—ãƒ»ä¿å­˜
            saved_count = 0
            for i in range(len(df)):
                if i < 26:  # MACDè¨ˆç®—ã«å¿…è¦ãªæœ€å°æœŸé–“
                    continue

                # MACDè¨ˆç®—
                close_series = pd.to_numeric(df["close"], errors="coerce")
                close_values = close_series.values[: i + 1].astype(np.float64)
                macd, signal, hist = talib.MACD(
                    close_values,
                    fastperiod=config["fast_period"],
                    slowperiod=config["slow_period"],
                    signalperiod=config["signal_period"],
                )

                current_macd = macd[-1] if not np.isnan(macd[-1]) else None
                current_signal = signal[-1] if not np.isnan(signal[-1]) else None
                current_hist = hist[-1] if not np.isnan(hist[-1]) else None

                if current_macd is not None:
                    # çŠ¶æ…‹åˆ¤å®š
                    state = self._analyze_macd_state(
                        current_macd, current_signal, current_hist
                    )

                    # ã‚¯ãƒ­ã‚¹åˆ†æ
                    cross_signal = self._analyze_macd_cross(macd, signal)

                    # ã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ä½ç½®
                    zero_line_position = self._analyze_zero_line_position(current_macd)

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿
                    point_additional_data = {
                        "signal_line": (
                            round(current_signal, 4) if current_signal else None
                        ),
                        "histogram": round(current_hist, 4) if current_hist else None,
                        "state": state,
                        "analysis": {
                            "cross_signal": cross_signal,
                            "zero_line_position": zero_line_position,
                        },
                    }

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    timestamp = df.index[i]
                    await self._save_unified_indicator(
                        "MACD",
                        timeframe,
                        current_macd,
                        point_additional_data,
                    )
                    saved_count += 1

            if saved_count == 0:
                print(f"âš ï¸ MACDè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶")
                return {"error": "MACDè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶", "count": 0}

            return {
                "indicator": "MACD",
                "timeframe": timeframe,
                "value": round(current_macd, 4),
                "additional_data": additional_data,
                "count": saved_count,  # å®Ÿéš›ã®ä¿å­˜ä»¶æ•°ã‚’è¿”ã™
            }

        except Exception as e:
            return {"error": str(e), "count": 0}

    async def _calculate_enhanced_bb(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        çµ±åˆãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰è¨ˆç®—

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: çµ±åˆBBè¨ˆç®—çµæœ
        """
        try:
            import talib

            config = self.indicators_config["BB"]

            # TA-Libã§ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰è¨ˆç®—
            close_series = pd.to_numeric(df["close"], errors="coerce")
            close_values = close_series.values.astype(np.float64)
            upper, middle, lower = talib.BBANDS(
                close_values,
                timeperiod=config["period"],
                nbdevup=config["std_dev"],
                nbdevdn=config["std_dev"],
                matype=0,
            )

            # æœ€æ–°å€¤ã‚’å–å¾—
            current_upper = upper[-1] if not np.isnan(upper[-1]) else None
            current_middle = middle[-1] if not np.isnan(middle[-1]) else None
            current_lower = lower[-1] if not np.isnan(lower[-1]) else None
            current_close = df["close"].iloc[-1]

            # å…¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§è¨ˆç®—ãƒ»ä¿å­˜
            saved_count = 0
            for i in range(len(df)):
                if i < config["period"]:  # BBè¨ˆç®—ã«å¿…è¦ãªæœ€å°æœŸé–“
                    continue

                # BBè¨ˆç®—
                close_series = pd.to_numeric(df["close"], errors="coerce")
                close_values = close_series.values[: i + 1].astype(np.float64)
                upper, middle, lower = talib.BBANDS(
                    close_values,
                    timeperiod=config["period"],
                    nbdevup=config["std_dev"],
                    nbdevdn=config["std_dev"],
                    matype=0,
                )

                current_upper = upper[-1] if not np.isnan(upper[-1]) else None
                current_middle = middle[-1] if not np.isnan(middle[-1]) else None
                current_lower = lower[-1] if not np.isnan(lower[-1]) else None
                current_close = df["close"].iloc[i]

                if current_middle is not None:
                    # ãƒãƒ³ãƒ‰ä½ç½®åˆ†æ
                    band_position = self._analyze_bb_position(
                        current_close, current_upper, current_middle, current_lower
                    )

                    # ãƒãƒ³ãƒ‰å¹…åˆ†æ
                    band_width = self._analyze_bb_width(upper, middle, lower)

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿
                    point_additional_data = {
                        "upper_band": (
                            round(current_upper, 4) if current_upper else None
                        ),
                        "middle_band": (
                            round(current_middle, 4) if current_middle else None
                        ),
                        "lower_band": (
                            round(current_lower, 4) if current_lower else None
                        ),
                        "band_position": band_position,
                        "band_width": band_width,
                    }

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    await self._save_unified_indicator(
                        "BB", timeframe, current_middle, point_additional_data
                    )
                    saved_count += 1

            if saved_count == 0:
                print(f"âš ï¸ BBè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶")
                return {"error": "BBè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶", "count": 0}

            return {
                "indicator": "BB",
                "timeframe": timeframe,
                "value": round(current_middle, 4),
                "additional_data": point_additional_data,
                "count": saved_count,  # å®Ÿéš›ã®ä¿å­˜ä»¶æ•°ã‚’è¿”ã™
            }

        except Exception as e:
            return {"error": str(e), "count": 0}

    async def _calculate_enhanced_ma(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        å¤šæœŸé–“ç§»å‹•å¹³å‡è¨ˆç®—ï¼ˆå‚è€ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: å¤šæœŸé–“MAè¨ˆç®—çµæœ
        """
        try:
            import talib

            saved_count = 0

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºå®Ÿã«æ•°å€¤å‹ã«å¤‰æ›ï¼ˆæ—¢ã«å¤‰æ›æ¸ˆã¿ã ãŒå¿µã®ãŸã‚ï¼‰
            close_series = pd.to_numeric(df["close"], errors="coerce")
            close_values = close_series.values.astype(np.float64)

            # SMAè¨ˆç®—
            for period in [
                self.indicators_config["SMA"]["short"],
                self.indicators_config["SMA"]["medium"],
                self.indicators_config["SMA"]["long"],
            ]:
                if isinstance(period, int):
                    sma_values = talib.SMA(close_values, timeperiod=period)

                    # æœ‰åŠ¹ãªå€¤ã®ã¿ã‚’ä¿å­˜ï¼ˆæœŸé–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                    valid_count = 0
                    for i, (timestamp, value) in enumerate(zip(df.index, sma_values)):
                        if not np.isnan(value) and i >= period - 1:
                            additional_data = {
                                "ma_type": "SMA",
                                "period": period,
                                "description": self.indicators_config["SMA"].get(
                                    "description", "ç§»å‹•å¹³å‡"
                                ),
                            }

                            indicator = TechnicalIndicatorModel(
                                currency_pair=self.currency_pair,
                                timestamp=timestamp,
                                indicator_type=f"SMA_{period}",
                                timeframe=timeframe,
                                value=float(value),
                                additional_data=additional_data,
                                parameters={
                                    "period": period,
                                    "source": "enhanced_unified_technical_calculator",
                                },
                            )
                            await self.indicator_repo.save(indicator)
                            saved_count += 1
                            valid_count += 1

                    print(f"    ğŸ“Š SMA {period}æœŸé–“: {valid_count}ä»¶")

            # EMAè¨ˆç®—
            for period in [
                self.indicators_config["EMA"]["short"],
                self.indicators_config["EMA"]["medium"],
                self.indicators_config["EMA"]["long"],
            ]:
                if isinstance(period, int):
                    ema_values = talib.EMA(close_values, timeperiod=period)

                    # æœ‰åŠ¹ãªå€¤ã®ã¿ã‚’ä¿å­˜ï¼ˆæœŸé–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
                    valid_count = 0
                    for i, (timestamp, value) in enumerate(zip(df.index, ema_values)):
                        if not np.isnan(value) and i >= period - 1:
                            additional_data = {
                                "ma_type": "EMA",
                                "period": period,
                                "description": self.indicators_config["EMA"].get(
                                    "description", "æŒ‡æ•°ç§»å‹•å¹³å‡"
                                ),
                            }

                            indicator = TechnicalIndicatorModel(
                                currency_pair=self.currency_pair,
                                timestamp=timestamp,
                                indicator_type=f"EMA_{period}",
                                timeframe=timeframe,
                                value=float(value),
                                additional_data=additional_data,
                                parameters={
                                    "period": period,
                                    "source": "enhanced_unified_technical_calculator",
                                },
                            )
                            await self.indicator_repo.save(indicator)
                            saved_count += 1
                            valid_count += 1

                    print(f"    ğŸ“Š EMA {period}æœŸé–“: {valid_count}ä»¶")

            print(f"  ğŸ“Š ç§»å‹•å¹³å‡è¨ˆç®—å®Œäº†: {saved_count}ä»¶")
            return {
                "indicator": "MA",
                "timeframe": timeframe,
                "count": saved_count,
            }

        except Exception as e:
            print(f"âŒ ç§»å‹•å¹³å‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "count": 0}

    async def _calculate_enhanced_stoch(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        çµ±åˆã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹è¨ˆç®—

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: çµ±åˆSTOCHè¨ˆç®—çµæœ
        """
        try:
            import talib

            config = self.indicators_config["STOCH"]

            # TA-Libã§ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹è¨ˆç®—
            high_series = pd.to_numeric(df["high"], errors="coerce")
            low_series = pd.to_numeric(df["low"], errors="coerce")
            close_series = pd.to_numeric(df["close"], errors="coerce")
            high_values = high_series.values.astype(np.float64)
            low_values = low_series.values.astype(np.float64)
            close_values = close_series.values.astype(np.float64)
            slowk, slowd = talib.STOCH(
                high_values,
                low_values,
                close_values,
                fastk_period=config["fastk_period"],
                slowk_period=config["slowk_period"],
                slowk_matype=0,
                slowd_period=config["slowd_period"],
                slowd_matype=0,
            )

            # æœ€æ–°å€¤ã‚’å–å¾—
            current_k = slowk[-1] if not np.isnan(slowk[-1]) else None
            current_d = slowd[-1] if not np.isnan(slowd[-1]) else None

            # å…¨ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§è¨ˆç®—ãƒ»ä¿å­˜
            saved_count = 0
            for i in range(len(df)):
                if i < config["fastk_period"]:  # STOCHè¨ˆç®—ã«å¿…è¦ãªæœ€å°æœŸé–“
                    continue

                # STOCHè¨ˆç®—
                high_series = pd.to_numeric(df["high"], errors="coerce")
                low_series = pd.to_numeric(df["low"], errors="coerce")
                close_series = pd.to_numeric(df["close"], errors="coerce")
                high_values = high_series.values[: i + 1].astype(np.float64)
                low_values = low_series.values[: i + 1].astype(np.float64)
                close_values = close_series.values[: i + 1].astype(np.float64)
                slowk, slowd = talib.STOCH(
                    high_values,
                    low_values,
                    close_values,
                    fastk_period=config["fastk_period"],
                    slowk_period=config["slowk_period"],
                    slowk_matype=0,
                    slowd_period=config["slowd_period"],
                    slowd_matype=0,
                )

                current_k = slowk[-1] if not np.isnan(slowk[-1]) else None
                current_d = slowd[-1] if not np.isnan(slowd[-1]) else None

                if current_k is not None and current_d is not None:
                    # çŠ¶æ…‹åˆ†æ
                    state = self._analyze_stoch_state(current_k, current_d)

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿
                    point_additional_data = {
                        "k_line": round(current_k, 2),
                        "d_line": round(current_d, 2),
                        "state": state,
                    }

                    # çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    await self._save_unified_indicator(
                        "STOCH", timeframe, current_k, point_additional_data
                    )
                    saved_count += 1

            if saved_count == 0:
                print(f"âš ï¸ STOCHè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶")
                return {"error": "STOCHè¨ˆç®—å¤±æ•—: ä¿å­˜ä»¶æ•°ãŒ0ä»¶", "count": 0}

            return {
                "indicator": "STOCH",
                "timeframe": timeframe,
                "value": round(current_k, 2),
                "additional_data": point_additional_data,
                "count": saved_count,  # å®Ÿéš›ã®ä¿å­˜ä»¶æ•°ã‚’è¿”ã™
            }

        except Exception as e:
            return {"error": str(e), "count": 0}

    async def _calculate_enhanced_atr(
        self, df: pd.DataFrame, timeframe: str, pbar=None
    ) -> Dict[str, Any]:
        """
        çµ±åˆATRè¨ˆç®—ï¼ˆå‚è€ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰

        Args:
            df: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            timeframe: æ™‚é–“è¶³

        Returns:
            Dict[str, Any]: çµ±åˆATRè¨ˆç®—çµæœ
        """
        try:
            import talib

            config = self.indicators_config["ATR"]
            saved_count = 0

            # ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºå®Ÿã«æ•°å€¤å‹ã«å¤‰æ›ï¼ˆæ—¢ã«å¤‰æ›æ¸ˆã¿ã ãŒå¿µã®ãŸã‚ï¼‰
            high_series = pd.to_numeric(df["high"], errors="coerce")
            low_series = pd.to_numeric(df["low"], errors="coerce")
            close_series = pd.to_numeric(df["close"], errors="coerce")
            high_values = high_series.values.astype(np.float64)
            low_values = low_series.values.astype(np.float64)
            close_values = close_series.values.astype(np.float64)

            # TA-Libã§ATRè¨ˆç®—
            atr_values = talib.ATR(
                high_values,
                low_values,
                close_values,
                timeperiod=config["period"],
            )

            # æœ‰åŠ¹ãªå€¤ã®ã¿ã‚’ä¿å­˜
            for i, (timestamp, atr_value) in enumerate(zip(df.index, atr_values)):
                if not np.isnan(atr_value):
                    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
                    volatility_analysis = self._analyze_atr_volatility(atr_values)

                    additional_data = {
                        "period": config["period"],
                        "volatility_analysis": volatility_analysis,
                        "description": "å¹³å‡çœŸã®ç¯„å›²ã«ã‚ˆã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æ¸¬å®š",
                    }

                    indicator = TechnicalIndicatorModel(
                        currency_pair=self.currency_pair,
                        timestamp=timestamp,
                        indicator_type="ATR",
                        timeframe=timeframe,
                        value=float(atr_value),
                        additional_data=additional_data,
                        parameters={
                            "period": config["period"],
                            "source": "enhanced_unified_technical_calculator",
                        },
                    )

                    await self.indicator_repo.save(indicator)
                    saved_count += 1

            print(f"  ğŸ“Š ATRè¨ˆç®—å®Œäº†: {saved_count}ä»¶")
            return {
                "indicator": "ATR",
                "timeframe": timeframe,
                "count": saved_count,
            }

        except Exception as e:
            print(f"âŒ ATRè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "count": 0}

    async def _save_unified_indicator(
        self,
        indicator_type: str,
        timeframe: str,
        value: float,
        additional_data: Dict[str, Any],
        analysis: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜

        Args:
            indicator_type: æŒ‡æ¨™ã‚¿ã‚¤ãƒ—
            timeframe: æ™‚é–“è¶³
            value: ä¸»è¦ãªå€¤
            additional_data: è¿½åŠ ãƒ‡ãƒ¼ã‚¿
            analysis: åˆ†æçµæœ

        Returns:
            bool: ä¿å­˜æˆåŠŸæ™‚True
        """
        try:
            # åˆ†æçµæœã‚’è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã«çµ±åˆ
            if analysis:
                additional_data["analysis"] = analysis

            # æŠ€è¡“æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
            current_timestamp = datetime.now()
            indicator = TechnicalIndicatorModel(
                currency_pair=self.currency_pair,
                timestamp=current_timestamp,
                indicator_type=indicator_type,
                timeframe=timeframe,
                value=value,
                additional_data=additional_data,
                parameters=self.indicators_config.get(indicator_type, {}),
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            await self.indicator_repo.save(indicator)

            return True

        except Exception as e:
            logger.error(f"çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ {indicator_type}ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            print(f"ä¿å­˜è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return False

    async def _save_unified_indicator_optimized(
        self, indicator_data: Dict[str, Any]
    ) -> bool:
        """
        çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰

        Args:
            indicator_data: çµ±åˆã•ã‚ŒãŸæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿

        Returns:
            bool: ä¿å­˜æˆåŠŸæ™‚True
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
            if not await self._validate_data_integrity(indicator_data):
                logger.warning("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            # ãƒ‡ãƒ¼ã‚¿åœ§ç¸®
            compressed_data = await self._compress_additional_data(
                indicator_data.get("additional_data", {})
            )

            # æŠ€è¡“æŒ‡æ¨™ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ™‚åˆ»ã‚’ä½¿ç”¨ï¼ˆè¨ˆç®—æ™‚åˆ»ã§ã¯ãªã„ï¼‰
            timestamp = indicator_data.get("timestamp")
            if timestamp is None:
                logger.error("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            indicator = TechnicalIndicatorModel(
                currency_pair=self.currency_pair,
                timestamp=timestamp,
                indicator_type=indicator_data.get("indicator_type"),
                timeframe=indicator_data.get("timeframe"),
                value=indicator_data.get("value"),
                additional_data=compressed_data,
                parameters=indicator_data.get("parameters", {}),
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            await self.indicator_repo.save(indicator)

            logger.info(
                f"çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {indicator_data.get('indicator_type')} - {indicator_data.get('timeframe')}"
            )
            return True

        except Exception as e:
            logger.error(f"çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _batch_save_indicators(self, indicators: List[Dict[str, Any]]) -> int:
        """
        ãƒãƒƒãƒä¿å­˜æ©Ÿèƒ½

        Args:
            indicators: ä¿å­˜ã™ã‚‹æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

        Returns:
            int: ä¿å­˜æˆåŠŸä»¶æ•°
        """
        try:
            if not indicators:
                return 0

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
            valid_indicators = []
            for indicator_data in indicators:
                if await self._validate_data_integrity(indicator_data):
                    valid_indicators.append(indicator_data)
                else:
                    logger.warning(
                        f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼å¤±æ•—: {indicator_data.get('indicator_type')}"
                    )

            if not valid_indicators:
                logger.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return 0

            # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            indicator_models = []
            for indicator_data in valid_indicators:
                compressed_data = await self._compress_additional_data(
                    indicator_data.get("additional_data", {})
                )

                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ™‚åˆ»ã‚’ä½¿ç”¨ï¼ˆè¨ˆç®—æ™‚åˆ»ã§ã¯ãªã„ï¼‰
                timestamp = indicator_data.get("timestamp")
                if timestamp is None:
                    logger.warning(
                        f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {indicator_data.get('indicator_type')}"
                    )
                    continue

                model = TechnicalIndicatorModel(
                    currency_pair=self.currency_pair,
                    timestamp=timestamp,
                    indicator_type=indicator_data.get("indicator_type"),
                    timeframe=indicator_data.get("timeframe"),
                    value=indicator_data.get("value"),
                    additional_data=compressed_data,
                    parameters=indicator_data.get("parameters", {}),
                )
                indicator_models.append(model)

            # ãƒãƒƒãƒä¿å­˜å®Ÿè¡Œ
            saved_models = await self.indicator_repo.save_batch(indicator_models)

            logger.info(f"ãƒãƒƒãƒä¿å­˜å®Œäº†: {len(saved_models)}ä»¶")
            return len(saved_models)

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def _validate_data_integrity(self, indicator_data: Dict[str, Any]) -> bool:
        """
        ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼

        Args:
            indicator_data: æ¤œè¨¼ã™ã‚‹æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿

        Returns:
            bool: æ•´åˆæ€§ãŒã‚ã‚‹å ´åˆTrue
        """
        try:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            required_fields = ["indicator_type", "timeframe", "value"]
            for field in required_fields:
                if field not in indicator_data or indicator_data[field] is None:
                    logger.warning(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
                    return False

            # ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
            if not isinstance(indicator_data["indicator_type"], str):
                logger.warning("indicator_typeã¯æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                return False

            if not isinstance(indicator_data["timeframe"], str):
                logger.warning("timeframeã¯æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                return False

            if not isinstance(indicator_data["value"], (int, float)):
                logger.warning("valueã¯æ•°å€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                return False

            # å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
            value = float(indicator_data["value"])
            if np.isnan(value) or np.isinf(value):
                logger.warning("valueãŒç„¡åŠ¹ãªå€¤ã§ã™")
                return False

            # æŒ‡æ¨™ã‚¿ã‚¤ãƒ—ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            valid_indicators = ["RSI", "MACD", "BB", "SMA", "EMA", "STOCH", "ATR"]
            if indicator_data["indicator_type"] not in valid_indicators:
                logger.warning(f"ç„¡åŠ¹ãªæŒ‡æ¨™ã‚¿ã‚¤ãƒ—: {indicator_data['indicator_type']}")
                return False

            # æ™‚é–“è¶³ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            valid_timeframes = ["M5", "M15", "H1", "H4", "D1"]
            if indicator_data["timeframe"] not in valid_timeframes:
                logger.warning(f"ç„¡åŠ¹ãªæ™‚é–“è¶³: {indicator_data['timeframe']}")
                return False

            # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ãƒã‚§ãƒƒã‚¯
            if (
                "additional_data" in indicator_data
                and indicator_data["additional_data"]
            ):
                if not isinstance(indicator_data["additional_data"], dict):
                    logger.warning("additional_dataã¯è¾æ›¸ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
                    return False

            logger.debug(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼æˆåŠŸ: {indicator_data['indicator_type']}")
            return True

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _compress_additional_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®åœ§ç¸®

        Args:
            data: åœ§ç¸®ã™ã‚‹ãƒ‡ãƒ¼ã‚¿

        Returns:
            Dict[str, Any]: åœ§ç¸®ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        try:
            if not data:
                return {}

            compressed_data = {}

            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ä¸¸ã‚å‡¦ç†
            for key, value in data.items():
                if isinstance(value, dict):
                    compressed_data[key] = await self._compress_additional_data(value)
                elif isinstance(value, (int, float)):
                    # å°æ•°ç‚¹ä»¥ä¸‹4æ¡ã«ä¸¸ã‚ã‚‹
                    compressed_data[key] = round(float(value), 4)
                elif isinstance(value, list):
                    # ãƒªã‚¹ãƒˆå†…ã®æ•°å€¤ã‚‚ä¸¸ã‚ã‚‹
                    compressed_list = []
                    for item in value:
                        if isinstance(item, (int, float)):
                            compressed_list.append(round(float(item), 4))
                        else:
                            compressed_list.append(item)
                    compressed_data[key] = compressed_list
                else:
                    compressed_data[key] = value

            return compressed_data

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            return data

    async def _analyze_existing_data(self) -> Dict[str, Any]:
        """
        æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ

        Returns:
            Dict[str, Any]: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æçµæœ
        """
        try:
            analysis_result = {
                "total_records": 0,
                "indicator_types": {},
                "timeframes": {},
                "data_quality": {},
                "recommendations": [],
            }

            # å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®å–å¾—
            total_query = select(func.count(TechnicalIndicatorModel.id))
            result = await self.session.execute(total_query)
            analysis_result["total_records"] = result.scalar()

            # æŒ‡æ¨™ã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆ
            type_query = select(
                TechnicalIndicatorModel.indicator_type,
                func.count(TechnicalIndicatorModel.id),
            ).group_by(TechnicalIndicatorModel.indicator_type)

            result = await self.session.execute(type_query)
            for indicator_type, count in result:
                analysis_result["indicator_types"][indicator_type] = count

            # æ™‚é–“è¶³åˆ¥ã®é›†è¨ˆ
            timeframe_query = select(
                TechnicalIndicatorModel.timeframe,
                func.count(TechnicalIndicatorModel.id),
            ).group_by(TechnicalIndicatorModel.timeframe)

            result = await self.session.execute(timeframe_query)
            for timeframe, count in result:
                analysis_result["timeframes"][timeframe] = count

            # ãƒ‡ãƒ¼ã‚¿å“è³ªã®åˆ†æ
            analysis_result["data_quality"] = await self._analyze_data_quality()

            # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
            analysis_result["recommendations"] = (
                await self._generate_data_recommendations(analysis_result)
            )

            logger.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æå®Œäº†: {analysis_result['total_records']}ä»¶")
            return analysis_result

        except Exception as e:
            logger.error(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _analyze_data_quality(self) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªã®åˆ†æ

        Returns:
            Dict[str, Any]: ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æçµæœ
        """
        try:
            quality_analysis = {
                "null_values": 0,
                "invalid_values": 0,
                "duplicate_records": 0,
                "missing_additional_data": 0,
            }

            # NULLå€¤ã®ãƒã‚§ãƒƒã‚¯
            null_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.value.is_(None)
            )
            result = await self.session.execute(null_query)
            quality_analysis["null_values"] = result.scalar()

            # ç„¡åŠ¹ãªå€¤ã®ãƒã‚§ãƒƒã‚¯ï¼ˆ0ã¾ãŸã¯è² ã®å€¤ï¼‰
            invalid_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.value <= 0
            )
            result = await self.session.execute(invalid_query)
            quality_analysis["invalid_values"] = result.scalar()

            # é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            duplicate_query = (
                select(
                    TechnicalIndicatorModel.currency_pair,
                    TechnicalIndicatorModel.timestamp,
                    TechnicalIndicatorModel.indicator_type,
                    TechnicalIndicatorModel.timeframe,
                    func.count(TechnicalIndicatorModel.id),
                )
                .group_by(
                    TechnicalIndicatorModel.currency_pair,
                    TechnicalIndicatorModel.timestamp,
                    TechnicalIndicatorModel.indicator_type,
                    TechnicalIndicatorModel.timeframe,
                )
                .having(func.count(TechnicalIndicatorModel.id) > 1)
            )

            result = await self.session.execute(duplicate_query)
            quality_analysis["duplicate_records"] = len(result.fetchall())

            # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            missing_data_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.additional_data.is_(None)
            )
            result = await self.session.execute(missing_data_query)
            quality_analysis["missing_additional_data"] = result.scalar()

            return quality_analysis

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _generate_data_recommendations(
        self, analysis_result: Dict[str, Any]
    ) -> List[str]:
        """
        ãƒ‡ãƒ¼ã‚¿æ¨å¥¨äº‹é …ã®ç”Ÿæˆ

        Args:
            analysis_result: åˆ†æçµæœ

        Returns:
            List[str]: æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ
        """
        try:
            recommendations = []

            total_records = analysis_result.get("total_records", 0)
            data_quality = analysis_result.get("data_quality", {})

            # ãƒ‡ãƒ¼ã‚¿é‡ã®æ¨å¥¨
            if total_records < 1000:
                recommendations.append(
                    "ãƒ‡ãƒ¼ã‚¿é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
                )

            # ãƒ‡ãƒ¼ã‚¿å“è³ªã®æ¨å¥¨
            if data_quality.get("null_values", 0) > 0:
                recommendations.append(
                    "NULLå€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )

            if data_quality.get("invalid_values", 0) > 0:
                recommendations.append(
                    "ç„¡åŠ¹ãªå€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )

            if data_quality.get("duplicate_records", 0) > 0:
                recommendations.append(
                    "é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã‚’è§£æ¶ˆã—ã¦ãã ã•ã„ã€‚"
                )

            if data_quality.get("missing_additional_data", 0) > 0:
                recommendations.append(
                    "è¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
                )

            # æŒ‡æ¨™ã‚¿ã‚¤ãƒ—ã®æ¨å¥¨
            indicator_types = analysis_result.get("indicator_types", {})
            if len(indicator_types) < 5:
                recommendations.append(
                    "æŒ‡æ¨™ã®ç¨®é¡ãŒå°‘ãªã„ã§ã™ã€‚ã‚ˆã‚Šå¤šæ§˜ãªæŒ‡æ¨™ã®è¨ˆç®—ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
                )

            # æ™‚é–“è¶³ã®æ¨å¥¨
            timeframes = analysis_result.get("timeframes", {})
            if len(timeframes) < 3:
                recommendations.append(
                    "æ™‚é–“è¶³ã®ç¨®é¡ãŒå°‘ãªã„ã§ã™ã€‚ã‚ˆã‚Šå¤šæ§˜ãªæ™‚é–“è¶³ã§ã®åˆ†æã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
                )

            return recommendations

        except Exception as e:
            logger.error(f"æ¨å¥¨äº‹é …ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ["æ¨å¥¨äº‹é …ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"]

    # åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆï¼‰
    def _analyze_rsi_state(self, rsi_value: float, config: Dict[str, Any]) -> str:
        """RSIçŠ¶æ…‹åˆ†æ"""
        if rsi_value >= config["overbought"]:
            return "overbought"
        elif rsi_value <= config["oversold"]:
            return "oversold"
        else:
            return "neutral"

    def _analyze_rsi_trend(self, rsi_values: np.ndarray, periods: int = 5) -> str:
        """RSIå‚¾ãåˆ†æ"""
        if len(rsi_values) < periods:
            return "unknown"

        recent_values = rsi_values[-periods:]
        if recent_values[-1] > recent_values[0]:
            return "rising"
        elif recent_values[-1] < recent_values[0]:
            return "falling"
        else:
            return "flat"

    def _analyze_multi_period_rsi(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """å¤šæœŸé–“RSIçµ±åˆåˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"overall_trend": "mixed", "confidence": "medium"}

    def _analyze_macd_state(self, macd: float, signal: float, hist: float) -> str:
        """MACDçŠ¶æ…‹åˆ†æ"""
        if macd > signal and hist > 0:
            return "bullish"
        elif macd < signal and hist < 0:
            return "bearish"
        else:
            return "neutral"

    def _analyze_macd_cross(self, macd: np.ndarray, signal: np.ndarray) -> str:
        """MACDã‚¯ãƒ­ã‚¹åˆ†æ"""
        if len(macd) < 2 or len(signal) < 2:
            return "unknown"

        if macd[-1] > signal[-1] and macd[-2] <= signal[-2]:
            return "bullish_cross"
        elif macd[-1] < signal[-1] and macd[-2] >= signal[-2]:
            return "bearish_cross"
        else:
            return "no_cross"

    def _analyze_zero_line_position(self, macd: float) -> str:
        """MACDã‚¼ãƒ­ãƒ©ã‚¤ãƒ³ä½ç½®åˆ†æ"""
        if macd > 0:
            return "above"
        elif macd < 0:
            return "below"
        else:
            return "at_zero"

    def _analyze_bb_position(
        self, close: float, upper: float, middle: float, lower: float
    ) -> str:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½®åˆ†æ"""
        if close > upper:
            return "above_upper"
        elif close < lower:
            return "below_lower"
        elif close > middle:
            return "above_middle"
        else:
            return "below_middle"

    def _analyze_bb_width(
        self, upper: np.ndarray, middle: np.ndarray, lower: np.ndarray
    ) -> str:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰å¹…åˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return "normal"

    def _analyze_multi_period_ma(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """å¤šæœŸé–“MAçµ±åˆåˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"trend": "mixed", "strength": "medium"}

    def _analyze_stoch_state(self, k: float, d: float) -> str:
        """ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹çŠ¶æ…‹åˆ†æ"""
        if k > 80 and d > 80:
            return "overbought"
        elif k < 20 and d < 20:
            return "oversold"
        else:
            return "neutral"

    def _analyze_atr_volatility(self, atr_values: np.ndarray) -> Dict[str, Any]:
        """ATRãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"volatility_level": "normal", "trend": "stable"}

    def _analyze_indicator_state(
        self, indicator_type: str, values: np.ndarray
    ) -> Dict[str, Any]:
        """
        æŒ‡æ¨™ã®çŠ¶æ…‹åˆ¤å®šï¼ˆTALibTechnicalIndicatorsçµ±åˆï¼‰

        Args:
            indicator_type: æŒ‡æ¨™ã‚¿ã‚¤ãƒ—
            values: æŒ‡æ¨™å€¤

        Returns:
            Dict[str, Any]: çŠ¶æ…‹åˆ†æçµæœ
        """
        try:
            if len(values) == 0:
                return {"state": "unknown", "confidence": "low"}

            current_value = values[-1] if not np.isnan(values[-1]) else None
            if current_value is None:
                return {"state": "unknown", "confidence": "low"}

            if indicator_type == "RSI":
                return self._analyze_rsi_state_advanced(current_value)
            elif indicator_type == "MACD":
                return self._analyze_macd_state_advanced(values)
            elif indicator_type == "BB":
                return self._analyze_bb_state_advanced(values)
            elif indicator_type == "STOCH":
                return self._analyze_stoch_state_advanced(values)
            elif indicator_type == "ATR":
                return self._analyze_atr_state_advanced(values)
            else:
                return {"state": "unknown", "confidence": "low"}

        except Exception as e:
            logger.error(f"æŒ‡æ¨™çŠ¶æ…‹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"state": "error", "confidence": "low"}

    def _analyze_trend_strength(
        self, values: np.ndarray, periods: int = 5
    ) -> Dict[str, Any]:
        """
        ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åˆ†æï¼ˆTALibTechnicalIndicatorsçµ±åˆï¼‰

        Args:
            values: æŒ‡æ¨™å€¤
            periods: åˆ†ææœŸé–“

        Returns:
            Dict[str, Any]: ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åˆ†æçµæœ
        """
        try:
            if len(values) < periods:
                return {"trend": "unknown", "strength": "low", "confidence": "low"}

            recent_values = values[-periods:]
            valid_values = recent_values[~np.isnan(recent_values)]

            if len(valid_values) < 2:
                return {"trend": "unknown", "strength": "low", "confidence": "low"}

            # ç·šå½¢å›å¸°ã§å‚¾ãã‚’è¨ˆç®—
            x = np.arange(len(valid_values))
            slope, intercept = np.polyfit(x, valid_values, 1)

            # æ±ºå®šä¿‚æ•°ã‚’è¨ˆç®—
            y_pred = slope * x + intercept
            r_squared = 1 - np.sum((valid_values - y_pred) ** 2) / np.sum(
                (valid_values - np.mean(valid_values)) ** 2
            )

            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
            if slope > 0:
                trend = "rising"
            elif slope < 0:
                trend = "falling"
            else:
                trend = "flat"

            # å¼·åº¦åˆ¤å®š
            if abs(slope) > 2.0 and r_squared > 0.7:
                strength = "strong"
            elif abs(slope) > 1.0 and r_squared > 0.5:
                strength = "medium"
            else:
                strength = "weak"

            # ä¿¡é ¼åº¦åˆ¤å®š
            if r_squared > 0.8:
                confidence = "high"
            elif r_squared > 0.6:
                confidence = "medium"
            else:
                confidence = "low"

            return {
                "trend": trend,
                "strength": strength,
                "confidence": confidence,
                "slope": float(slope),
                "r_squared": float(r_squared),
            }

        except Exception as e:
            logger.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"trend": "error", "strength": "low", "confidence": "low"}

    def _generate_trading_signals(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆï¼ˆTALibTechnicalIndicatorsçµ±åˆï¼‰

        Args:
            indicator_data: æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿

        Returns:
            Dict[str, Any]: ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚·ã‚°ãƒŠãƒ«
        """
        try:
            signals = {
                "primary_signal": "hold",
                "secondary_signal": "hold",
                "confidence": "low",
                "reason": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³",
            }

            indicator_type = indicator_data.get("indicator_type")
            state = indicator_data.get("state", "unknown")
            trend = indicator_data.get("trend", "unknown")
            strength = indicator_data.get("strength", "low")

            if indicator_type == "RSI":
                signals.update(self._generate_rsi_signals(indicator_data))
            elif indicator_type == "MACD":
                signals.update(self._generate_macd_signals(indicator_data))
            elif indicator_type == "BB":
                signals.update(self._generate_bb_signals(indicator_data))
            elif indicator_type == "STOCH":
                signals.update(self._generate_stoch_signals(indicator_data))

            return signals

        except Exception as e:
            logger.error(f"ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"primary_signal": "error", "confidence": "low"}

    def _perform_advanced_analysis(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        é«˜åº¦åˆ†ææ©Ÿèƒ½ï¼ˆTALibTechnicalIndicatorsçµ±åˆï¼‰

        Args:
            indicator_data: æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿

        Returns:
            Dict[str, Any]: é«˜åº¦åˆ†æçµæœ
        """
        try:
            analysis = {
                "divergence": self._detect_divergence_advanced(indicator_data),
                "momentum": self._analyze_momentum_advanced(indicator_data),
                "volatility": self._analyze_volatility_advanced(indicator_data),
                "support_resistance": self._analyze_support_resistance_advanced(
                    indicator_data
                ),
            }

            return analysis

        except Exception as e:
            logger.error(f"é«˜åº¦åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _apply_optimized_settings(self) -> None:
        """
        æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã®é©ç”¨ï¼ˆTechnicalIndicatorsAnalyzerçµ±åˆï¼‰
        """
        try:
            # TechnicalIndicatorsAnalyzerã®æœ€é©åŒ–è¨­å®šã‚’é©ç”¨
            optimized_config = {
                "RSI": {
                    "short_term": {
                        "period": 30,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                        "overbought": 70,
                        "oversold": 30,
                        "description": "çŸ­æœŸã®éç†±ãƒ»éå†·æ„Ÿã‚’æ¸¬å®š",
                    },
                    "medium_term": {
                        "period": 50,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                        "overbought": 65,
                        "oversold": 35,
                        "description": "ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®å¼·å¼±ã‚’æ¸¬å®š",
                    },
                    "long_term": {
                        "period": 70,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                        "overbought": 60,
                        "oversold": 40,
                        "description": "é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®æ–¹å‘æ€§ã‚’æ¸¬å®š",
                    },
                },
                "SMA": {
                    "short": 20,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                    "medium": 50,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                    "long": 200,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                    "description": "çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®3æœŸé–“ã§å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŠŠæ¡",
                },
                "EMA": {
                    "short": 12,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "medium": 26,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "long": 50,  # TechnicalIndicatorsAnalyzerã‹ã‚‰æ¡ç”¨
                    "description": "MACDã¨é€£æºã™ã‚‹çŸ­æœŸãƒ»ä¸­æœŸã€é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰ç”¨",
                },
                "MACD": {
                    "fast_period": 12,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                    "slow_period": 26,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                    "signal_period": 9,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                    "analysis_features": [
                        "cross_signal",  # TechnicalIndicatorsAnalyzerã‹ã‚‰
                        "zero_line_position",  # TechnicalIndicatorsAnalyzerã‹ã‚‰
                    ],
                    "unified_save": True,
                },
                "BB": {
                    "period": 20,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                    "std_dev": 2.0,  # å…¨ã‚·ã‚¹ãƒ†ãƒ å…±é€š
                    "analysis_features": [
                        "band_position",  # TechnicalIndicatorsAnalyzerã‹ã‚‰
                        "band_walk",  # TechnicalIndicatorsAnalyzerã‹ã‚‰
                        "band_width",  # TechnicalIndicatorsAnalyzerã‹ã‚‰
                    ],
                    "unified_save": True,
                },
                "STOCH": {
                    "fastk_period": 14,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "slowk_period": 3,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "slowd_period": 3,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "analysis_features": [
                        "state_analysis"  # TALibTechnicalIndicatorsã‹ã‚‰
                    ],
                    "unified_save": True,
                },
                "ATR": {
                    "period": 14,  # UnifiedTechnicalCalculatorã‹ã‚‰æ¡ç”¨
                    "analysis_features": [
                        "volatility_analysis"  # TALibTechnicalIndicatorsã‹ã‚‰
                    ],
                },
            }

            # è¨­å®šã‚’æ›´æ–°
            self.indicators_config.update(optimized_config)
            logger.info("æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"æœ€é©åŒ–è¨­å®šé©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")

    def _validate_settings_compatibility(self) -> bool:
        """
        è¨­å®šã®äº’æ›æ€§æ¤œè¨¼ï¼ˆTechnicalIndicatorsAnalyzerçµ±åˆï¼‰

        Returns:
            bool: äº’æ›æ€§ãŒã‚ã‚‹å ´åˆTrue
        """
        try:
            # RSIè¨­å®šã®æ¤œè¨¼
            rsi_config = self.indicators_config.get("RSI", {})
            if not all(
                key in rsi_config for key in ["short_term", "medium_term", "long_term"]
            ):
                logger.warning("RSIè¨­å®šãŒä¸å®Œå…¨ã§ã™")
                return False

            # ç§»å‹•å¹³å‡è¨­å®šã®æ¤œè¨¼
            sma_config = self.indicators_config.get("SMA", {})
            if not all(key in sma_config for key in ["short", "medium", "long"]):
                logger.warning("SMAè¨­å®šãŒä¸å®Œå…¨ã§ã™")
                return False

            # MACDè¨­å®šã®æ¤œè¨¼
            macd_config = self.indicators_config.get("MACD", {})
            if not all(
                key in macd_config
                for key in ["fast_period", "slow_period", "signal_period"]
            ):
                logger.warning("MACDè¨­å®šãŒä¸å®Œå…¨ã§ã™")
                return False

            logger.info("è¨­å®šã®äº’æ›æ€§æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return True

        except Exception as e:
            logger.error(f"è¨­å®šäº’æ›æ€§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _migrate_existing_settings(self) -> Dict[str, Any]:
        """
        æ—¢å­˜è¨­å®šã®ç§»è¡Œï¼ˆTechnicalIndicatorsAnalyzerçµ±åˆï¼‰

        Returns:
            Dict[str, Any]: ç§»è¡Œã•ã‚ŒãŸè¨­å®š
        """
        try:
            migrated_settings = {}

            # æ—¢å­˜ã®è¨­å®šã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            original_config = self.indicators_config.copy()

            # æ–°ã—ã„è¨­å®šã‚’é©ç”¨
            self._apply_optimized_settings()

            # ç§»è¡Œçµæœã‚’è¨˜éŒ²
            migrated_settings = {
                "original_config": original_config,
                "new_config": self.indicators_config,
                "migration_time": datetime.now().isoformat(),
                "compatibility": self._validate_settings_compatibility(),
            }

            logger.info("æ—¢å­˜è¨­å®šã®ç§»è¡ŒãŒå®Œäº†ã—ã¾ã—ãŸ")
            return migrated_settings

        except Exception as e:
            logger.error(f"è¨­å®šç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_rsi_state_advanced(self, rsi_value: float) -> Dict[str, Any]:
        """RSIé«˜åº¦çŠ¶æ…‹åˆ†æ"""
        if rsi_value >= 80:
            return {"state": "extremely_overbought", "confidence": "high"}
        elif rsi_value >= 70:
            return {"state": "overbought", "confidence": "high"}
        elif rsi_value >= 60:
            return {"state": "bullish", "confidence": "medium"}
        elif rsi_value >= 40:
            return {"state": "neutral", "confidence": "medium"}
        elif rsi_value >= 30:
            return {"state": "bearish", "confidence": "medium"}
        elif rsi_value >= 20:
            return {"state": "oversold", "confidence": "high"}
        else:
            return {"state": "extremely_oversold", "confidence": "high"}

    def _analyze_macd_state_advanced(self, values: np.ndarray) -> Dict[str, Any]:
        """MACDé«˜åº¦çŠ¶æ…‹åˆ†æ"""
        if len(values) < 3:
            return {"state": "unknown", "confidence": "low"}

        current = values[-1] if not np.isnan(values[-1]) else None
        previous = values[-2] if not np.isnan(values[-2]) else None

        if current is None or previous is None:
            return {"state": "unknown", "confidence": "low"}

        if current > 0 and current > previous:
            return {"state": "strong_bullish", "confidence": "high"}
        elif current > 0 and current < previous:
            return {"state": "weakening_bullish", "confidence": "medium"}
        elif current < 0 and current < previous:
            return {"state": "strong_bearish", "confidence": "high"}
        elif current < 0 and current > previous:
            return {"state": "weakening_bearish", "confidence": "medium"}
        else:
            return {"state": "neutral", "confidence": "medium"}

    def _analyze_bb_state_advanced(self, values: np.ndarray) -> Dict[str, Any]:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰é«˜åº¦çŠ¶æ…‹åˆ†æ"""
        if len(values) < 20:
            return {"state": "unknown", "confidence": "low"}

        # ç°¡æ˜“çš„ãªãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ
        recent_values = values[-20:]
        volatility = np.std(recent_values[~np.isnan(recent_values)])

        if volatility > 2.0:
            return {"state": "high_volatility", "confidence": "high"}
        elif volatility > 1.0:
            return {"state": "medium_volatility", "confidence": "medium"}
        else:
            return {"state": "low_volatility", "confidence": "medium"}

    def _analyze_stoch_state_advanced(self, values: np.ndarray) -> Dict[str, Any]:
        """ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹é«˜åº¦çŠ¶æ…‹åˆ†æ"""
        if len(values) < 5:
            return {"state": "unknown", "confidence": "low"}

        recent_values = values[-5:]
        avg_value = np.nanmean(recent_values)

        if avg_value >= 80:
            return {"state": "overbought", "confidence": "high"}
        elif avg_value <= 20:
            return {"state": "oversold", "confidence": "high"}
        elif avg_value >= 60:
            return {"state": "bullish", "confidence": "medium"}
        elif avg_value <= 40:
            return {"state": "bearish", "confidence": "medium"}
        else:
            return {"state": "neutral", "confidence": "medium"}

    def _analyze_atr_state_advanced(self, values: np.ndarray) -> Dict[str, Any]:
        """ATRé«˜åº¦çŠ¶æ…‹åˆ†æ"""
        if len(values) < 10:
            return {"state": "unknown", "confidence": "low"}

        recent_values = values[-10:]
        avg_atr = np.nanmean(recent_values)
        current_atr = values[-1] if not np.isnan(values[-1]) else avg_atr

        if current_atr > avg_atr * 1.5:
            return {"state": "high_volatility", "confidence": "high"}
        elif current_atr < avg_atr * 0.5:
            return {"state": "low_volatility", "confidence": "high"}
        else:
            return {"state": "normal_volatility", "confidence": "medium"}

    def _generate_rsi_signals(self, indicator_data: Dict[str, Any]) -> Dict[str, Any]:
        """RSIã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        state = indicator_data.get("state", "unknown")
        value = indicator_data.get("value", 50)

        if state == "extremely_overbought":
            return {
                "primary_signal": "sell",
                "secondary_signal": "strong_sell",
                "confidence": "high",
            }
        elif state == "overbought":
            return {
                "primary_signal": "sell",
                "secondary_signal": "hold",
                "confidence": "medium",
            }
        elif state == "extremely_oversold":
            return {
                "primary_signal": "buy",
                "secondary_signal": "strong_buy",
                "confidence": "high",
            }
        elif state == "oversold":
            return {
                "primary_signal": "buy",
                "secondary_signal": "hold",
                "confidence": "medium",
            }
        else:
            return {
                "primary_signal": "hold",
                "secondary_signal": "hold",
                "confidence": "low",
            }

    def _generate_macd_signals(self, indicator_data: Dict[str, Any]) -> Dict[str, Any]:
        """MACDã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        state = indicator_data.get("state", "unknown")
        trend = indicator_data.get("trend", "unknown")

        if state == "strong_bullish" and trend == "rising":
            return {
                "primary_signal": "buy",
                "secondary_signal": "strong_buy",
                "confidence": "high",
            }
        elif state == "strong_bearish" and trend == "falling":
            return {
                "primary_signal": "sell",
                "secondary_signal": "strong_sell",
                "confidence": "high",
            }
        elif state == "weakening_bullish":
            return {
                "primary_signal": "hold",
                "secondary_signal": "sell",
                "confidence": "medium",
            }
        elif state == "weakening_bearish":
            return {
                "primary_signal": "hold",
                "secondary_signal": "buy",
                "confidence": "medium",
            }
        else:
            return {
                "primary_signal": "hold",
                "secondary_signal": "hold",
                "confidence": "low",
            }

    def _generate_bb_signals(self, indicator_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        state = indicator_data.get("state", "unknown")

        if state == "high_volatility":
            return {
                "primary_signal": "hold",
                "secondary_signal": "caution",
                "confidence": "medium",
            }
        elif state == "low_volatility":
            return {
                "primary_signal": "hold",
                "secondary_signal": "breakout_watch",
                "confidence": "medium",
            }
        else:
            return {
                "primary_signal": "hold",
                "secondary_signal": "hold",
                "confidence": "low",
            }

    def _generate_stoch_signals(self, indicator_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¹ãƒˆã‚­ãƒ£ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        state = indicator_data.get("state", "unknown")

        if state == "overbought":
            return {
                "primary_signal": "sell",
                "secondary_signal": "hold",
                "confidence": "medium",
            }
        elif state == "oversold":
            return {
                "primary_signal": "buy",
                "secondary_signal": "hold",
                "confidence": "medium",
            }
        else:
            return {
                "primary_signal": "hold",
                "secondary_signal": "hold",
                "confidence": "low",
            }

    def _detect_divergence_advanced(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é«˜åº¦ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹æ¤œå‡º"""
        # å®Ÿè£…äºˆå®š
        return {"divergence_type": "none", "confidence": "low"}

    def _analyze_momentum_advanced(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é«˜åº¦ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ åˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"momentum": "neutral", "strength": "medium"}

    def _analyze_volatility_advanced(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é«˜åº¦ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"volatility": "normal", "trend": "stable"}

    def _analyze_support_resistance_advanced(
        self, indicator_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é«˜åº¦ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ"""
        # å®Ÿè£…äºˆå®š
        return {"support": None, "resistance": None, "confidence": "low"}

    def start_analysis_progress(self, analysis_type: str, total_steps: int):
        """
        åˆ†ææ©Ÿèƒ½ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹é–‹å§‹ï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Args:
            analysis_type: åˆ†æã‚¿ã‚¤ãƒ—
            total_steps: ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°

        Returns:
            tqdm.auto.tqdm: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        try:
            from tqdm.auto import tqdm

            if not self.progress_config["enable_progress"]:
                return None

            pbar = tqdm(
                total=total_steps,
                desc=f"ğŸ” {analysis_type} åˆ†æä¸­...",
                unit="ã‚¹ãƒ†ãƒƒãƒ—",
                **self.progress_config["tqdm_config"],
            )

            return pbar

        except Exception as e:
            logger.error(f"åˆ†æãƒ—ãƒ­ã‚°ãƒ¬ã‚¹é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def update_analysis_progress(self, progress_id, step: str, details: Dict[str, Any]):
        """
        åˆ†æãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Args:
            progress_id: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ID
            step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
            details: è©³ç´°æƒ…å ±
        """
        try:
            if not self.progress_config["enable_progress"] or progress_id is None:
                return

            # è©³ç´°æƒ…å ±ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
            detail_str = ""
            if details:
                detail_items = []
                for key, value in details.items():
                    if isinstance(value, float):
                        detail_items.append(f"{key}: {value:.2f}")
                    else:
                        detail_items.append(f"{key}: {value}")
                detail_str = f" ({', '.join(detail_items)})"

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
            progress_id.set_description(f"ğŸ” {step}{detail_str}")
            progress_id.update(1)

        except Exception as e:
            logger.error(f"åˆ†æãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def show_performance_info(self, performance_data: Dict[str, Any]):
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±è¡¨ç¤ºï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Args:
            performance_data: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
        """
        try:
            if not self.progress_config["enable_progress"]:
                return

            print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±:")
            print(f"   â±ï¸ å‡¦ç†æ™‚é–“: {performance_data.get('processing_time', 'N/A')}")
            print(f"   ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {performance_data.get('memory_usage', 'N/A')}")
            print(f"   ğŸš€ å‡¦ç†é€Ÿåº¦: {performance_data.get('processing_speed', 'N/A')}")
            print(f"   ğŸ“ˆ æˆåŠŸç‡: {performance_data.get('success_rate', 'N/A')}%")

        except Exception as e:
            logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")

    def show_error_details(self, error_info: Dict[str, Any]):
        """
        ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤ºï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Args:
            error_info: ã‚¨ãƒ©ãƒ¼æƒ…å ±
        """
        try:
            if not self.progress_config["enable_progress"]:
                return

            print("âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
            print(f"   ğŸ” ã‚¨ãƒ©ãƒ¼ç®‡æ‰€: {error_info.get('location', 'N/A')}")
            print(f"   ğŸ“ ã‚¨ãƒ©ãƒ¼å†…å®¹: {error_info.get('message', 'N/A')}")
            print(f"   ğŸ› ï¸ ãƒªã‚«ãƒãƒªãƒ¼æƒ…å ±: {error_info.get('recovery_info', 'N/A')}")

        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")

    def _create_detailed_progress_manager(self):
        """
        è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†ä½œæˆï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Returns:
            Dict[str, Any]: è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        try:
            from tqdm.auto import tqdm

            progress_manager = {
                "enable_progress": self.progress_config["enable_progress"],
                "tqdm_config": self.progress_config["tqdm_config"],
                "progress_bars": {},
                "performance_data": {},
                "error_data": {},
            }

            return progress_manager

        except Exception as e:
            logger.error(f"è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _update_detailed_progress(
        self,
        progress_manager: Dict[str, Any],
        progress_type: str,
        step: str,
        details: Dict[str, Any] = None,
    ):
        """
        è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ï¼ˆtqdmè©³ç´°åŒ–ï¼‰

        Args:
            progress_manager: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            progress_type: ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚¿ã‚¤ãƒ—
            step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
            details: è©³ç´°æƒ…å ±
        """
        try:
            if not progress_manager or not progress_manager["enable_progress"]:
                return

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
            if details and "processing_time" in details:
                progress_manager["performance_data"][progress_type] = details

            # ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
            if details and "error" in details:
                progress_manager["error_data"][progress_type] = details

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
            if progress_type in progress_manager["progress_bars"]:
                pbar = progress_manager["progress_bars"][progress_type]
                self.update_analysis_progress(pbar, step, details or {})

        except Exception as e:
            logger.error(f"è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    async def migrate_existing_data(self, progress_callback=None) -> Dict[str, Any]:
        """
        æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œ

        Args:
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°

        Returns:
            Dict[str, Any]: ç§»è¡Œçµæœ
        """
        try:
            migration_result = {
                "total_records": 0,
                "migrated_records": 0,
                "failed_records": 0,
                "migration_time": None,
                "errors": [],
            }

            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
            analysis_result = await self._analyze_existing_data()
            total_records = analysis_result.get("total_records", 0)
            migration_result["total_records"] = total_records

            if total_records == 0:
                logger.info("ç§»è¡Œå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return migration_result

            # ç§»è¡Œé–‹å§‹æ™‚åˆ»
            start_time = datetime.now()
            migration_result["migration_time"] = start_time.isoformat()

            logger.info(f"ãƒ‡ãƒ¼ã‚¿ç§»è¡Œé–‹å§‹: {total_records}ä»¶")

            # ãƒãƒƒãƒã‚µã‚¤ã‚º
            batch_size = 100
            migrated_count = 0
            failed_count = 0

            # å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
            query = select(TechnicalIndicatorModel).order_by(TechnicalIndicatorModel.id)
            result = await self.session.execute(query)
            all_records = result.scalars().all()

            # ãƒãƒƒãƒå‡¦ç†
            for i in range(0, len(all_records), batch_size):
                batch_records = all_records[i : i + batch_size]

                # é€²æ—æ›´æ–°
                if progress_callback:
                    progress = (i / len(all_records)) * 100
                    progress_callback(
                        progress,
                        f"ãƒãƒƒãƒå‡¦ç†ä¸­: {i+1}-{min(i+batch_size, len(all_records))}",
                    )

                # ãƒãƒƒãƒå†…ã®å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†
                for record in batch_records:
                    try:
                        # çµ±åˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¤‰æ›
                        unified_data = await self._convert_to_unified_format(record)

                        # çµ±åˆãƒ‡ãƒ¼ã‚¿ä¿å­˜
                        if await self._save_unified_indicator_optimized(unified_data):
                            migrated_count += 1
                        else:
                            failed_count += 1
                            migration_result["errors"].append(
                                f"ãƒ¬ã‚³ãƒ¼ãƒ‰ID {record.id}: ä¿å­˜å¤±æ•—"
                            )

                    except Exception as e:
                        failed_count += 1
                        error_msg = f"ãƒ¬ã‚³ãƒ¼ãƒ‰ID {record.id}: {str(e)}"
                        migration_result["errors"].append(error_msg)
                        logger.error(error_msg)

            # ç§»è¡Œçµæœã‚’æ›´æ–°
            migration_result["migrated_records"] = migrated_count
            migration_result["failed_records"] = failed_count

            # ç§»è¡Œå®Œäº†æ™‚åˆ»
            end_time = datetime.now()
            migration_duration = (end_time - start_time).total_seconds()

            logger.info(
                f"ãƒ‡ãƒ¼ã‚¿ç§»è¡Œå®Œäº†: {migrated_count}ä»¶æˆåŠŸ, {failed_count}ä»¶å¤±æ•—, æ‰€è¦æ™‚é–“: {migration_duration:.2f}ç§’"
            )

            return migration_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def validate_migration_results(self) -> bool:
        """
        ç§»è¡Œçµæœã®æ¤œè¨¼

        Returns:
            bool: æ¤œè¨¼æˆåŠŸæ™‚True
        """
        try:
            # ç§»è¡Œå‰å¾Œã®ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒ
            before_analysis = await self._analyze_existing_data()
            after_analysis = await self._analyze_existing_data()

            # ãƒ‡ãƒ¼ã‚¿é‡ã®ç¢ºèª
            if after_analysis.get("total_records", 0) < before_analysis.get(
                "total_records", 0
            ):
                logger.warning("ç§»è¡Œå¾Œã«ãƒ‡ãƒ¼ã‚¿é‡ãŒæ¸›å°‘ã—ã¾ã—ãŸ")
                return False

            # ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª
            before_quality = before_analysis.get("data_quality", {})
            after_quality = after_analysis.get("data_quality", {})

            # NULLå€¤ã®ç¢ºèª
            if after_quality.get("null_values", 0) > before_quality.get(
                "null_values", 0
            ):
                logger.warning("ç§»è¡Œå¾Œã«NULLå€¤ãŒå¢—åŠ ã—ã¾ã—ãŸ")
                return False

            # ç„¡åŠ¹ãªå€¤ã®ç¢ºèª
            if after_quality.get("invalid_values", 0) > before_quality.get(
                "invalid_values", 0
            ):
                logger.warning("ç§»è¡Œå¾Œã«ç„¡åŠ¹ãªå€¤ãŒå¢—åŠ ã—ã¾ã—ãŸ")
                return False

            logger.info("ç§»è¡Œçµæœã®æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ")
            return True

        except Exception as e:
            logger.error(f"ç§»è¡Œçµæœæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def rollback_migration(self) -> bool:
        """
        ç§»è¡Œã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

        Returns:
            bool: ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸæ™‚True
        """
        try:
            logger.info("ç§»è¡Œã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’é–‹å§‹ã—ã¾ã™")

            # ç§»è¡Œå¾Œã«ä½œæˆã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤
            # æ³¨æ„: ã“ã®å®Ÿè£…ã¯ç°¡æ˜“ç‰ˆã§ã™ã€‚å®Ÿéš›ã®é‹ç”¨ã§ã¯ã‚ˆã‚Šæ…é‡ãªãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå¿…è¦ã§ã™

            # æœ€æ–°ã®ç§»è¡Œãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã™ã‚‹ã‚¯ã‚¨ãƒª
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ç§»è¡Œå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™

            logger.warning("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™ã€‚æ‰‹å‹•ã§ã®å¾©å…ƒãŒå¿…è¦ã§ã™")
            return False

        except Exception as e:
            logger.error(f"ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def generate_migration_report(self) -> Dict[str, Any]:
        """
        ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ

        Returns:
            Dict[str, Any]: ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
            analysis_result = await self._analyze_existing_data()

            # ç§»è¡Œå®Ÿè¡Œ
            migration_result = await self.migrate_existing_data()

            # ç§»è¡Œçµæœã®æ¤œè¨¼
            validation_result = await self.validate_migration_results()

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = {
                "report_type": "ãƒ‡ãƒ¼ã‚¿ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆ",
                "generated_at": datetime.now().isoformat(),
                "analysis_before": analysis_result,
                "migration_result": migration_result,
                "validation_result": validation_result,
                "summary": {
                    "total_records": migration_result.get("total_records", 0),
                    "migrated_records": migration_result.get("migrated_records", 0),
                    "failed_records": migration_result.get("failed_records", 0),
                    "success_rate": 0,
                },
            }

            # æˆåŠŸç‡ã®è¨ˆç®—
            total = report["summary"]["total_records"]
            migrated = report["summary"]["migrated_records"]
            if total > 0:
                report["summary"]["success_rate"] = (migrated / total) * 100

            logger.info(
                f"ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: æˆåŠŸç‡ {report['summary']['success_rate']:.1f}%"
            )
            return report

        except Exception as e:
            logger.error(f"ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _convert_to_unified_format(
        self, record: TechnicalIndicatorModel
    ) -> Dict[str, Any]:
        """
        æ—¢å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆå½¢å¼ã«å¤‰æ›

        Args:
            record: æ—¢å­˜ã®TechnicalIndicatorModel

        Returns:
            Dict[str, Any]: çµ±åˆå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿
        """
        try:
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
            unified_data = {
                "indicator_type": record.indicator_type,
                "timeframe": record.timeframe,
                "value": float(record.value),
                "timestamp": record.timestamp,
                "parameters": record.parameters or {},
            }

            # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ
            if record.additional_data:
                unified_data["additional_data"] = record.additional_data
            else:
                # è¿½åŠ ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯åŸºæœ¬çš„ãªæ§‹é€ ã‚’ä½œæˆ
                unified_data["additional_data"] = {
                    "original_record_id": record.id,
                    "migration_timestamp": datetime.now().isoformat(),
                    "data_source": "legacy",
                }

            return unified_data

        except Exception as e:
            logger.error(f"çµ±åˆå½¢å¼å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def validate_data_integrity(self) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼

        Returns:
            Dict[str, Any]: æ•´åˆæ€§æ¤œè¨¼çµæœ
        """
        try:
            integrity_result = {
                "overall_status": "unknown",
                "validation_rules": {},
                "issues_found": [],
                "recommendations": [],
                "validation_time": datetime.now().isoformat(),
            }

            # ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
            type_validation = await self._validate_data_types()
            integrity_result["validation_rules"]["data_types"] = type_validation

            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            range_validation = await self._validate_data_ranges()
            integrity_result["validation_rules"]["data_ranges"] = range_validation

            # é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯
            relationship_validation = await self._validate_data_relationships()
            integrity_result["validation_rules"][
                "relationships"
            ] = relationship_validation

            # ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
            consistency_validation = await self._validate_data_consistency()
            integrity_result["validation_rules"]["consistency"] = consistency_validation

            # å•é¡Œã®é›†è¨ˆ
            total_issues = 0
            for rule_name, rule_result in integrity_result["validation_rules"].items():
                if rule_result.get("status") == "failed":
                    total_issues += rule_result.get("issue_count", 0)
                    integrity_result["issues_found"].extend(
                        rule_result.get("issues", [])
                    )

            # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ±ºå®š
            if total_issues == 0:
                integrity_result["overall_status"] = "passed"
            elif total_issues < 10:
                integrity_result["overall_status"] = "warning"
            else:
                integrity_result["overall_status"] = "failed"

            # æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
            integrity_result["recommendations"] = (
                await self._generate_integrity_recommendations(integrity_result)
            )

            logger.info(
                f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼å®Œäº†: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={integrity_result['overall_status']}, å•é¡Œæ•°={total_issues}"
            )
            return integrity_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def monitor_data_quality(self) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–

        Returns:
            Dict[str, Any]: å“è³ªç›£è¦–çµæœ
        """
        try:
            quality_result = {
                "monitoring_time": datetime.now().isoformat(),
                "quality_metrics": {},
                "alerts": [],
                "trends": {},
            }

            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
            realtime_metrics = await self._get_realtime_quality_metrics()
            quality_result["quality_metrics"]["realtime"] = realtime_metrics

            # å®šæœŸãƒã‚§ãƒƒã‚¯
            periodic_metrics = await self._get_periodic_quality_metrics()
            quality_result["quality_metrics"]["periodic"] = periodic_metrics

            # ç•°å¸¸æ¤œå‡º
            anomalies = await self._detect_quality_anomalies(
                realtime_metrics, periodic_metrics
            )
            quality_result["alerts"] = anomalies

            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trends = await self._analyze_quality_trends()
            quality_result["trends"] = trends

            logger.info(f"ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–å®Œäº†: ã‚¢ãƒ©ãƒ¼ãƒˆæ•°={len(anomalies)}")
            return quality_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def auto_repair_data(self, issues: List[Dict[str, Any]]) -> int:
        """
        ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•ä¿®å¾©

        Args:
            issues: ä¿®å¾©å¯¾è±¡ã®å•é¡Œãƒªã‚¹ãƒˆ

        Returns:
            int: ä¿®å¾©æˆåŠŸä»¶æ•°
        """
        try:
            repaired_count = 0

            for issue in issues:
                try:
                    issue_type = issue.get("type")
                    issue_data = issue.get("data", {})

                    if issue_type == "null_value":
                        success = await self._repair_null_value(issue_data)
                    elif issue_type == "invalid_range":
                        success = await self._repair_invalid_range(issue_data)
                    elif issue_type == "duplicate_record":
                        success = await self._repair_duplicate_record(issue_data)
                    elif issue_type == "missing_additional_data":
                        success = await self._repair_missing_additional_data(issue_data)
                    else:
                        logger.warning(f"æœªçŸ¥ã®å•é¡Œã‚¿ã‚¤ãƒ—: {issue_type}")
                        continue

                    if success:
                        repaired_count += 1
                        logger.info(f"ä¿®å¾©æˆåŠŸ: {issue_type}")

                except Exception as e:
                    logger.error(f"ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {issue_type} - {e}")

            logger.info(f"è‡ªå‹•ä¿®å¾©å®Œäº†: {repaired_count}ä»¶æˆåŠŸ")
            return repaired_count

        except Exception as e:
            logger.error(f"è‡ªå‹•ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    async def generate_integrity_report(self) -> Dict[str, Any]:
        """
        æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ

        Returns:
            Dict[str, Any]: æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            # æ•´åˆæ€§æ¤œè¨¼å®Ÿè¡Œ
            integrity_result = await self.validate_data_integrity()

            # å“è³ªç›£è¦–å®Ÿè¡Œ
            quality_result = await self.monitor_data_quality()

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = {
                "report_type": "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆ",
                "generated_at": datetime.now().isoformat(),
                "integrity_validation": integrity_result,
                "quality_monitoring": quality_result,
                "summary": {
                    "overall_status": integrity_result.get("overall_status", "unknown"),
                    "total_issues": len(integrity_result.get("issues_found", [])),
                    "total_alerts": len(quality_result.get("alerts", [])),
                    "recommendations": integrity_result.get("recommendations", []),
                },
            }

            logger.info(
                f"æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹={report['summary']['overall_status']}"
            )
            return report

        except Exception as e:
            logger.error(f"æ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def send_integrity_alert(self, alert_data: Dict[str, Any]) -> bool:
        """
        æ•´åˆæ€§ã‚¢ãƒ©ãƒ¼ãƒˆã®é€ä¿¡

        Args:
            alert_data: ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿

        Returns:
            bool: é€ä¿¡æˆåŠŸæ™‚True
        """
        try:
            # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š
            alert_level = alert_data.get("level", "info")
            alert_message = alert_data.get("message", "")

            if alert_level == "critical":
                logger.critical(f"ğŸš¨ é‡å¤§ãªæ•´åˆæ€§å•é¡Œ: {alert_message}")
            elif alert_level == "warning":
                logger.warning(f"âš ï¸ æ•´åˆæ€§è­¦å‘Š: {alert_message}")
            else:
                logger.info(f"â„¹ï¸ æ•´åˆæ€§æƒ…å ±: {alert_message}")

            # å®Ÿéš›ã®é‹ç”¨ã§ã¯ã€Discordé€šçŸ¥ã‚„ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãªã©ã‚’å®Ÿè£…
            # ã“ã“ã§ã¯ãƒ­ã‚°å‡ºåŠ›ã®ã¿

            return True

        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _validate_data_types(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯"""
        try:
            validation_result = {"status": "passed", "issue_count": 0, "issues": []}

            # æ–‡å­—åˆ—ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            string_fields = ["indicator_type", "timeframe", "currency_pair"]
            for field in string_fields:
                query = select(func.count(TechnicalIndicatorModel.id)).where(
                    getattr(TechnicalIndicatorModel, field).is_(None)
                )
                result = await self.session.execute(query)
                null_count = result.scalar()

                if null_count > 0:
                    validation_result["status"] = "failed"
                    validation_result["issue_count"] += null_count
                    validation_result["issues"].append(
                        f"{field}ã«NULLå€¤ãŒ{null_count}ä»¶ã‚ã‚Šã¾ã™"
                    )

            # æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.value.is_(None)
            )
            result = await self.session.execute(query)
            null_count = result.scalar()

            if null_count > 0:
                validation_result["status"] = "failed"
                validation_result["issue_count"] += null_count
                validation_result["issues"].append(
                    f"valueã«NULLå€¤ãŒ{null_count}ä»¶ã‚ã‚Šã¾ã™"
                )

            return validation_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "issue_count": 0, "issues": [str(e)]}

    async def _validate_data_ranges(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ç¯„å›²ãƒã‚§ãƒƒã‚¯"""
        try:
            validation_result = {"status": "passed", "issue_count": 0, "issues": []}

            # RSIå€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ0-100ï¼‰
            rsi_query = select(func.count(TechnicalIndicatorModel.id)).where(
                and_(
                    TechnicalIndicatorModel.indicator_type == "RSI",
                    or_(
                        TechnicalIndicatorModel.value < 0,
                        TechnicalIndicatorModel.value > 100,
                    ),
                )
            )
            result = await self.session.execute(rsi_query)
            invalid_rsi_count = result.scalar()

            if invalid_rsi_count > 0:
                validation_result["status"] = "failed"
                validation_result["issue_count"] += invalid_rsi_count
                validation_result["issues"].append(
                    f"RSIå€¤ãŒç¯„å›²å¤–ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ{invalid_rsi_count}ä»¶ã‚ã‚Šã¾ã™"
                )

            # è² ã®å€¤ã®ãƒã‚§ãƒƒã‚¯ï¼ˆä¸€éƒ¨ã®æŒ‡æ¨™ã‚’é™¤ãï¼‰
            negative_query = select(func.count(TechnicalIndicatorModel.id)).where(
                and_(
                    TechnicalIndicatorModel.value < 0,
                    TechnicalIndicatorModel.indicator_type.in_(["RSI", "STOCH"]),
                )
            )
            result = await self.session.execute(negative_query)
            negative_count = result.scalar()

            if negative_count > 0:
                validation_result["status"] = "failed"
                validation_result["issue_count"] += negative_count
                validation_result["issues"].append(
                    f"è² ã®å€¤ãŒä¸é©åˆ‡ãªãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ{negative_count}ä»¶ã‚ã‚Šã¾ã™"
                )

            return validation_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ç¯„å›²ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "issue_count": 0, "issues": [str(e)]}

    async def _validate_data_relationships(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            validation_result = {"status": "passed", "issue_count": 0, "issues": []}

            # é€šè²¨ãƒšã‚¢ã¨æ™‚é–“è¶³ã®çµ„ã¿åˆã‚ã›ãƒã‚§ãƒƒã‚¯
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè©³ç´°ãªé–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 

            return validation_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "issue_count": 0, "issues": [str(e)]}

    async def _validate_data_consistency(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            validation_result = {"status": "passed", "issue_count": 0, "issues": []}

            # é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            duplicate_query = (
                select(
                    TechnicalIndicatorModel.currency_pair,
                    TechnicalIndicatorModel.timestamp,
                    TechnicalIndicatorModel.indicator_type,
                    TechnicalIndicatorModel.timeframe,
                    func.count(TechnicalIndicatorModel.id),
                )
                .group_by(
                    TechnicalIndicatorModel.currency_pair,
                    TechnicalIndicatorModel.timestamp,
                    TechnicalIndicatorModel.indicator_type,
                    TechnicalIndicatorModel.timeframe,
                )
                .having(func.count(TechnicalIndicatorModel.id) > 1)
            )

            result = await self.session.execute(duplicate_query)
            duplicates = result.fetchall()

            if duplicates:
                validation_result["status"] = "failed"
                validation_result["issue_count"] += len(duplicates)
                validation_result["issues"].append(
                    f"é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ{len(duplicates)}ä»¶ã‚ã‚Šã¾ã™"
                )

            return validation_result

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "issue_count": 0, "issues": [str(e)]}

    async def _get_realtime_quality_metrics(self) -> Dict[str, Any]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        try:
            metrics = {
                "total_records": 0,
                "null_values": 0,
                "invalid_values": 0,
                "duplicate_records": 0,
            }

            # å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
            total_query = select(func.count(TechnicalIndicatorModel.id))
            result = await self.session.execute(total_query)
            metrics["total_records"] = result.scalar()

            # NULLå€¤ã®æ•°
            null_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.value.is_(None)
            )
            result = await self.session.execute(null_query)
            metrics["null_values"] = result.scalar()

            # ç„¡åŠ¹ãªå€¤ã®æ•°
            invalid_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.value <= 0
            )
            result = await self.session.execute(invalid_query)
            metrics["invalid_values"] = result.scalar()

            return metrics

        except Exception as e:
            logger.error(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def _get_periodic_quality_metrics(self) -> Dict[str, Any]:
        """å®šæœŸå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        try:
            # éå»24æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’åˆ†æ
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=24)

            metrics = {"period": "24h", "records_added": 0, "quality_score": 0.0}

            # éå»24æ™‚é–“ã«è¿½åŠ ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
            added_query = select(func.count(TechnicalIndicatorModel.id)).where(
                TechnicalIndicatorModel.created_at >= start_time
            )
            result = await self.session.execute(added_query)
            metrics["records_added"] = result.scalar()

            # å“è³ªã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            total_records = metrics["records_added"]
            if total_records > 0:
                # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè©³ç´°ãªå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ã‚’å®Ÿè£…
                metrics["quality_score"] = 95.0  # ä»®ã®å€¤

            return metrics

        except Exception as e:
            logger.error(f"å®šæœŸå“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def _detect_quality_anomalies(
        self, realtime_metrics: Dict[str, Any], periodic_metrics: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """å“è³ªç•°å¸¸ã®æ¤œå‡º"""
        try:
            anomalies = []

            # NULLå€¤ã®ç•°å¸¸æ¤œå‡º
            null_ratio = realtime_metrics.get("null_values", 0) / max(
                realtime_metrics.get("total_records", 1), 1
            )
            if null_ratio > 0.1:  # 10%ä»¥ä¸Š
                anomalies.append(
                    {
                        "type": "high_null_ratio",
                        "level": "warning",
                        "message": f"NULLå€¤ã®æ¯”ç‡ãŒé«˜ã„ã§ã™: {null_ratio:.1%}",
                        "data": {"null_ratio": null_ratio},
                    }
                )

            # ç„¡åŠ¹ãªå€¤ã®ç•°å¸¸æ¤œå‡º
            invalid_ratio = realtime_metrics.get("invalid_values", 0) / max(
                realtime_metrics.get("total_records", 1), 1
            )
            if invalid_ratio > 0.05:  # 5%ä»¥ä¸Š
                anomalies.append(
                    {
                        "type": "high_invalid_ratio",
                        "level": "critical",
                        "message": f"ç„¡åŠ¹ãªå€¤ã®æ¯”ç‡ãŒé«˜ã„ã§ã™: {invalid_ratio:.1%}",
                        "data": {"invalid_ratio": invalid_ratio},
                    }
                )

            return anomalies

        except Exception as e:
            logger.error(f"å“è³ªç•°å¸¸æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def _analyze_quality_trends(self) -> Dict[str, Any]:
        """å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        try:
            trends = {
                "data_growth": "stable",
                "quality_trend": "stable",
                "recommendations": [],
            }

            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè£…

            return trends

        except Exception as e:
            logger.error(f"å“è³ªãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def _generate_integrity_recommendations(
        self, integrity_result: Dict[str, Any]
    ) -> List[str]:
        """æ•´åˆæ€§æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        try:
            recommendations = []

            overall_status = integrity_result.get("overall_status", "unknown")
            issues_found = integrity_result.get("issues_found", [])

            if overall_status == "failed":
                recommendations.append(
                    "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å³åº§ã«å¯¾å‡¦ãŒå¿…è¦ã§ã™ã€‚"
                )
            elif overall_status == "warning":
                recommendations.append(
                    "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã«è»½å¾®ãªå•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ç›£è¦–ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚"
                )

            if len(issues_found) > 0:
                recommendations.append(f"æ¤œå‡ºã•ã‚ŒãŸå•é¡Œæ•°: {len(issues_found)}ä»¶")

            return recommendations

        except Exception as e:
            logger.error(f"æ•´åˆæ€§æ¨å¥¨äº‹é …ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ["æ¨å¥¨äº‹é …ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"]

    async def _repair_null_value(self, issue_data: Dict[str, Any]) -> bool:
        """NULLå€¤ã®ä¿®å¾©"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€é©åˆ‡ãªå€¤ã§NULLã‚’ç½®æ›
            logger.info("NULLå€¤ä¿®å¾©æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
            return False
        except Exception as e:
            logger.error(f"NULLå€¤ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _repair_invalid_range(self, issue_data: Dict[str, Any]) -> bool:
        """ç„¡åŠ¹ç¯„å›²å€¤ã®ä¿®å¾©"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€é©åˆ‡ãªç¯„å›²å†…ã®å€¤ã«ä¿®æ­£
            logger.info("ç„¡åŠ¹ç¯„å›²å€¤ä¿®å¾©æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
            return False
        except Exception as e:
            logger.error(f"ç„¡åŠ¹ç¯„å›²å€¤ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _repair_duplicate_record(self, issue_data: Dict[str, Any]) -> bool:
        """é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ä¿®å¾©"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å‰Šé™¤ã¾ãŸã¯çµ±åˆ
            logger.info("é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ä¿®å¾©æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
            return False
        except Exception as e:
            logger.error(f"é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _repair_missing_additional_data(self, issue_data: Dict[str, Any]) -> bool:
        """ä¸è¶³è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã®ä¿®å¾©"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ä¸è¶³ã—ã¦ã„ã‚‹è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            logger.info("ä¸è¶³è¿½åŠ ãƒ‡ãƒ¼ã‚¿ä¿®å¾©æ©Ÿèƒ½ã¯å®Ÿè£…ä¸­ã§ã™")
            return False
        except Exception as e:
            logger.error(f"ä¸è¶³è¿½åŠ ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    # ==================== å·®åˆ†æ¤œçŸ¥æ©Ÿèƒ½çµ±åˆ ====================

    async def calculate_with_diff_detection(
        self, limit: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        å·®åˆ†æ¤œçŸ¥ä»˜ããƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—

        Args:
            limit: å„æ™‚é–“è¶³ã®å‡¦ç†ä»¶æ•°åˆ¶é™

        Returns:
            Dict[str, Any]: è¨ˆç®—çµæœã®è©³ç´°
        """
        try:
            logger.info("ğŸ”„ å·®åˆ†æ¤œçŸ¥ä»˜ããƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™è¨ˆç®—é–‹å§‹...")

            # TechnicalIndicatorDiffCalculatorã‚’ä½¿ç”¨
            from src.application.services.technical_indicator_diff_calculator import (
                TechnicalIndicatorDiffCalculator,
            )

            diff_calculator = TechnicalIndicatorDiffCalculator(self.currency_pair)
            await diff_calculator.initialize()

            try:
                result = await diff_calculator.calculate_differential_indicators(limit)
                return result
            finally:
                await diff_calculator.cleanup()

        except Exception as e:
            logger.error(f"âŒ å·®åˆ†æ¤œçŸ¥ä»˜ãè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "error": str(e)}

    async def calculate_for_uncalculated_data(
        self, timeframe: str, limit: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        æœªè¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å¯¾è±¡ã¨ã—ãŸè¨ˆç®—

        Args:
            timeframe: æ™‚é–“è¶³
            limit: å‡¦ç†ä»¶æ•°åˆ¶é™

        Returns:
            Dict[str, Any]: è¨ˆç®—çµæœ
        """
        try:
            logger.info(f"ğŸ”„ {timeframe}ã®æœªè¨ˆç®—ãƒ‡ãƒ¼ã‚¿è¨ˆç®—é–‹å§‹...")

            # TechnicalIndicatorDiffCalculatorã‚’ä½¿ç”¨
            from src.application.services.technical_indicator_diff_calculator import (
                TechnicalIndicatorDiffCalculator,
            )

            diff_calculator = TechnicalIndicatorDiffCalculator(self.currency_pair)
            await diff_calculator.initialize()

            try:
                result = await diff_calculator.calculate_for_timeframe(timeframe, limit)
                return result
            finally:
                await diff_calculator.cleanup()

        except Exception as e:
            logger.error(f"âŒ æœªè¨ˆç®—ãƒ‡ãƒ¼ã‚¿è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "error": str(e)}

    async def mark_as_calculated(self, processed_data: List[Any]) -> bool:
        """
        è¨ˆç®—å®Œäº†ãƒ•ãƒ©ã‚°ã‚’æ›´æ–°

        Args:
            processed_data: å‡¦ç†ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

        Returns:
            bool: æ›´æ–°æˆåŠŸæ™‚True
        """
        try:
            logger.info("ğŸ”„ è¨ˆç®—å®Œäº†ãƒ•ãƒ©ã‚°æ›´æ–°é–‹å§‹...")

            # DiffDetectionServiceã‚’ä½¿ç”¨
            from src.infrastructure.database.services.diff_detection_service import (
                DiffDetectionService,
            )

            if not self.session:
                logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            diff_service = DiffDetectionService(self.session)
            result = await diff_service.update_calculation_flags(processed_data)

            logger.info(f"âœ… è¨ˆç®—å®Œäº†ãƒ•ãƒ©ã‚°æ›´æ–°: {result}")
            return result

        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—å®Œäº†ãƒ•ãƒ©ã‚°æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def get_calculation_status(self) -> Dict[str, Any]:
        """
        è¨ˆç®—çŠ¶æ³ã®å–å¾—

        Returns:
            Dict[str, Any]: è¨ˆç®—çŠ¶æ³ã®è©³ç´°
        """
        try:
            logger.info("ğŸ“Š è¨ˆç®—çŠ¶æ³å–å¾—é–‹å§‹...")

            # DiffDetectionServiceã‚’ä½¿ç”¨
            from src.infrastructure.database.services.diff_detection_service import (
                DiffDetectionService,
            )

            if not self.session:
                logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return {}

            diff_service = DiffDetectionService(self.session)
            status = await diff_service.get_calculation_status()

            logger.info("âœ… è¨ˆç®—çŠ¶æ³å–å¾—å®Œäº†")
            return status

        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def reset_calculation_flags(self, timeframe: Optional[str] = None) -> bool:
        """
        è¨ˆç®—ãƒ•ãƒ©ã‚°ã®ãƒªã‚»ãƒƒãƒˆ

        Args:
            timeframe: ç‰¹å®šã®æ™‚é–“è¶³ã®ã¿ãƒªã‚»ãƒƒãƒˆï¼ˆNoneã®å ´åˆã¯å…¨ä»¶ï¼‰

        Returns:
            bool: ãƒªã‚»ãƒƒãƒˆæˆåŠŸæ™‚True
        """
        try:
            logger.info("ğŸ”„ è¨ˆç®—ãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆé–‹å§‹...")

            # DiffDetectionServiceã‚’ä½¿ç”¨
            from src.infrastructure.database.services.diff_detection_service import (
                DiffDetectionService,
            )

            if not self.session:
                logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            diff_service = DiffDetectionService(self.session)
            result = await diff_service.reset_calculation_flags(timeframe)

            logger.info(f"âœ… è¨ˆç®—ãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆ: {result}")
            return result

        except Exception as e:
            logger.error(f"âŒ è¨ˆç®—ãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False


# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    async with EnhancedUnifiedTechnicalCalculator("USD/JPY") as calculator:
        # å…¨æŒ‡æ¨™è¨ˆç®—
        results = await calculator.calculate_all_indicators()


if __name__ == "__main__":
    asyncio.run(main())
