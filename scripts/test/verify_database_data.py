"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

USD/JPYã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã‹ã©ã†ã‹ã‚’è©³ã—ãæ¤œè¨¼ã™ã‚‹
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List

import numpy as np
import pandas as pd
from sqlalchemy import text

from src.infrastructure.database.connection import db_manager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class DatabaseDataVerifier:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å™¨"""

    def __init__(self):
        self.test_periods = [7, 30, 90, 365]

    async def verify_database_data(self) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°æ¤œè¨¼"""
        logger.info("=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹ ===")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            await db_manager.initialize(
                "sqlite+aiosqlite:///./data/exchange_analytics.db"
            )
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")

            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æƒ…å ±
            basic_info = await self._get_basic_data_info()

            # å„æœŸé–“ã§ã®ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            period_verifications = {}
            for period in self.test_periods:
                logger.info(f"æœŸé–“ {period}æ—¥ ã§ã®æ¤œè¨¼:")
                verification = await self._verify_period_data(period)
                period_verifications[f"{period}days"] = verification

            # ç•°å¸¸å€¤æ¤œå‡º
            anomaly_detection = await self._detect_anomalies()

            # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
            quality_assessment = self._assess_data_quality(
                basic_info, period_verifications
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†
            await db_manager.close()

            return {
                "basic_info": basic_info,
                "period_verifications": period_verifications,
                "anomaly_detection": anomaly_detection,
                "quality_assessment": quality_assessment,
                "verification_time": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            await db_manager.close()
            return {"error": str(e)}

    async def _get_basic_data_info(self) -> Dict:
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã®å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
                count_query = text(
                    """
                    SELECT COUNT(*) as total_count
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    """
                )
                count_result = await session.execute(count_query)
                total_count = count_result.scalar()

                # æ—¥ä»˜ç¯„å›²
                date_range_query = text(
                    """
                    SELECT
                        MIN(timestamp) as earliest_date,
                        MAX(timestamp) as latest_date
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    """
                )
                date_result = await session.execute(date_range_query)
                date_row = date_result.fetchone()
                earliest_date = date_row[0] if date_row else None
                latest_date = date_row[1] if date_row else None

                # é€šè²¨ãƒšã‚¢åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
                currency_query = text(
                    """
                    SELECT currency_pair, COUNT(*) as count
                    FROM price_data
                    GROUP BY currency_pair
                    ORDER BY count DESC
                    """
                )
                currency_result = await session.execute(currency_query)
                currency_counts = {row[0]: row[1] for row in currency_result.fetchall()}

                # æœ€æ–°ã®æ•°ä»¶ã®ãƒ‡ãƒ¼ã‚¿
                recent_query = text(
                    """
                    SELECT
                        timestamp,
                        currency_pair,
                        open_price,
                        high_price,
                        low_price,
                        close_price,
                        volume
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT 10
                    """
                )
                recent_result = await session.execute(recent_query)
                recent_data = [
                    {
                        "timestamp": row[0],
                        "currency_pair": row[1],
                        "open": float(row[2]),
                        "high": float(row[3]),
                        "low": float(row[4]),
                        "close": float(row[5]),
                        "volume": float(row[6]) if row[6] else 0,
                    }
                    for row in recent_result.fetchall()
                ]

                return {
                    "total_records": total_count,
                    "date_range": {
                        "earliest": earliest_date,
                        "latest": latest_date,
                        "span_days": (
                            (
                                datetime.fromisoformat(latest_date)
                                - datetime.fromisoformat(earliest_date)
                            ).days
                            if earliest_date and latest_date
                            else 0
                        ),
                    },
                    "currency_distribution": currency_counts,
                    "recent_data": recent_data,
                }

        except Exception as e:
            logger.error(f"åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _verify_period_data(self, days: int) -> Dict:
        """ç‰¹å®šæœŸé–“ã§ã®ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"""
        try:
            async with db_manager.get_session() as session:
                # æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
                query = text(
                    """
                    SELECT
                        timestamp,
                        open_price,
                        high_price,
                        low_price,
                        close_price,
                        volume
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT :days
                    """
                )

                result = await session.execute(query, {"days": days})
                rows = result.fetchall()

                if not rows:
                    return {"error": f"æœŸé–“{days}æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

                # DataFrameã«å¤‰æ›
                data = pd.DataFrame(
                    rows,
                    columns=["timestamp", "open", "high", "low", "close", "volume"],
                )
                data = data.sort_values("timestamp").reset_index(drop=True)

                # åŸºæœ¬çµ±è¨ˆ
                price_stats = {
                    "open": {
                        "min": float(data["open"].min()),
                        "max": float(data["open"].max()),
                        "mean": float(data["open"].mean()),
                        "std": float(data["open"].std()),
                        "unique_values": int(data["open"].nunique()),
                    },
                    "high": {
                        "min": float(data["high"].min()),
                        "max": float(data["high"].max()),
                        "mean": float(data["high"].mean()),
                        "std": float(data["high"].std()),
                        "unique_values": int(data["high"].nunique()),
                    },
                    "low": {
                        "min": float(data["low"].min()),
                        "max": float(data["low"].max()),
                        "mean": float(data["low"].mean()),
                        "std": float(data["low"].std()),
                        "unique_values": int(data["low"].nunique()),
                    },
                    "close": {
                        "min": float(data["close"].min()),
                        "max": float(data["close"].max()),
                        "mean": float(data["close"].mean()),
                        "std": float(data["close"].std()),
                        "unique_values": int(data["close"].nunique()),
                    },
                }

                # ä¾¡æ ¼å¤‰å‹•åˆ†æ
                price_changes = self._analyze_price_changes(data)

                # ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
                consistency_checks = self._check_data_consistency(data)

                # æ™‚ç³»åˆ—åˆ†æ
                time_series_analysis = self._analyze_time_series(data)

                return {
                    "data_points": len(data),
                    "date_range": {
                        "start": data["timestamp"].iloc[0],
                        "end": data["timestamp"].iloc[-1],
                    },
                    "price_statistics": price_stats,
                    "price_changes": price_changes,
                    "consistency_checks": consistency_checks,
                    "time_series_analysis": time_series_analysis,
                }

        except Exception as e:
            logger.error(f"æœŸé–“{days}æ—¥æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_price_changes(self, data: pd.DataFrame) -> Dict:
        """ä¾¡æ ¼å¤‰å‹•ã®åˆ†æ"""
        try:
            analysis = {}

            # æ—¥æ¬¡å¤‰å‹•
            if len(data) > 1:
                close_changes = data["close"].diff().dropna()
                analysis["daily_changes"] = {
                    "mean_change": float(close_changes.mean()),
                    "std_change": float(close_changes.std()),
                    "min_change": float(close_changes.min()),
                    "max_change": float(close_changes.max()),
                    "positive_changes": int((close_changes > 0).sum()),
                    "negative_changes": int((close_changes < 0).sum()),
                    "zero_changes": int((close_changes == 0).sum()),
                }

                # å¤‰å‹•ç‡
                close_returns = data["close"].pct_change().dropna()
                analysis["daily_returns"] = {
                    "mean_return": float(close_returns.mean()),
                    "std_return": float(close_returns.std()),
                    "min_return": float(close_returns.min()),
                    "max_return": float(close_returns.max()),
                }

            # ä¾¡æ ¼ç¯„å›²ã®åˆ†æ
            price_ranges = data["high"] - data["low"]
            analysis["price_ranges"] = {
                "mean_range": float(price_ranges.mean()),
                "std_range": float(price_ranges.std()),
                "min_range": float(price_ranges.min()),
                "max_range": float(price_ranges.max()),
            }

            return analysis

        except Exception as e:
            logger.error(f"ä¾¡æ ¼å¤‰å‹•åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _check_data_consistency(self, data: pd.DataFrame) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            checks = {}

            # ä¾¡æ ¼ã®è«–ç†çš„é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
            high_low_consistent = (data["high"] >= data["low"]).all()
            high_open_consistent = (data["high"] >= data["open"]).all()
            high_close_consistent = (data["high"] >= data["close"]).all()
            low_open_consistent = (data["low"] <= data["open"]).all()
            low_close_consistent = (data["low"] <= data["close"]).all()

            checks["price_logic"] = {
                "high_ge_low": high_low_consistent,
                "high_ge_open": high_open_consistent,
                "high_ge_close": high_close_consistent,
                "low_le_open": low_open_consistent,
                "low_le_close": low_close_consistent,
                "all_consistent": all(
                    [
                        high_low_consistent,
                        high_open_consistent,
                        high_close_consistent,
                        low_open_consistent,
                        low_close_consistent,
                    ]
                ),
            }

            # ã‚¼ãƒ­å€¤ãƒã‚§ãƒƒã‚¯
            zero_checks = {
                "zero_open": int((data["open"] == 0).sum()),
                "zero_high": int((data["high"] == 0).sum()),
                "zero_low": int((data["low"] == 0).sum()),
                "zero_close": int((data["close"] == 0).sum()),
                "zero_volume": int((data["volume"] == 0).sum()),
            }
            checks["zero_values"] = zero_checks

            # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
            missing_checks = {
                "missing_open": int(data["open"].isna().sum()),
                "missing_high": int(data["high"].isna().sum()),
                "missing_low": int(data["low"].isna().sum()),
                "missing_close": int(data["close"].isna().sum()),
                "missing_volume": int(data["volume"].isna().sum()),
            }
            checks["missing_values"] = missing_checks

            # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            duplicate_checks = {
                "duplicate_timestamps": int(data["timestamp"].duplicated().sum()),
                "duplicate_open": int(data["open"].duplicated().sum()),
                "duplicate_high": int(data["high"].duplicated().sum()),
                "duplicate_low": int(data["low"].duplicated().sum()),
                "duplicate_close": int(data["close"].duplicated().sum()),
            }
            checks["duplicates"] = duplicate_checks

            return checks

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_time_series(self, data: pd.DataFrame) -> Dict:
        """æ™‚ç³»åˆ—åˆ†æ"""
        try:
            analysis = {}

            # æ™‚ç³»åˆ—ã®é€£ç¶šæ€§
            timestamps = pd.to_datetime(data["timestamp"])
            time_diffs = timestamps.diff().dropna()

            analysis["time_continuity"] = {
                "total_periods": len(timestamps),
                "time_diffs": {
                    "mean": str(time_diffs.mean()),
                    "std": str(time_diffs.std()),
                    "min": str(time_diffs.min()),
                    "max": str(time_diffs.max()),
                },
            }

            # ä¾¡æ ¼ã®æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³
            if len(data) > 10:
                # ç§»å‹•å¹³å‡
                ma_5 = data["close"].rolling(5).mean()
                ma_10 = data["close"].rolling(10).mean()

                analysis["moving_averages"] = {
                    "ma_5_range": {
                        "min": float(ma_5.min()),
                        "max": float(ma_5.max()),
                        "std": float(ma_5.std()),
                    },
                    "ma_10_range": {
                        "min": float(ma_10.min()),
                        "max": float(ma_10.max()),
                        "std": float(ma_10.std()),
                    },
                }

            return analysis

        except Exception as e:
            logger.error(f"æ™‚ç³»åˆ—åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _detect_anomalies(self) -> Dict:
        """ç•°å¸¸å€¤ã®æ¤œå‡º"""
        try:
            async with db_manager.get_session() as session:
                # ç•°å¸¸ã«å¤§ããªä¾¡æ ¼å¤‰å‹•
                anomaly_query = text(
                    """
                    SELECT
                        timestamp,
                        open_price,
                        high_price,
                        low_price,
                        close_price,
                        ABS(close_price - LAG(close_price) OVER (ORDER BY timestamp)) as price_change
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT 100
                    """
                )

                result = await session.execute(anomaly_query)
                rows = result.fetchall()

                if not rows:
                    return {"error": "ç•°å¸¸å€¤æ¤œå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

                # ç•°å¸¸å€¤ã®ç‰¹å®š
                anomalies = []
                for row in rows:
                    if row[5] and row[5] > 1.0:  # 1å††ä»¥ä¸Šã®å¤‰å‹•
                        anomalies.append(
                            {
                                "timestamp": row[0],
                                "open": float(row[1]),
                                "high": float(row[2]),
                                "low": float(row[3]),
                                "close": float(row[4]),
                                "price_change": float(row[5]),
                            }
                        )

                return {
                    "large_price_changes": anomalies,
                    "anomaly_count": len(anomalies),
                }

        except Exception as e:
            logger.error(f"ç•°å¸¸å€¤æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _assess_data_quality(
        self, basic_info: Dict, period_verifications: Dict
    ) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç·åˆè©•ä¾¡"""
        try:
            assessment = {"overall_score": 0, "issues": [], "recommendations": []}

            score = 0
            max_score = 100

            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿é‡ã®è©•ä¾¡
            total_records = basic_info.get("total_records", 0)
            if total_records > 10000:
                score += 20
            elif total_records > 1000:
                score += 15
            elif total_records > 100:
                score += 10
            else:
                assessment["issues"].append("ãƒ‡ãƒ¼ã‚¿é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                assessment["recommendations"].append("ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãã ã•ã„")

            # æ—¥ä»˜ç¯„å›²ã®è©•ä¾¡
            date_range = basic_info.get("date_range", {})
            span_days = date_range.get("span_days", 0)
            if span_days > 365:
                score += 20
            elif span_days > 90:
                score += 15
            elif span_days > 30:
                score += 10
            else:
                assessment["issues"].append("ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã™ãã¾ã™")
                assessment["recommendations"].append("ã‚ˆã‚Šé•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãã ã•ã„")

            # ä¾¡æ ¼å¤‰å‹•ã®è©•ä¾¡
            for period_key, verification in period_verifications.items():
                if "error" not in verification:
                    price_stats = verification.get("price_statistics", {})
                    close_stats = price_stats.get("close", {})
                    unique_values = close_stats.get("unique_values", 0)

                    if unique_values < 2:
                        assessment["issues"].append(f"{period_key}: ä¾¡æ ¼å¤‰å‹•ãŒã‚ã‚Šã¾ã›ã‚“")
                        assessment["recommendations"].append(
                            f"{period_key}: ã‚ˆã‚Šå¤‰å‹•ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™"
                        )
                    else:
                        score += 10

            # ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ã®è©•ä¾¡
            for period_key, verification in period_verifications.items():
                if "error" not in verification:
                    consistency = verification.get("consistency_checks", {})
                    price_logic = consistency.get("price_logic", {})

                    if price_logic.get("all_consistent", False):
                        score += 10
                    else:
                        assessment["issues"].append(f"{period_key}: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®è«–ç†çš„ä¸æ•´åˆãŒã‚ã‚Šã¾ã™")
                        assessment["recommendations"].append(
                            f"{period_key}: ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                        )

            assessment["overall_score"] = min(score, max_score)

            # ç·åˆè©•ä¾¡
            if assessment["overall_score"] >= 80:
                assessment["grade"] = "A"
                assessment["summary"] = "ãƒ‡ãƒ¼ã‚¿å“è³ªã¯è‰¯å¥½ã§ã™"
            elif assessment["overall_score"] >= 60:
                assessment["grade"] = "B"
                assessment["summary"] = "ãƒ‡ãƒ¼ã‚¿å“è³ªã¯ä¸­ç¨‹åº¦ã§ã™"
            elif assessment["overall_score"] >= 40:
                assessment["grade"] = "C"
                assessment["summary"] = "ãƒ‡ãƒ¼ã‚¿å“è³ªã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
            else:
                assessment["grade"] = "D"
                assessment["summary"] = "ãƒ‡ãƒ¼ã‚¿å“è³ªãŒéå¸¸ã«æ‚ªã„ã§ã™"

            return assessment

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    verifier = DatabaseDataVerifier()
    results = await verifier.verify_database_data()

    if "error" in results:
        print(f"\nâŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {results['error']}")
        return

    print("\n=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼çµæœ ===")

    # åŸºæœ¬æƒ…å ±
    basic_info = results.get("basic_info", {})
    print(f"\nğŸ“Š åŸºæœ¬æƒ…å ±:")
    print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {basic_info.get('total_records', 0):,}")

    date_range = basic_info.get("date_range", {})
    print(
        f"  æ—¥ä»˜ç¯„å›²: {date_range.get('earliest', 'N/A')} ï½ {date_range.get('latest', 'N/A')}"
    )
    print(f"  æœŸé–“: {date_range.get('span_days', 0)}æ—¥")

    currency_dist = basic_info.get("currency_distribution", {})
    print(f"  é€šè²¨ãƒšã‚¢åˆ†å¸ƒ:")
    for currency, count in currency_dist.items():
        print(f"    {currency}: {count:,}ä»¶")

    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿
    recent_data = basic_info.get("recent_data", [])
    if recent_data:
        print(f"\nğŸ“ˆ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½5ä»¶ï¼‰:")
        for i, data in enumerate(recent_data[:5]):
            print(
                f"  {i+1}. {data['timestamp']}: O:{data['open']:.2f} H:{data['high']:.2f} L:{data['low']:.2f} C:{data['close']:.2f}"
            )

    # æœŸé–“åˆ¥æ¤œè¨¼
    period_verifications = results.get("period_verifications", {})
    print(f"\nğŸ” æœŸé–“åˆ¥æ¤œè¨¼:")

    for period_key, verification in period_verifications.items():
        if "error" in verification:
            print(f"\n  {period_key}: âŒ {verification['error']}")
            continue

        print(f"\n  {period_key}:")
        print(f"    ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {verification.get('data_points', 0)}ä»¶")

        price_stats = verification.get("price_statistics", {})
        close_stats = price_stats.get("close", {})
        print(
            f"    çµ‚å€¤ç¯„å›²: {close_stats.get('min', 0):.2f} - {close_stats.get('max', 0):.2f}"
        )
        print(f"    çµ‚å€¤å¹³å‡: {close_stats.get('mean', 0):.2f}")
        print(f"    çµ‚å€¤æ¨™æº–åå·®: {close_stats.get('std', 0):.4f}")
        print(f"    çµ‚å€¤ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤: {close_stats.get('unique_values', 0)}")

        # ä¾¡æ ¼å¤‰å‹•
        price_changes = verification.get("price_changes", {})
        daily_changes = price_changes.get("daily_changes", {})
        if daily_changes:
            print(
                f"    æ—¥æ¬¡å¤‰å‹•: å¹³å‡{daily_changes.get('mean_change', 0):.4f}, æ¨™æº–åå·®{daily_changes.get('std_change', 0):.4f}"
            )
            print(
                f"    å¤‰å‹•æ–¹å‘: +{daily_changes.get('positive_changes', 0)} -{daily_changes.get('negative_changes', 0)} ={daily_changes.get('zero_changes', 0)}"
            )

        # ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        consistency = verification.get("consistency_checks", {})
        price_logic = consistency.get("price_logic", {})
        print(f"    ä¾¡æ ¼è«–ç†: {'âœ…' if price_logic.get('all_consistent', False) else 'âŒ'}")

        zero_values = consistency.get("zero_values", {})
        if any(zero_values.values()):
            print(f"    ã‚¼ãƒ­å€¤: {zero_values}")

    # ç•°å¸¸å€¤æ¤œå‡º
    anomaly_detection = results.get("anomaly_detection", {})
    print(f"\nğŸš¨ ç•°å¸¸å€¤æ¤œå‡º:")
    print(f"  å¤§ããªä¾¡æ ¼å¤‰å‹•: {anomaly_detection.get('anomaly_count', 0)}ä»¶")

    large_changes = anomaly_detection.get("large_price_changes", [])
    if large_changes:
        print(f"  ç•°å¸¸å¤‰å‹•è©³ç´°ï¼ˆä¸Šä½3ä»¶ï¼‰:")
        for i, change in enumerate(large_changes[:3]):
            print(f"    {i+1}. {change['timestamp']}: {change['price_change']:.2f}å††å¤‰å‹•")

    # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
    quality_assessment = results.get("quality_assessment", {})
    print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡:")
    print(f"  ç·åˆã‚¹ã‚³ã‚¢: {quality_assessment.get('overall_score', 0)}/100")
    print(f"  ã‚°ãƒ¬ãƒ¼ãƒ‰: {quality_assessment.get('grade', 'N/A')}")
    print(f"  è©•ä¾¡: {quality_assessment.get('summary', 'N/A')}")

    issues = quality_assessment.get("issues", [])
    if issues:
        print(f"  å•é¡Œç‚¹:")
        for issue in issues:
            print(f"    âŒ {issue}")

    recommendations = quality_assessment.get("recommendations", [])
    if recommendations:
        print(f"  æ¨å¥¨äº‹é …:")
        for rec in recommendations:
            print(f"    ğŸ’¡ {rec}")


if __name__ == "__main__":
    asyncio.run(main())
