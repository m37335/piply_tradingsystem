"""
ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºã®è©³ç´°åˆ†æã¨ãƒ‡ãƒãƒƒã‚°
"""

import asyncio
import logging
from typing import Dict

import numpy as np
import pandas as pd
from scipy.signal import find_peaks
from sqlalchemy import text

from src.infrastructure.analysis.pattern_detectors.support_resistance_detector_v3 import (
    SupportResistanceDetectorV3,
)
from src.infrastructure.database.connection import db_manager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class Pattern15V3BufferedPeaksDebugger:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚¬ãƒ¼"""

    def __init__(self):
        self.timeframes = ["5m", "1h", "1d"]

    async def debug_buffered_peaks(self) -> Dict:
        """ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºã®è©³ç´°ãƒ‡ãƒãƒƒã‚°"""
        logger.info("=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°é–‹å§‹ ===")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            await db_manager.initialize(
                "sqlite+aiosqlite:///./data/exchange_analytics.db"
            )
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")

            results = {}
            for timeframe in self.timeframes:
                logger.info(f"ãƒ‡ãƒãƒƒã‚°æ™‚é–“è¶³: {timeframe}")
                result = await self._debug_single_timeframe(timeframe)
                results[timeframe] = result

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†
            await db_manager.close()

            return results

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            await db_manager.close()
            return {"error": str(e)}

    async def _debug_single_timeframe(self, timeframe: str) -> Dict:
        """å˜ä¸€æ™‚é–“è¶³ã®ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°"""
        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            data = await self._fetch_market_data(100)  # 100ä»¶ã®ãƒ‡ãƒ¼ã‚¿
            if data.empty:
                return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}

            logger.info(f"  å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")

            # ãƒ‡ãƒ†ã‚¯ã‚¿ãƒ¼ä½œæˆ
            detector = SupportResistanceDetectorV3(timeframe)

            # ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºã®è©³ç´°åˆ†æ
            debug_result = self._analyze_buffered_peaks_detailed(
                data, detector, timeframe
            )

            return {
                "timeframe": timeframe,
                "data_points": len(data),
                "debug_analysis": debug_result,
            }

        except Exception as e:
            logger.error(f"æ™‚é–“è¶³ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_buffered_peaks_detailed(
        self, data: pd.DataFrame, detector: SupportResistanceDetectorV3, timeframe: str
    ) -> Dict:
        """ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºã®è©³ç´°åˆ†æ"""
        try:
            analysis = {}

            # æ™‚é–“è¶³åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            analysis["timeframe_parameters"] = {
                "timeframe": timeframe,
                "min_peaks": detector.min_peaks,
                "analysis_period": detector.analysis_period,
                "buffer_percentile": detector.buffer_percentile,
                "min_line_strength": detector.min_line_strength,
                "max_angle": detector.max_angle,
                "price_tolerance": detector.price_tolerance,
            }

            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆ
            high_prices = data["High"].values
            low_prices = data["Low"].values

            analysis["price_statistics"] = {
                "high_prices": {
                    "min": np.min(high_prices),
                    "max": np.max(high_prices),
                    "mean": np.mean(high_prices),
                    "std": np.std(high_prices),
                    "percentiles": {
                        "10": np.percentile(high_prices, 10),
                        "25": np.percentile(high_prices, 25),
                        "50": np.percentile(high_prices, 50),
                        "75": np.percentile(high_prices, 75),
                        "90": np.percentile(high_prices, 90),
                    },
                },
                "low_prices": {
                    "min": np.min(low_prices),
                    "max": np.max(low_prices),
                    "mean": np.mean(low_prices),
                    "std": np.std(low_prices),
                    "percentiles": {
                        "10": np.percentile(low_prices, 10),
                        "25": np.percentile(low_prices, 25),
                        "50": np.percentile(low_prices, 50),
                        "75": np.percentile(low_prices, 75),
                        "90": np.percentile(low_prices, 90),
                    },
                },
            }

            # ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ©ã‚¤ãƒ³ç”¨ã®ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå¤§å€¤æ¤œå‡º
            resistance_peaks = self._debug_find_buffered_peaks(
                high_prices, "max", detector
            )
            analysis["resistance_peaks"] = resistance_peaks

            # ã‚µãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ç”¨ã®ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå°å€¤æ¤œå‡º
            support_troughs = self._debug_find_buffered_peaks(
                low_prices, "min", detector
            )
            analysis["support_troughs"] = support_troughs

            # ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³ã®å¯è¦–åŒ–
            analysis["buffer_zones"] = self._analyze_buffer_zones(
                high_prices, low_prices, detector
            )

            return analysis

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤è©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _debug_find_buffered_peaks(
        self, prices: np.ndarray, peak_type: str, detector: SupportResistanceDetectorV3
    ) -> Dict:
        """ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºã®è©³ç´°ãƒ‡ãƒãƒƒã‚°"""
        try:
            debug_info = {}

            if peak_type == "max":
                # ä¸Šä½N%ã®ä¾¡æ ¼å¸¯ã‚’ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦å®šç¾©
                threshold = np.percentile(prices, 100 - detector.buffer_percentile)
                debug_info["threshold"] = threshold
                debug_info["threshold_percentile"] = 100 - detector.buffer_percentile

                # find_peaksã§ã®æ¤œå‡º
                peaks, properties = find_peaks(prices, height=threshold, distance=1)
                debug_info["find_peaks_result"] = {
                    "peaks": peaks.tolist(),
                    "peak_count": len(peaks),
                    "properties": properties,
                }

                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                if len(peaks) == 0:
                    sorted_indices = np.argsort(prices)[::-1]
                    fallback_peaks = sorted_indices[: detector.min_peaks]
                    debug_info["fallback_peaks"] = {
                        "peaks": fallback_peaks.tolist(),
                        "peak_count": len(fallback_peaks),
                        "triggered": True,
                        "reason": "find_peaks returned 0 peaks",
                    }
                    final_peaks = fallback_peaks
                else:
                    debug_info["fallback_peaks"] = {
                        "triggered": False,
                        "reason": "find_peaks returned peaks",
                    }
                    final_peaks = peaks

            else:  # min
                # ä¸‹ä½N%ã®ä¾¡æ ¼å¸¯ã‚’ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦å®šç¾©
                threshold = np.percentile(prices, detector.buffer_percentile)
                debug_info["threshold"] = threshold
                debug_info["threshold_percentile"] = detector.buffer_percentile

                # find_peaksã§ã®æ¤œå‡ºï¼ˆè² ã®å€¤ã§æ¤œå‡ºï¼‰
                peaks, properties = find_peaks(-prices, height=-threshold, distance=1)
                debug_info["find_peaks_result"] = {
                    "peaks": peaks.tolist(),
                    "peak_count": len(peaks),
                    "properties": properties,
                }

                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                if len(peaks) == 0:
                    sorted_indices = np.argsort(prices)
                    fallback_peaks = sorted_indices[: detector.min_peaks]
                    debug_info["fallback_peaks"] = {
                        "peaks": fallback_peaks.tolist(),
                        "peak_count": len(fallback_peaks),
                        "triggered": True,
                        "reason": "find_peaks returned 0 peaks",
                    }
                    final_peaks = fallback_peaks
                else:
                    debug_info["fallback_peaks"] = {
                        "triggered": False,
                        "reason": "find_peaks returned peaks",
                    }
                    final_peaks = peaks

            # æœ€çµ‚çµæœ
            debug_info["final_result"] = {
                "peaks": final_peaks.tolist(),
                "peak_count": len(final_peaks),
                "peak_prices": [prices[i] for i in final_peaks],
                "meets_minimum": len(final_peaks) >= detector.min_peaks,
            }

            # ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³å†…ã®ä¾¡æ ¼ãƒã‚¤ãƒ³ãƒˆæ•°
            if peak_type == "max":
                buffer_zone_points = np.sum(prices >= threshold)
            else:
                buffer_zone_points = np.sum(prices <= threshold)

            debug_info["buffer_zone_analysis"] = {
                "buffer_zone_points": int(buffer_zone_points),
                "buffer_zone_percentage": (buffer_zone_points / len(prices)) * 100,
                "total_points": len(prices),
            }

            return debug_info

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_buffer_zones(
        self,
        high_prices: np.ndarray,
        low_prices: np.ndarray,
        detector: SupportResistanceDetectorV3,
    ) -> Dict:
        """ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³ã®åˆ†æ"""
        try:
            analysis = {}

            # ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ç”¨ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³
            resistance_threshold = np.percentile(
                high_prices, 100 - detector.buffer_percentile
            )
            resistance_zone_points = high_prices >= resistance_threshold
            resistance_zone_indices = np.where(resistance_zone_points)[0]

            analysis["resistance_buffer_zone"] = {
                "threshold": resistance_threshold,
                "threshold_percentile": 100 - detector.buffer_percentile,
                "zone_points": int(np.sum(resistance_zone_points)),
                "zone_percentage": (np.sum(resistance_zone_points) / len(high_prices))
                * 100,
                "zone_indices": resistance_zone_indices.tolist()[:10],  # æœ€åˆã®10å€‹
                "zone_prices": high_prices[resistance_zone_points][
                    :10
                ].tolist(),  # æœ€åˆã®10å€‹
            }

            # ã‚µãƒãƒ¼ãƒˆç”¨ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³
            support_threshold = np.percentile(low_prices, detector.buffer_percentile)
            support_zone_points = low_prices <= support_threshold
            support_zone_indices = np.where(support_zone_points)[0]

            analysis["support_buffer_zone"] = {
                "threshold": support_threshold,
                "threshold_percentile": detector.buffer_percentile,
                "zone_points": int(np.sum(support_zone_points)),
                "zone_percentage": (np.sum(support_zone_points) / len(low_prices))
                * 100,
                "zone_indices": support_zone_indices.tolist()[:10],  # æœ€åˆã®10å€‹
                "zone_prices": low_prices[support_zone_points][:10].tolist(),  # æœ€åˆã®10å€‹
            }

            return analysis

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _fetch_market_data(self, limit: int) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                query = text(
                    """
                    SELECT
                        timestamp as Date,
                        open_price as Open,
                        high_price as High,
                        low_price as Low,
                        close_price as Close,
                        volume as Volume
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT :limit
                """
                )

                result = await session.execute(query, {"limit": limit})
                rows = result.fetchall()

                if not rows:
                    return pd.DataFrame()

                data = pd.DataFrame(
                    rows, columns=["Date", "Open", "High", "Low", "Close", "Volume"]
                )

                data = data.sort_values("Date").reset_index(drop=True)
                return data

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    debugger = Pattern15V3BufferedPeaksDebugger()
    results = await debugger.debug_buffered_peaks()

    if "error" in results:
        print(f"\nâŒ ãƒ‡ãƒãƒƒã‚°ã‚¨ãƒ©ãƒ¼: {results['error']}")
        return

    print("\n=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 ãƒãƒƒãƒ•ã‚¡ä»˜ãæ¥µå€¤æ¤œå‡ºãƒ‡ãƒãƒƒã‚°çµæœ ===")

    for timeframe, result in results.items():
        if "error" in result:
            print(f"\nâŒ {timeframe}: {result['error']}")
            continue

        print(f"\nğŸ“Š {timeframe} ({result['data_points']}ä»¶):")

        debug_analysis = result.get("debug_analysis", {})

        # æ™‚é–“è¶³åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        tf_params = debug_analysis.get("timeframe_parameters", {})
        print(f"  âš™ï¸ æ™‚é–“è¶³åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        print(f"    æ™‚é–“è¶³: {tf_params.get('timeframe')}")
        print(f"    æœ€å°ãƒ”ãƒ¼ã‚¯æ•°: {tf_params.get('min_peaks')}")
        print(f"    åˆ†ææœŸé–“: {tf_params.get('analysis_period')}ãƒã‚¤ãƒ³ãƒˆ")
        print(f"    ãƒãƒƒãƒ•ã‚¡ç™¾åˆ†ä½: {tf_params.get('buffer_percentile')}%")
        print(f"    æœ€å°ãƒ©ã‚¤ãƒ³å¼·åº¦: {tf_params.get('min_line_strength')}")
        print(f"    æœ€å¤§è§’åº¦: {tf_params.get('max_angle')}åº¦")
        print(f"    ä¾¡æ ¼è¨±å®¹èª¤å·®: {tf_params.get('price_tolerance'):.3f}")

        # ä¾¡æ ¼çµ±è¨ˆ
        price_stats = debug_analysis.get("price_statistics", {})
        if price_stats:
            print(f"  ğŸ“ˆ ä¾¡æ ¼çµ±è¨ˆ:")

            high_stats = price_stats.get("high_prices", {})
            print(f"    é«˜å€¤:")
            print(f"      æœ€å°: {high_stats.get('min', 0):.5f}")
            print(f"      æœ€å¤§: {high_stats.get('max', 0):.5f}")
            print(f"      å¹³å‡: {high_stats.get('mean', 0):.5f}")
            print(f"      æ¨™æº–åå·®: {high_stats.get('std', 0):.5f}")

            high_percentiles = high_stats.get("percentiles", {})
            print(f"      ç™¾åˆ†ä½:")
            print(f"        10%: {high_percentiles.get('10', 0):.5f}")
            print(f"        25%: {high_percentiles.get('25', 0):.5f}")
            print(f"        50%: {high_percentiles.get('50', 0):.5f}")
            print(f"        75%: {high_percentiles.get('75', 0):.5f}")
            print(f"        90%: {high_percentiles.get('90', 0):.5f}")

            low_stats = price_stats.get("low_prices", {})
            print(f"    å®‰å€¤:")
            print(f"      æœ€å°: {low_stats.get('min', 0):.5f}")
            print(f"      æœ€å¤§: {low_stats.get('max', 0):.5f}")
            print(f"      å¹³å‡: {low_stats.get('mean', 0):.5f}")
            print(f"      æ¨™æº–åå·®: {low_stats.get('std', 0):.5f}")

            low_percentiles = low_stats.get("percentiles", {})
            print(f"      ç™¾åˆ†ä½:")
            print(f"        10%: {low_percentiles.get('10', 0):.5f}")
            print(f"        25%: {low_percentiles.get('25', 0):.5f}")
            print(f"        50%: {low_percentiles.get('50', 0):.5f}")
            print(f"        75%: {low_percentiles.get('75', 0):.5f}")
            print(f"        90%: {low_percentiles.get('90', 0):.5f}")

        # ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ”ãƒ¼ã‚¯
        resistance_peaks = debug_analysis.get("resistance_peaks", {})
        if resistance_peaks:
            print(f"  ğŸ”º ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ”ãƒ¼ã‚¯æ¤œå‡º:")
            print(
                f"    é–¾å€¤: {resistance_peaks.get('threshold', 0):.5f} (ä¸Šä½{resistance_peaks.get('threshold_percentile', 0)}%)"
            )

            find_peaks_result = resistance_peaks.get("find_peaks_result", {})
            print(f"    find_peaksçµæœ:")
            print(f"      ãƒ”ãƒ¼ã‚¯æ•°: {find_peaks_result.get('peak_count', 0)}")
            print(f"      ãƒ”ãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {find_peaks_result.get('peaks', [])[:5]}")

            fallback_peaks = resistance_peaks.get("fallback_peaks", {})
            if fallback_peaks.get("triggered", False):
                print(f"    âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†:")
                print(f"      ç†ç”±: {fallback_peaks.get('reason', '')}")
                print(f"      ãƒ”ãƒ¼ã‚¯æ•°: {fallback_peaks.get('peak_count', 0)}")
                print(f"      ãƒ”ãƒ¼ã‚¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {fallback_peaks.get('peaks', [])[:5]}")

            final_result = resistance_peaks.get("final_result", {})
            print(f"    æœ€çµ‚çµæœ:")
            print(f"      ãƒ”ãƒ¼ã‚¯æ•°: {final_result.get('peak_count', 0)}")
            print(
                f"      æœ€å°è¦ä»¶æº€è¶³: {'âœ…' if final_result.get('meets_minimum', False) else 'âŒ'}"
            )
            print(f"      ãƒ”ãƒ¼ã‚¯ä¾¡æ ¼: {final_result.get('peak_prices', [])[:5]}")

            buffer_zone = resistance_peaks.get("buffer_zone_analysis", {})
            print(f"    ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³:")
            print(f"      ã‚¾ãƒ¼ãƒ³å†…ãƒã‚¤ãƒ³ãƒˆæ•°: {buffer_zone.get('buffer_zone_points', 0)}")
            print(f"      ã‚¾ãƒ¼ãƒ³å‰²åˆ: {buffer_zone.get('buffer_zone_percentage', 0):.1f}%")

        # ã‚µãƒãƒ¼ãƒˆãƒœãƒˆãƒ 
        support_troughs = debug_analysis.get("support_troughs", {})
        if support_troughs:
            print(f"  ğŸ”» ã‚µãƒãƒ¼ãƒˆãƒœãƒˆãƒ æ¤œå‡º:")
            print(
                f"    é–¾å€¤: {support_troughs.get('threshold', 0):.5f} (ä¸‹ä½{support_troughs.get('threshold_percentile', 0)}%)"
            )

            find_peaks_result = support_troughs.get("find_peaks_result", {})
            print(f"    find_peaksçµæœ:")
            print(f"      ãƒœãƒˆãƒ æ•°: {find_peaks_result.get('peak_count', 0)}")
            print(f"      ãƒœãƒˆãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {find_peaks_result.get('peaks', [])[:5]}")

            fallback_peaks = support_troughs.get("fallback_peaks", {})
            if fallback_peaks.get("triggered", False):
                print(f"    âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†:")
                print(f"      ç†ç”±: {fallback_peaks.get('reason', '')}")
                print(f"      ãƒœãƒˆãƒ æ•°: {fallback_peaks.get('peak_count', 0)}")
                print(f"      ãƒœãƒˆãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {fallback_peaks.get('peaks', [])[:5]}")

            final_result = support_troughs.get("final_result", {})
            print(f"    æœ€çµ‚çµæœ:")
            print(f"      ãƒœãƒˆãƒ æ•°: {final_result.get('peak_count', 0)}")
            print(
                f"      æœ€å°è¦ä»¶æº€è¶³: {'âœ…' if final_result.get('meets_minimum', False) else 'âŒ'}"
            )
            print(f"      ãƒœãƒˆãƒ ä¾¡æ ¼: {final_result.get('peak_prices', [])[:5]}")

            buffer_zone = support_troughs.get("buffer_zone_analysis", {})
            print(f"    ãƒãƒƒãƒ•ã‚¡ã‚¾ãƒ¼ãƒ³:")
            print(f"      ã‚¾ãƒ¼ãƒ³å†…ãƒã‚¤ãƒ³ãƒˆæ•°: {buffer_zone.get('buffer_zone_points', 0)}")
            print(f"      ã‚¾ãƒ¼ãƒ³å‰²åˆ: {buffer_zone.get('buffer_zone_percentage', 0):.1f}%")


if __name__ == "__main__":
    asyncio.run(main())
