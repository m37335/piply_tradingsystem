"""
å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’åˆ†æã—ã¦ã€ã‚¿ãƒƒãƒãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã®å•é¡Œã‚’èª¿æŸ»ã™ã‚‹
"""

import asyncio
import logging
from typing import Dict, List

import pandas as pd
from sqlalchemy import text

from src.infrastructure.database.connection import db_manager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class RealDataPatternAnalyzer:
    """å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå™¨"""

    async def analyze_real_data_patterns(self) -> Dict:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        logger.info("=== å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æé–‹å§‹ ===")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            await db_manager.initialize(
                "sqlite+aiosqlite:///./data/exchange_analytics.db"
            )
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")

            # ç›´è¿‘3ãƒ¶æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            data = await self._fetch_market_data(90)
            if data.empty:
                logger.error("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}

            logger.info(f"å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")
            logger.info(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {data.iloc[0]['Date']} - {data.iloc[-1]['Date']}")

            # ãƒ‡ãƒ¼ã‚¿åˆ†æå®Ÿè¡Œ
            analysis = self._analyze_data_patterns(data)

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†
            await db_manager.close()

            return analysis

        except Exception as e:
            logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            await db_manager.close()
            return {"error": str(e)}

    async def _fetch_market_data(self, days: int) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                query = text(
                    """
                    SELECT
                        timestamp as Date,
                        open_price as Open,
                        high_price as High,
                        low_price as Low,
                        close_price as Close,
                        volume as Volume
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT :days
                """
                )

                result = await session.execute(query, {"days": days})
                rows = result.fetchall()

                if not rows:
                    return pd.DataFrame()

                data = pd.DataFrame(
                    rows, columns=["Date", "Open", "High", "Low", "Close", "Volume"]
                )

                data = data.sort_values("Date").reset_index(drop=True)
                return data

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    def _analyze_data_patterns(self, data: pd.DataFrame) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        analysis = {
            "basic_stats": {},
            "high_patterns": {},
            "low_patterns": {},
            "price_movements": {},
            "recommendations": [],
        }

        # åŸºæœ¬çµ±è¨ˆ
        analysis["basic_stats"] = {
            "total_points": len(data),
            "price_range": f"{data['Close'].min():.4f} - {data['Close'].max():.4f}",
            "avg_price": data["Close"].mean(),
            "price_volatility": data["Close"].std(),
            "high_range": f"{data['High'].min():.4f} - {data['High'].max():.4f}",
            "low_range": f"{data['Low'].min():.4f} - {data['Low'].max():.4f}",
        }

        # é«˜å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        analysis["high_patterns"] = self._analyze_high_patterns(data)

        # å®‰å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        analysis["low_patterns"] = self._analyze_low_patterns(data)

        # ä¾¡æ ¼å¤‰å‹•åˆ†æ
        analysis["price_movements"] = self._analyze_price_movements(data)

        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        analysis["recommendations"] = self._generate_recommendations(analysis)

        return analysis

    def _analyze_high_patterns(self, data: pd.DataFrame) -> Dict:
        """é«˜å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        patterns = {
            "strict_peaks": [],
            "relaxed_peaks": [],
            "consecutive_highs": [],
            "high_frequency": 0,
        }

        # å³æ ¼ãªãƒ”ãƒ¼ã‚¯æ¤œå‡ºï¼ˆå…ƒã®æ¡ä»¶ï¼‰
        for i in range(2, len(data) - 2):
            if (
                data.iloc[i]["High"] > data.iloc[i - 1]["High"]
                and data.iloc[i]["High"] > data.iloc[i - 2]["High"]
                and data.iloc[i]["High"] > data.iloc[i + 1]["High"]
                and data.iloc[i]["High"] > data.iloc[i + 2]["High"]
            ):
                patterns["strict_peaks"].append(i)

        # ç·©å’Œã•ã‚ŒãŸãƒ”ãƒ¼ã‚¯æ¤œå‡ºï¼ˆç¾åœ¨ã®æ¡ä»¶ï¼‰
        for i in range(1, len(data) - 1):
            if (
                data.iloc[i]["High"] > data.iloc[i - 1]["High"]
                and data.iloc[i]["High"] > data.iloc[i + 1]["High"]
            ):
                patterns["relaxed_peaks"].append(i)

        # é€£ç¶šé«˜å€¤ã®åˆ†æ
        consecutive_count = 0
        for i in range(1, len(data)):
            if data.iloc[i]["High"] > data.iloc[i - 1]["High"]:
                consecutive_count += 1
            else:
                if consecutive_count > 0:
                    patterns["consecutive_highs"].append(consecutive_count)
                consecutive_count = 0

        patterns["high_frequency"] = len(patterns["relaxed_peaks"]) / len(data)

        return patterns

    def _analyze_low_patterns(self, data: pd.DataFrame) -> Dict:
        """å®‰å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        patterns = {
            "strict_bottoms": [],
            "relaxed_bottoms": [],
            "consecutive_lows": [],
            "low_frequency": 0,
        }

        # å³æ ¼ãªãƒœãƒˆãƒ æ¤œå‡ºï¼ˆå…ƒã®æ¡ä»¶ï¼‰
        for i in range(2, len(data) - 2):
            if (
                data.iloc[i]["Low"] < data.iloc[i - 1]["Low"]
                and data.iloc[i]["Low"] < data.iloc[i - 2]["Low"]
                and data.iloc[i]["Low"] < data.iloc[i + 1]["Low"]
                and data.iloc[i]["Low"] < data.iloc[i + 2]["Low"]
            ):
                patterns["strict_bottoms"].append(i)

        # ç·©å’Œã•ã‚ŒãŸãƒœãƒˆãƒ æ¤œå‡ºï¼ˆç¾åœ¨ã®æ¡ä»¶ï¼‰
        for i in range(1, len(data) - 1):
            if (
                data.iloc[i]["Low"] < data.iloc[i - 1]["Low"]
                and data.iloc[i]["Low"] < data.iloc[i + 1]["Low"]
            ):
                patterns["relaxed_bottoms"].append(i)

        # é€£ç¶šå®‰å€¤ã®åˆ†æ
        consecutive_count = 0
        for i in range(1, len(data)):
            if data.iloc[i]["Low"] < data.iloc[i - 1]["Low"]:
                consecutive_count += 1
            else:
                if consecutive_count > 0:
                    patterns["consecutive_lows"].append(consecutive_count)
                consecutive_count = 0

        patterns["low_frequency"] = len(patterns["relaxed_bottoms"]) / len(data)

        return patterns

    def _analyze_price_movements(self, data: pd.DataFrame) -> Dict:
        """ä¾¡æ ¼å¤‰å‹•ã®åˆ†æ"""
        movements = {
            "price_changes": [],
            "high_low_spreads": [],
            "volatility_patterns": [],
        }

        # ä¾¡æ ¼å¤‰åŒ–ã®åˆ†æ
        for i in range(1, len(data)):
            change = data.iloc[i]["Close"] - data.iloc[i - 1]["Close"]
            movements["price_changes"].append(change)

        # é«˜å€¤-å®‰å€¤ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã®åˆ†æ
        for i in range(len(data)):
            spread = data.iloc[i]["High"] - data.iloc[i]["Low"]
            movements["high_low_spreads"].append(spread)

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
        for i in range(1, len(data)):
            volatility = (
                abs(data.iloc[i]["Close"] - data.iloc[i - 1]["Close"])
                / data.iloc[i - 1]["Close"]
            )
            movements["volatility_patterns"].append(volatility)

        return movements

    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """æ¨å¥¨äº‹é …ã®ç”Ÿæˆ"""
        recommendations = []

        high_patterns = analysis["high_patterns"]
        low_patterns = analysis["low_patterns"]

        # å³æ ¼ãªãƒ”ãƒ¼ã‚¯/ãƒœãƒˆãƒ ã®æ¤œå‡ºæ•°
        strict_highs = len(high_patterns["strict_peaks"])
        strict_lows = len(low_patterns["strict_bottoms"])
        relaxed_highs = len(high_patterns["relaxed_peaks"])
        relaxed_lows = len(low_patterns["relaxed_bottoms"])

        if strict_highs == 0 and strict_lows == 0:
            recommendations.append("å³æ ¼ãªæ¡ä»¶ã§ã¯ãƒ”ãƒ¼ã‚¯/ãƒœãƒˆãƒ ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã€‚æ¡ä»¶ã®ç·©å’ŒãŒå¿…è¦ã§ã™ã€‚")

        if relaxed_highs == 0 and relaxed_lows == 0:
            recommendations.append("ç·©å’Œã•ã‚ŒãŸæ¡ä»¶ã§ã‚‚ãƒ”ãƒ¼ã‚¯/ãƒœãƒˆãƒ ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã€‚ã•ã‚‰ã«æ¡ä»¶ã‚’ç·©å’Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

        if relaxed_highs > 0 or relaxed_lows > 0:
            recommendations.append(
                f"ç·©å’Œã•ã‚ŒãŸæ¡ä»¶ã§é«˜å€¤ãƒ”ãƒ¼ã‚¯{relaxed_highs}ä»¶ã€å®‰å€¤ãƒœãƒˆãƒ {relaxed_lows}ä»¶ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"
            )

        # é«˜å€¤/å®‰å€¤ã®é »åº¦åˆ†æ
        high_freq = high_patterns["high_frequency"]
        low_freq = low_patterns["low_frequency"]

        if high_freq < 0.1:
            recommendations.append("é«˜å€¤ãƒ”ãƒ¼ã‚¯ã®é »åº¦ãŒä½ã™ãã¾ã™ã€‚æ¤œå‡ºæ¡ä»¶ã‚’ã•ã‚‰ã«ç·©å’Œã—ã¦ãã ã•ã„ã€‚")

        if low_freq < 0.1:
            recommendations.append("å®‰å€¤ãƒœãƒˆãƒ ã®é »åº¦ãŒä½ã™ãã¾ã™ã€‚æ¤œå‡ºæ¡ä»¶ã‚’ã•ã‚‰ã«ç·©å’Œã—ã¦ãã ã•ã„ã€‚")

        return recommendations


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    analyzer = RealDataPatternAnalyzer()
    results = await analyzer.analyze_real_data_patterns()

    if "error" in results:
        print(f"\nâŒ åˆ†æã‚¨ãƒ©ãƒ¼: {results['error']}")
        return

    print("\n=== å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ ===")

    # åŸºæœ¬çµ±è¨ˆ
    print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
    stats = results["basic_stats"]
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {stats['total_points']}")
    print(f"  ä¾¡æ ¼ç¯„å›²: {stats['price_range']}")
    print(f"  å¹³å‡ä¾¡æ ¼: {stats['avg_price']:.4f}")
    print(f"  ä¾¡æ ¼ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {stats['price_volatility']:.4f}")
    print(f"  é«˜å€¤ç¯„å›²: {stats['high_range']}")
    print(f"  å®‰å€¤ç¯„å›²: {stats['low_range']}")

    # é«˜å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³
    print(f"\nğŸ”´ é«˜å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    high_patterns = results["high_patterns"]
    print(f"  å³æ ¼ãªãƒ”ãƒ¼ã‚¯: {len(high_patterns['strict_peaks'])}ä»¶")
    print(f"  ç·©å’Œã•ã‚ŒãŸãƒ”ãƒ¼ã‚¯: {len(high_patterns['relaxed_peaks'])}ä»¶")
    print(f"  é«˜å€¤é »åº¦: {high_patterns['high_frequency']:.4f}")
    if high_patterns["consecutive_highs"]:
        print(f"  é€£ç¶šé«˜å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³: {high_patterns['consecutive_highs'][:5]}")  # æœ€åˆã®5ä»¶ã®ã¿

    # å®‰å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³
    print(f"\nğŸŸ¢ å®‰å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³:")
    low_patterns = results["low_patterns"]
    print(f"  å³æ ¼ãªãƒœãƒˆãƒ : {len(low_patterns['strict_bottoms'])}ä»¶")
    print(f"  ç·©å’Œã•ã‚ŒãŸãƒœãƒˆãƒ : {len(low_patterns['relaxed_bottoms'])}ä»¶")
    print(f"  å®‰å€¤é »åº¦: {low_patterns['low_frequency']:.4f}")
    if low_patterns["consecutive_lows"]:
        print(f"  é€£ç¶šå®‰å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³: {low_patterns['consecutive_lows'][:5]}")  # æœ€åˆã®5ä»¶ã®ã¿

    # ä¾¡æ ¼å¤‰å‹•
    print(f"\nğŸ“ˆ ä¾¡æ ¼å¤‰å‹•:")
    movements = results["price_movements"]
    price_changes = movements["price_changes"]
    if price_changes:
        print(f"  å¹³å‡ä¾¡æ ¼å¤‰åŒ–: {sum(price_changes) / len(price_changes):.4f}")
        print(f"  æœ€å¤§ä¾¡æ ¼å¤‰åŒ–: {max(price_changes, key=abs):.4f}")

    # æ¨å¥¨äº‹é …
    print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
    for recommendation in results["recommendations"]:
        print(f"  â€¢ {recommendation}")


if __name__ == "__main__":
    asyncio.run(main())
