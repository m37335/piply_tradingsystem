#!/usr/bin/env python3
"""
SQLite to PostgreSQL Migration Script
SQLiteã‹ã‚‰PostgreSQLã¸ã®ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python scripts/migration/sqlite_to_postgresql_migration.py
"""

import asyncio
import json
import os
import sqlite3
from datetime import datetime
from typing import Any, Dict, List, Optional

import asyncpg
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

from src.infrastructure.database.connection import DatabaseManager
from src.utils.logging_config import get_infrastructure_logger

logger = get_infrastructure_logger()


class SQLiteToPostgreSQLMigration:
    """SQLiteã‹ã‚‰PostgreSQLã¸ã®ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self, sqlite_path: str, postgresql_url: str):
        self.sqlite_path = sqlite_path
        self.postgresql_url = postgresql_url
        self.sqlite_conn = None
        self.postgresql_pool = None

    async def initialize(self):
        """åˆæœŸåŒ–"""
        # SQLiteæ¥ç¶š
        self.sqlite_conn = sqlite3.connect(self.sqlite_path)
        self.sqlite_conn.row_factory = sqlite3.Row

        # PostgreSQLæ¥ç¶šãƒ—ãƒ¼ãƒ«
        self.postgresql_pool = await asyncpg.create_pool(
            host="localhost",
            port=5432,
            database="exchange_analytics_production_db",
            user="exchange_analytics_user",
            password="exchange_password",
        )

        logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    async def close(self):
        """æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.sqlite_conn:
            self.sqlite_conn.close()
        if self.postgresql_pool:
            await self.postgresql_pool.close()

    def get_sqlite_tables(self) -> List[str]:
        """SQLiteã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        cursor = self.sqlite_conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        cursor.close()
        return tables

    async def get_postgresql_tables(self) -> List[str]:
        """PostgreSQLã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        async with self.postgresql_pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name
                """
            )
            return [row['table_name'] for row in rows]

    def get_table_schema(self, table_name: str) -> List[Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—"""
        cursor = self.sqlite_conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = []
        for row in cursor.fetchall():
            columns.append({
                'name': row[1],
                'type': row[2],
                'notnull': bool(row[3]),
                'default': row[4],
                'pk': bool(row[5])
            })
        cursor.close()
        return columns

    def get_table_data(self, table_name: str, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        cursor = self.sqlite_conn.cursor()
        
        if limit:
            cursor.execute(f"SELECT * FROM {table_name} LIMIT {limit}")
        else:
            cursor.execute(f"SELECT * FROM {table_name}")
        
        rows = cursor.fetchall()
        data = []
        for row in rows:
            row_dict = {}
            for i, column in enumerate(row.keys()):
                value = row[i]
                # JSONæ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
                if isinstance(value, str) and (value.startswith('{') or value.startswith('[')):
                    try:
                        value = json.loads(value)
                    except json.JSONDecodeError:
                        pass
                # æ—¥æ™‚æ–‡å­—åˆ—ã®å ´åˆã¯datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                elif isinstance(value, str) and ' ' in value and ':' in value:
                    try:
                        from datetime import datetime
                        # SQLiteã®æ—¥æ™‚å½¢å¼ã‚’è§£æ
                        if '.' in value:  # ãƒã‚¤ã‚¯ãƒ­ç§’ä»˜ã
                            value = datetime.strptime(value, '%Y-%m-%d %H:%M:%S.%f')
                        else:  # ãƒã‚¤ã‚¯ãƒ­ç§’ãªã—
                            value = datetime.strptime(value, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        pass  # å¤‰æ›ã§ããªã„å ´åˆã¯ãã®ã¾ã¾
                row_dict[column] = value
            data.append(row_dict)
        
        cursor.close()
        return data

    async def migrate_table(self, table_name: str, batch_size: int = 1000) -> int:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç§»è¡Œ"""
        logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã®ç§»è¡Œã‚’é–‹å§‹...")

        # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        data = self.get_table_data(table_name)
        total_rows = len(data)
        
        if total_rows == 0:
            logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã¯ç©ºã§ã™")
            return 0

        # ãƒãƒƒãƒå‡¦ç†ã§æŒ¿å…¥
        migrated_count = 0
        for i in range(0, total_rows, batch_size):
            batch = data[i:i + batch_size]
            
            try:
                await self._insert_batch(table_name, batch)
                migrated_count += len(batch)
                logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name}: {migrated_count}/{total_rows} ä»¶ç§»è¡Œå®Œäº†")
            except Exception as e:
                logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã®ãƒãƒƒãƒæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {e}")
                raise

        logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã®ç§»è¡Œå®Œäº†: {migrated_count} ä»¶")
        return migrated_count

    async def _insert_batch(self, table_name: str, batch: List[Dict[str, Any]]):
        """ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥"""
        if not batch:
            return

        # ã‚«ãƒ©ãƒ åã‚’å–å¾—
        columns = list(batch[0].keys())
        placeholders = [f"${i+1}" for i in range(len(columns))]
        
        # INSERTæ–‡ã‚’ä½œæˆ
        query = f"""
        INSERT INTO {table_name} ({', '.join(columns)})
        VALUES ({', '.join(placeholders)})
        ON CONFLICT DO NOTHING
        """

        async with self.postgresql_pool.acquire() as conn:
            # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            values = []
            for row in batch:
                row_values = []
                for column in columns:
                    value = row.get(column)
                    # JSONãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æ–‡å­—åˆ—åŒ–
                    if isinstance(value, (dict, list)):
                        value = json.dumps(value)
                    row_values.append(value)
                values.append(row_values)

            # ãƒãƒƒãƒæŒ¿å…¥å®Ÿè¡Œ
            await conn.executemany(query, values)

    async def migrate_all_tables(self) -> Dict[str, int]:
        """å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç§»è¡Œ"""
        logger.info("ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚’é–‹å§‹ã—ã¾ã™...")

        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
        sqlite_tables = self.get_sqlite_tables()
        postgresql_tables = await self.get_postgresql_tables()

        logger.info(f"SQLiteãƒ†ãƒ¼ãƒ–ãƒ«: {sqlite_tables}")
        logger.info(f"PostgreSQLãƒ†ãƒ¼ãƒ–ãƒ«: {postgresql_tables}")

        # å…±é€šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç§»è¡Œ
        common_tables = set(sqlite_tables) & set(postgresql_tables)
        migration_results = {}

        for table_name in sorted(common_tables):
            try:
                count = await self.migrate_table(table_name)
                migration_results[table_name] = count
            except Exception as e:
                logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name} ã®ç§»è¡Œã«å¤±æ•—: {e}")
                migration_results[table_name] = 0

        return migration_results

    async def verify_migration(self) -> Dict[str, Dict[str, int]]:
        """ç§»è¡Œçµæœã‚’æ¤œè¨¼"""
        logger.info("ç§»è¡Œçµæœã‚’æ¤œè¨¼ã—ã¾ã™...")

        sqlite_tables = self.get_sqlite_tables()
        postgresql_tables = await self.get_postgresql_tables()
        common_tables = set(sqlite_tables) & set(postgresql_tables)

        verification_results = {}

        for table_name in sorted(common_tables):
            # SQLiteã®è¡Œæ•°ã‚’å–å¾—
            cursor = self.sqlite_conn.cursor()
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            sqlite_count = cursor.fetchone()[0]
            cursor.close()

            # PostgreSQLã®è¡Œæ•°ã‚’å–å¾—
            async with self.postgresql_pool.acquire() as conn:
                postgresql_count = await conn.fetchval(f"SELECT COUNT(*) FROM {table_name}")

            verification_results[table_name] = {
                'sqlite_count': sqlite_count,
                'postgresql_count': postgresql_count,
                'match': sqlite_count == postgresql_count
            }

            logger.info(f"ãƒ†ãƒ¼ãƒ–ãƒ« {table_name}: SQLite={sqlite_count}, PostgreSQL={postgresql_count}, ä¸€è‡´={sqlite_count == postgresql_count}")

        return verification_results


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # è¨­å®š
    sqlite_path = "/app/data/exchange_analytics.db"
    postgresql_url = "postgresql+asyncpg://exchange_analytics_user:exchange_password@localhost:5432/exchange_analytics_production_db"

    # ç§»è¡Œã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    migration = SQLiteToPostgreSQLMigration(sqlite_path, postgresql_url)

    try:
        # åˆæœŸåŒ–
        await migration.initialize()

        # ç§»è¡Œå®Ÿè¡Œ
        results = await migration.migrate_all_tables()

        # çµæœè¡¨ç¤º
        logger.info("=== ç§»è¡Œçµæœ ===")
        total_migrated = 0
        for table_name, count in results.items():
            logger.info(f"{table_name}: {count} ä»¶")
            total_migrated += count

        logger.info(f"ç·ç§»è¡Œä»¶æ•°: {total_migrated} ä»¶")

        # æ¤œè¨¼
        verification = await migration.verify_migration()
        
        logger.info("=== æ¤œè¨¼çµæœ ===")
        all_match = True
        for table_name, result in verification.items():
            status = "âœ…" if result['match'] else "âŒ"
            logger.info(f"{status} {table_name}: SQLite={result['sqlite_count']}, PostgreSQL={result['postgresql_count']}")
            if not result['match']:
                all_match = False

        if all_match:
            logger.info("ğŸ‰ å…¨ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã§ç§»è¡ŒãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        else:
            logger.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã§ç§»è¡Œã«å•é¡ŒãŒã‚ã‚Šã¾ã™")

    except Exception as e:
        logger.error(f"ç§»è¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        raise
    finally:
        await migration.close()


if __name__ == "__main__":
    asyncio.run(main())
