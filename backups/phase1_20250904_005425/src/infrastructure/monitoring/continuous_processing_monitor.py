"""
ç¶™ç¶šå‡¦ç†ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹

è²¬ä»»:
- ç¶™ç¶šå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç›£è¦–
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®åé›†
- ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
- ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã®ç›£è¦–

ç‰¹å¾´:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
- è‡ªå‹•ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- éšœå®³æ¤œçŸ¥
"""

import logging
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class ContinuousProcessingMonitor:
    """
    ç¶™ç¶šå‡¦ç†ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹

    è²¬ä»»:
    - ç¶™ç¶šå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç›£è¦–
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã®åé›†
    - ã‚¨ãƒ©ãƒ¼æ¤œå‡ºã¨ã‚¢ãƒ©ãƒ¼ãƒˆ
    - ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ã®ç›£è¦–
    """

    def __init__(self):
        self.metrics = {
            "processing_times": [],
            "error_counts": {},
            "success_rates": {},
            "data_volumes": [],
            "system_health": {},
            "alert_history": [],
        }

        # ç›£è¦–è¨­å®š
        self.alert_thresholds = {
            "max_processing_time": 300,  # 5åˆ†
            "min_success_rate": 0.8,  # 80%ï¼ˆåˆæœŸåŒ–æ™‚ã«å¯¾å¿œï¼‰
            "max_error_count": 5,  # 5å›
            "max_consecutive_failures": 3,  # 3å›
            "min_data_volume": 1,  # 1ä»¶ï¼ˆåˆæœŸåŒ–æ™‚ã«å¯¾å¿œï¼‰
        }

        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_cycles": 0,
            "successful_cycles": 0,
            "failed_cycles": 0,
            "total_alerts": 0,
            "last_alert": None,
            "monitoring_start_time": datetime.now(),
        }

        # ç›£è¦–çŠ¶æ…‹
        self.is_monitoring = False
        self.monitoring_interval = 60  # ç§’

    async def start_monitoring(self):
        """
        ç›£è¦–ã‚’é–‹å§‹
        """
        if self.is_monitoring:
            logger.warning("âš ï¸ ç›£è¦–ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
            return

        try:
            logger.info("ğŸ” ç¶™ç¶šå‡¦ç†ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™")
            self.is_monitoring = True
            self.stats["monitoring_start_time"] = datetime.now()

        except Exception as e:
            logger.error(f"âŒ ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            self.is_monitoring = False
            raise

    async def stop_monitoring(self):
        """
        ç›£è¦–ã‚’åœæ­¢
        """
        if not self.is_monitoring:
            logger.warning("âš ï¸ ç›£è¦–ã¯æ—¢ã«åœæ­¢ã—ã¦ã„ã¾ã™")
            return

        try:
            logger.info("ğŸ›‘ ç¶™ç¶šå‡¦ç†ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™")
            self.is_monitoring = False

        except Exception as e:
            logger.error(f"âŒ ç›£è¦–åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def monitor_processing_cycle(self, cycle_data: Dict[str, Any]):
        """
        å‡¦ç†ã‚µã‚¤ã‚¯ãƒ«ã®ç›£è¦–

        Args:
            cycle_data: ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿
        """
        try:
            if not self.is_monitoring:
                return

            self.stats["total_cycles"] += 1

            # å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
            processing_time = cycle_data.get("processing_time", 0)
            self.metrics["processing_times"].append(processing_time)

            # å‡¦ç†æ™‚é–“ã®é–¾å€¤ãƒã‚§ãƒƒã‚¯
            if processing_time > self.alert_thresholds["max_processing_time"]:
                await self.send_alert(
                    "PERFORMANCE", f"å‡¦ç†æ™‚é–“ãŒé–¾å€¤ã‚’è¶…é: {processing_time:.2f}ç§’"
                )

            # æˆåŠŸç‡ã‚’è¨ˆç®—
            total_runs = cycle_data.get("total_runs", 0)
            successful_runs = cycle_data.get("successful_runs", 0)

            if total_runs > 0:
                success_rate = successful_runs / total_runs
                self.metrics["success_rates"]["overall"] = success_rate

                if success_rate < self.alert_thresholds["min_success_rate"]:
                    await self.send_alert(
                        "RELIABILITY", f"æˆåŠŸç‡ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹: {success_rate:.2%}"
                    )

            # ãƒ‡ãƒ¼ã‚¿é‡ã‚’è¨˜éŒ²
            data_volume = cycle_data.get("data_volume", 0)
            self.metrics["data_volumes"].append(data_volume)

            if data_volume < self.alert_thresholds["min_data_volume"]:
                await self.send_alert(
                    "DATA_VOLUME", f"ãƒ‡ãƒ¼ã‚¿é‡ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹: {data_volume}ä»¶"
                )

            # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¨˜éŒ²
            error_count = cycle_data.get("error_count", 0)
            if error_count > 0:
                self.metrics["error_counts"][datetime.now().isoformat()] = error_count

                if error_count > self.alert_thresholds["max_error_count"]:
                    await self.send_alert(
                        "ERROR_RATE", f"ã‚¨ãƒ©ãƒ¼æ•°ãŒé–¾å€¤ã‚’è¶…é: {error_count}å›"
                    )

            # æˆåŠŸã‚µã‚¤ã‚¯ãƒ«ã¨ã—ã¦è¨˜éŒ²
            if cycle_data.get("status") == "success":
                self.stats["successful_cycles"] += 1
            else:
                self.stats["failed_cycles"] += 1

        except Exception as e:
            logger.error(f"âŒ å‡¦ç†ã‚µã‚¤ã‚¯ãƒ«ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")

    async def check_system_health(self) -> Dict[str, Any]:
        """
        ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯

        Returns:
            Dict[str, Any]: å¥å…¨æ€§æƒ…å ±
        """
        try:
            health_status = {
                "service": "ContinuousProcessingMonitor",
                "status": "healthy",
                "timestamp": datetime.now(),
                "is_monitoring": self.is_monitoring,
                "uptime": (
                    datetime.now() - self.stats["monitoring_start_time"]
                ).total_seconds(),
            }

            # å‡¦ç†æ™‚é–“ã®åˆ†æ
            if self.metrics["processing_times"]:
                avg_processing_time = sum(self.metrics["processing_times"]) / len(
                    self.metrics["processing_times"]
                )
                max_processing_time = max(self.metrics["processing_times"])
                health_status["processing_time"] = {
                    "average": avg_processing_time,
                    "max": max_processing_time,
                    "threshold": self.alert_thresholds["max_processing_time"],
                }

                if avg_processing_time > self.alert_thresholds["max_processing_time"]:
                    health_status["status"] = "degraded"
                    health_status["issues"] = ["å‡¦ç†æ™‚é–“ãŒé–¾å€¤ã‚’è¶…é"]

            # æˆåŠŸç‡ã®åˆ†æ
            if "overall" in self.metrics["success_rates"]:
                success_rate = self.metrics["success_rates"]["overall"]
                health_status["success_rate"] = {
                    "current": success_rate,
                    "threshold": self.alert_thresholds["min_success_rate"],
                }

                if success_rate < self.alert_thresholds["min_success_rate"]:
                    health_status["status"] = "degraded"
                    if "issues" not in health_status:
                        health_status["issues"] = []
                    health_status["issues"].append("æˆåŠŸç‡ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹")

            # ã‚¨ãƒ©ãƒ¼ç‡ã®åˆ†æ
            if self.metrics["error_counts"]:
                recent_errors = sum(
                    count
                    for timestamp, count in self.metrics["error_counts"].items()
                    if datetime.fromisoformat(timestamp)
                    > datetime.now() - timedelta(hours=1)
                )
                health_status["error_rate"] = {
                    "recent_errors": recent_errors,
                    "threshold": self.alert_thresholds["max_error_count"],
                }

                if recent_errors > self.alert_thresholds["max_error_count"]:
                    health_status["status"] = "degraded"
                    if "issues" not in health_status:
                        health_status["issues"] = []
                    health_status["issues"].append("ã‚¨ãƒ©ãƒ¼æ•°ãŒé–¾å€¤ã‚’è¶…é")

            # ãƒ‡ãƒ¼ã‚¿é‡ã®åˆ†æ
            if self.metrics["data_volumes"]:
                recent_data_volume = sum(
                    volume for volume in self.metrics["data_volumes"][-10:]
                )
                health_status["data_volume"] = {
                    "recent_total": recent_data_volume,
                    "threshold": self.alert_thresholds["min_data_volume"],
                }

                if recent_data_volume < self.alert_thresholds["min_data_volume"]:
                    health_status["status"] = "degraded"
                    if "issues" not in health_status:
                        health_status["issues"] = []
                    health_status["issues"].append("ãƒ‡ãƒ¼ã‚¿é‡ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹")

            # çµ±è¨ˆæƒ…å ±
            health_status["stats"] = {
                "total_cycles": self.stats["total_cycles"],
                "successful_cycles": self.stats["successful_cycles"],
                "failed_cycles": self.stats["failed_cycles"],
                "total_alerts": self.stats["total_alerts"],
            }

            return health_status

        except Exception as e:
            logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "service": "ContinuousProcessingMonitor",
                "status": "unhealthy",
                "error": str(e),
                "timestamp": datetime.now(),
            }

    async def send_alert(self, alert_type: str, message: str):
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡

        Args:
            alert_type: ã‚¢ãƒ©ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—
            message: ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        try:
            alert_data = {
                "timestamp": datetime.now(),
                "type": alert_type,
                "message": message,
                "severity": self._get_alert_severity(alert_type),
            }

            # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ã«è¿½åŠ 
            self.metrics["alert_history"].append(alert_data)
            self.stats["total_alerts"] += 1
            self.stats["last_alert"] = datetime.now()

            # ãƒ­ã‚°å‡ºåŠ›
            logger.warning(f"ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆ [{alert_type}]: {message}")

            # å®Ÿéš›ã®ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ï¼ˆå®Ÿè£…äºˆå®šï¼‰
            # await self._send_notification(alert_data)

        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    def _get_alert_severity(self, alert_type: str) -> str:
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«åŸºã¥ãé‡è¦åº¦ã‚’å–å¾—

        Args:
            alert_type: ã‚¢ãƒ©ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—

        Returns:
            str: é‡è¦åº¦ï¼ˆcritical, warning, infoï¼‰
        """
        severity_map = {
            "PERFORMANCE": "warning",
            "RELIABILITY": "critical",
            "ERROR_RATE": "critical",
            "DATA_VOLUME": "warning",
            "SYSTEM_HEALTH": "critical",
        }
        return severity_map.get(alert_type, "info")

    async def get_monitoring_metrics(self) -> Dict[str, Any]:
        """
        ç›£è¦–æŒ‡æ¨™ã‚’å–å¾—

        Returns:
            Dict[str, Any]: ç›£è¦–æŒ‡æ¨™
        """
        try:
            return {
                "metrics": self.metrics,
                "stats": self.stats,
                "thresholds": self.alert_thresholds,
                "is_monitoring": self.is_monitoring,
                "monitoring_interval": self.monitoring_interval,
            }

        except Exception as e:
            logger.error(f"âŒ ç›£è¦–æŒ‡æ¨™å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    async def reset_metrics(self):
        """
        ç›£è¦–æŒ‡æ¨™ã‚’ãƒªã‚»ãƒƒãƒˆ
        """
        try:
            self.metrics = {
                "processing_times": [],
                "error_counts": {},
                "success_rates": {},
                "data_volumes": {},
                "system_health": {},
                "alert_history": [],
            }

            self.stats = {
                "total_cycles": 0,
                "successful_cycles": 0,
                "failed_cycles": 0,
                "total_alerts": 0,
                "last_alert": None,
                "monitoring_start_time": datetime.now(),
            }

            logger.info("ğŸ”„ ç›£è¦–æŒ‡æ¨™ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error(f"âŒ ç›£è¦–æŒ‡æ¨™ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    async def update_alert_thresholds(
        self,
        max_processing_time: Optional[int] = None,
        min_success_rate: Optional[float] = None,
        max_error_count: Optional[int] = None,
        max_consecutive_failures: Optional[int] = None,
        min_data_volume: Optional[int] = None,
    ):
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤ã‚’æ›´æ–°

        Args:
            max_processing_time: æœ€å¤§å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰
            min_success_rate: æœ€å°æˆåŠŸç‡
            max_error_count: æœ€å¤§ã‚¨ãƒ©ãƒ¼æ•°
            max_consecutive_failures: æœ€å¤§é€£ç¶šå¤±æ•—å›æ•°
            min_data_volume: æœ€å°ãƒ‡ãƒ¼ã‚¿é‡
        """
        try:
            if max_processing_time is not None:
                self.alert_thresholds["max_processing_time"] = max_processing_time
                logger.info(f"ğŸ”„ æœ€å¤§å‡¦ç†æ™‚é–“é–¾å€¤ã‚’æ›´æ–°: {max_processing_time}ç§’")

            if min_success_rate is not None:
                self.alert_thresholds["min_success_rate"] = min_success_rate
                logger.info(f"ğŸ”„ æœ€å°æˆåŠŸç‡é–¾å€¤ã‚’æ›´æ–°: {min_success_rate}")

            if max_error_count is not None:
                self.alert_thresholds["max_error_count"] = max_error_count
                logger.info(f"ğŸ”„ æœ€å¤§ã‚¨ãƒ©ãƒ¼æ•°é–¾å€¤ã‚’æ›´æ–°: {max_error_count}")

            if max_consecutive_failures is not None:
                self.alert_thresholds["max_consecutive_failures"] = (
                    max_consecutive_failures
                )
                logger.info(
                    f"ğŸ”„ æœ€å¤§é€£ç¶šå¤±æ•—å›æ•°é–¾å€¤ã‚’æ›´æ–°: {max_consecutive_failures}"
                )

            if min_data_volume is not None:
                self.alert_thresholds["min_data_volume"] = min_data_volume
                logger.info(f"ğŸ”„ æœ€å°ãƒ‡ãƒ¼ã‚¿é‡é–¾å€¤ã‚’æ›´æ–°: {min_data_volume}")

        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒ©ãƒ¼ãƒˆé–¾å€¤æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    async def get_alert_history(self, hours: int = 24) -> List[Dict[str, Any]]:
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ã‚’å–å¾—

        Args:
            hours: å–å¾—ã™ã‚‹æ™‚é–“ç¯„å›²ï¼ˆæ™‚é–“ï¼‰

        Returns:
            List[Dict[str, Any]]: ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´
        """
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_alerts = [
                alert
                for alert in self.metrics["alert_history"]
                if alert["timestamp"] > cutoff_time
            ]
            return recent_alerts

        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    async def analyze_performance_trends(self) -> Dict[str, Any]:
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘ã‚’åˆ†æ

        Returns:
            Dict[str, Any]: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœ
        """
        try:
            if not self.metrics["processing_times"]:
                return {"message": "åˆ†æãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"}

            processing_times = self.metrics["processing_times"]
            recent_times = processing_times[-10:]  # æœ€æ–°10ä»¶

            analysis = {
                "overall": {
                    "average": sum(processing_times) / len(processing_times),
                    "max": max(processing_times),
                    "min": min(processing_times),
                    "total_samples": len(processing_times),
                },
                "recent": {
                    "average": sum(recent_times) / len(recent_times),
                    "max": max(recent_times),
                    "min": min(recent_times),
                    "samples": len(recent_times),
                },
                "trend": "stable",
            }

            # å‚¾å‘åˆ†æ
            if len(recent_times) >= 5:
                recent_avg = sum(recent_times) / len(recent_times)
                overall_avg = sum(processing_times) / len(processing_times)

                if recent_avg > overall_avg * 1.05:  # 5%ä»¥ä¸Šã®å¢—åŠ 
                    analysis["trend"] = "degrading"
                elif recent_avg < overall_avg * 0.95:  # 5%ä»¥ä¸Šã®æ¸›å°‘
                    analysis["trend"] = "improving"

            return analysis

        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}
