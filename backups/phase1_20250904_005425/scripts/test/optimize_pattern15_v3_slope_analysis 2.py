"""
ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 å‚¾ãåˆ†æã¨æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒãƒƒãƒ•ã‚¡ç¸®å°1ã‚’æ¡ç”¨ã—ã€é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿ã§å‚¾ãï¼ˆslopeï¼‰ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸåˆ†æ
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict

import numpy as np
import pandas as pd
from sqlalchemy import text

from src.infrastructure.analysis.pattern_detectors.support_resistance_detector_v3 import (
    SupportResistanceDetectorV3,
)
from src.infrastructure.database.connection import db_manager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class Pattern15V3SlopeAnalyzer:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 å‚¾ãåˆ†æå™¨"""

    def __init__(self):
        self.timeframes = ["5m", "1h", "1d"]
        self.test_periods = [
            {"name": "6ãƒ¶æœˆ", "days": 180},
            {"name": "1å¹´", "days": 365},
            {"name": "2å¹´", "days": 730},
        ]
        
        # ãƒãƒƒãƒ•ã‚¡ç¸®å°1è¨­å®šï¼ˆæ¡ç”¨ï¼‰
        self.optimized_settings = {
            "5m": {
                "buffer_percentile": 10,
                "min_peaks": 3,
                "min_line_strength": 0.5,
                "max_angle": 30,
                "price_tolerance": 0.003,
            },
            "1h": {
                "buffer_percentile": 8,
                "min_peaks": 4,
                "min_line_strength": 0.7,
                "max_angle": 20,
                "price_tolerance": 0.002,
            },
            "1d": {
                "buffer_percentile": 5,
                "min_peaks": 5,
                "min_line_strength": 0.9,
                "max_angle": 15,
                "price_tolerance": 0.001,
            },
        }

    async def analyze_slope_patterns(self) -> Dict:
        """å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        logger.info("=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 å‚¾ãåˆ†æé–‹å§‹ ===")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            await db_manager.initialize(
                "sqlite+aiosqlite:///./data/exchange_analytics.db"
            )
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±å–å¾—
            db_info = await self._get_database_info()
            
            # é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿ã§ã®å‚¾ãåˆ†æ
            slope_analysis = await self._analyze_long_term_slopes()
            
            # æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ
            optimization_results = await self._test_optimized_settings()

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†
            await db_manager.close()

            return {
                "database_info": db_info,
                "slope_analysis": slope_analysis,
                "optimization_results": optimization_results,
                "analysis_time": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"å‚¾ãåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            await db_manager.close()
            return {"error": str(e)}

    async def _get_database_info(self) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
                count_query = text(
                    """
                    SELECT COUNT(*) as total_records
                    FROM price_data 
                    WHERE currency_pair = 'USD/JPY'
                    """
                )
                count_result = await session.execute(count_query)
                total_records = count_result.fetchone()[0]

                # ãƒ‡ãƒ¼ã‚¿æœŸé–“
                period_query = text(
                    """
                    SELECT 
                        MIN(timestamp) as start_date,
                        MAX(timestamp) as end_date
                    FROM price_data 
                    WHERE currency_pair = 'USD/JPY'
                    """
                )
                period_result = await session.execute(period_query)
                period_row = period_result.fetchone()
                start_date = period_row[0]
                end_date = period_row[1]

                return {
                    "total_records": total_records,
                    "start_date": start_date.isoformat() if start_date else None,
                    "end_date": end_date.isoformat() if end_date else None,
                    "data_span_days": (
                        (end_date - start_date).days if start_date and end_date else 0
                    ),
                }

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _analyze_long_term_slopes(self) -> Dict:
        """é•·æœŸé–“ãƒ‡ãƒ¼ã‚¿ã§ã®å‚¾ãåˆ†æ"""
        try:
            analysis = {}

            # æœ€é•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
            max_period = max(self.test_periods, key=lambda x: x["days"])
            data = await self._fetch_market_data(max_period["days"])
            
            if data.empty:
                return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}

            logger.info(f"é•·æœŸé–“å‚¾ãåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")

            # åŸºæœ¬çµ±è¨ˆ
            analysis["basic_statistics"] = self._analyze_basic_statistics(data)

            # å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            analysis["slope_patterns"] = self._analyze_slope_patterns(data)

            return analysis

        except Exception as e:
            logger.error(f"é•·æœŸé–“å‚¾ãåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_basic_statistics(self, data: pd.DataFrame) -> Dict:
        """åŸºæœ¬çµ±è¨ˆåˆ†æ"""
        try:
            high_prices = data["High"].values
            low_prices = data["Low"].values
            close_prices = data["Close"].values

            # ä¾¡æ ¼çµ±è¨ˆ
            price_stats = {
                "high_prices": {
                    "min": float(np.min(high_prices)),
                    "max": float(np.max(high_prices)),
                    "mean": float(np.mean(high_prices)),
                    "std": float(np.std(high_prices)),
                    "range": float(np.max(high_prices) - np.min(high_prices)),
                    "coefficient_of_variation": float(
                        np.std(high_prices) / np.mean(high_prices)
                    ),
                },
                "low_prices": {
                    "min": float(np.min(low_prices)),
                    "max": float(np.max(low_prices)),
                    "mean": float(np.mean(low_prices)),
                    "std": float(np.std(low_prices)),
                    "range": float(np.max(low_prices) - np.min(low_prices)),
                    "coefficient_of_variation": float(
                        np.std(low_prices) / np.mean(low_prices)
                    ),
                },
                "close_prices": {
                    "min": float(np.min(close_prices)),
                    "max": float(np.max(close_prices)),
                    "mean": float(np.mean(close_prices)),
                    "std": float(np.std(close_prices)),
                    "range": float(np.max(close_prices) - np.min(close_prices)),
                    "coefficient_of_variation": float(
                        np.std(close_prices) / np.mean(close_prices)
                    ),
                },
            }

            # ä¾¡æ ¼å¤‰åŒ–ç‡åˆ†æ
            price_changes = np.diff(close_prices) / close_prices[:-1]
            change_stats = {
                "mean_change": float(np.mean(price_changes)),
                "std_change": float(np.std(price_changes)),
                "max_change": float(np.max(price_changes)),
                "min_change": float(np.min(price_changes)),
                "abs_mean_change": float(np.mean(np.abs(price_changes))),
                "positive_changes_ratio": float(
                    np.sum(price_changes > 0) / len(price_changes)
                ),
            }

            return {
                "price_statistics": price_stats,
                "change_statistics": change_stats,
                "data_points": len(data),
            }

        except Exception as e:
            logger.error(f"åŸºæœ¬çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_slope_patterns(self, data: pd.DataFrame) -> Dict:
        """å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        try:
            analysis = {}

            close_prices = data["Close"].values

            # ç·šå½¢å›å¸°ã«ã‚ˆã‚‹å…¨ä½“å‚¾ã
            x = np.arange(len(close_prices))
            slope, intercept = np.polyfit(x, close_prices, 1)
            
            analysis["overall_trend"] = {
                "slope": float(slope),
                "intercept": float(intercept),
                "slope_per_day": float(slope),
                "slope_percentage": float(slope / np.mean(close_prices) * 100),
                "trend_direction": "ä¸Šæ˜‡" if slope > 0 else "ä¸‹é™" if slope < 0 else "æ¨ªã°ã„",
                "trend_strength": abs(slope) / np.std(close_prices),
            }

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥å‚¾ãåˆ†æ
            segment_size = len(close_prices) // 4
            segment_slopes = {}

            for i in range(4):
                start_idx = i * segment_size
                end_idx = (i + 1) * segment_size if i < 3 else len(close_prices)
                
                segment_prices = close_prices[start_idx:end_idx]
                segment_x = np.arange(len(segment_prices))
                
                if len(segment_prices) > 1:
                    seg_slope, seg_intercept = np.polyfit(segment_x, segment_prices, 1)
                    
                    segment_slopes[f"segment_{i+1}"] = {
                        "slope": float(seg_slope),
                        "intercept": float(seg_intercept),
                        "trend_direction": "ä¸Šæ˜‡" if seg_slope > 0 else "ä¸‹é™" if seg_slope < 0 else "æ¨ªã°ã„",
                        "data_points": len(segment_prices),
                    }

            analysis["segment_slopes"] = segment_slopes

            return analysis

        except Exception as e:
            logger.error(f"å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _test_optimized_settings(self) -> Dict:
        """æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ"""
        try:
            results = {}

            for timeframe in self.timeframes:
                logger.info(f"æœ€é©åŒ–è¨­å®šãƒ†ã‚¹ãƒˆ: {timeframe}")
                timeframe_results = {}

                for period in self.test_periods:
                    logger.info(f"  æœŸé–“: {period['name']}")
                    result = await self._test_with_optimized_settings(
                        timeframe, period
                    )
                    timeframe_results[period["name"]] = result

                # æ™‚é–“è¶³åˆ¥çµ±è¨ˆ
                timeframe_stats = self._analyze_timeframe_statistics(timeframe_results)
                timeframe_results["statistics"] = timeframe_stats

                results[timeframe] = timeframe_results

            return results

        except Exception as e:
            logger.error(f"æœ€é©åŒ–è¨­å®šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def _test_with_optimized_settings(
        self, timeframe: str, period: Dict
    ) -> Dict:
        """æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            data = await self._fetch_market_data(period["days"])
            if data.empty:
                return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}

            logger.info(f"    å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")

            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ†ã‚¯ã‚¿ãƒ¼ä½œæˆ
            detector = self._create_optimized_detector(timeframe)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            detection = detector.detect(data)

            if detection:
                # è©³ç´°åˆ†æ
                detailed_analysis = self._analyze_detection_with_slope_details(
                    detection, data, timeframe, period
                )
                return {
                    "detected": True,
                    "detection": detection,
                    "analysis": detailed_analysis,
                    "data_points": len(data),
                    "period_days": period["days"],
                    "settings": self.optimized_settings[timeframe],
                }
            else:
                return {
                    "detected": False,
                    "data_points": len(data),
                    "period_days": period["days"],
                    "settings": self.optimized_settings[timeframe],
                }

        except Exception as e:
            logger.error(f"æœ€é©åŒ–è¨­å®šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _create_optimized_detector(self, timeframe: str) -> SupportResistanceDetectorV3:
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ†ã‚¯ã‚¿ãƒ¼ä½œæˆ"""
        detector = SupportResistanceDetectorV3(timeframe)
        
        # ãƒãƒƒãƒ•ã‚¡ç¸®å°1è¨­å®šã‚’é©ç”¨
        settings = self.optimized_settings[timeframe]
        detector.min_peaks = settings["min_peaks"]
        detector.buffer_percentile = settings["buffer_percentile"]
        detector.min_line_strength = settings["min_line_strength"]
        detector.max_angle = settings["max_angle"]
        detector.price_tolerance = settings["price_tolerance"]
        
        return detector

    def _analyze_detection_with_slope_details(
        self, detection: Dict, data: pd.DataFrame, timeframe: str, period: Dict
    ) -> Dict:
        """å‚¾ãè©³ç´°ã‚’å«ã‚€æ¤œå‡ºåˆ†æ"""
        try:
            analysis = {}

            # åŸºæœ¬æƒ…å ±
            pattern_data = detection.get("pattern_data", {})
            equation = pattern_data.get("equation", {})

            analysis["basic_info"] = {
                "pattern_type": detection.get("pattern_type"),
                "confidence": detection.get("confidence_score"),
                "direction": detection.get("direction"),
                "strategy": detection.get("strategy"),
                "timeframe": timeframe,
                "period": period["name"],
                "settings": self.optimized_settings[timeframe],
            }

            # æ•°å­¦çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå‚¾ãé‡è¦–ï¼‰
            slope = equation.get("slope", 0)
            angle = equation.get("angle", 0)
            
            analysis["mathematical"] = {
                "slope": slope,
                "intercept": equation.get("intercept"),
                "angle": angle,
                "equation_score": equation.get("score"),
                "slope_description": self._get_slope_description(slope),
                "angle_description": self._get_angle_description(angle),
            }

            # å‚¾ãã®è©³ç´°åˆ†æ
            analysis["slope_analysis"] = self._analyze_slope_details(
                equation, data, pattern_data, timeframe
            )

            # ãƒãƒƒãƒ•ã‚¡åˆ†æ
            analysis["buffer_analysis"] = self._analyze_buffer_effectiveness(
                data, pattern_data, self.optimized_settings[timeframe]
            )

            return analysis

        except Exception as e:
            logger.error(f"å‚¾ãè©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_slope_details(
        self, equation: Dict, data: pd.DataFrame, pattern_data: Dict, timeframe: str
    ) -> Dict:
        """å‚¾ãã®è©³ç´°åˆ†æ"""
        try:
            analysis = {}

            slope = equation.get("slope", 0)
            angle = equation.get("angle", 0)

            # å‚¾ãã®åŸºæœ¬æƒ…å ±
            analysis["slope_basic"] = {
                "slope_value": slope,
                "angle_degrees": angle,
                "angle_abs": abs(angle),
                "is_horizontal": abs(angle) < 5,
                "is_vertical": abs(angle) > 85,
            }

            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
            high_prices = data["High"].values
            low_prices = data["Low"].values
            close_prices = data["Close"].values

            # ä¾¡æ ¼ã®ä¸€è²«æ€§åˆ†æ
            price_consistency = {
                "high_price_std": float(np.std(high_prices)),
                "low_price_std": float(np.std(low_prices)),
                "close_price_std": float(np.std(close_prices)),
                "price_range": float(np.max(high_prices) - np.min(low_prices)),
                "price_range_ratio": float(
                    (np.max(high_prices) - np.min(low_prices)) / np.mean(close_prices)
                ),
            }

            analysis["price_consistency"] = price_consistency

            # æ¥µå€¤ã®åˆ†æ
            peaks = pattern_data.get("peaks", [])
            troughs = pattern_data.get("troughs", [])
            
            if peaks:
                peak_prices = [high_prices[i] for i in peaks]
                analysis["peak_analysis"] = {
                    "peak_prices": peak_prices,
                    "peak_price_std": float(np.std(peak_prices)),
                    "peak_price_range": float(
                        np.max(peak_prices) - np.min(peak_prices)
                    ),
                    "peak_price_mean": float(np.mean(peak_prices)),
                }

            if troughs:
                trough_prices = [low_prices[i] for i in troughs]
                analysis["trough_analysis"] = {
                    "trough_prices": trough_prices,
                    "trough_price_std": float(np.std(trough_prices)),
                    "trough_price_range": float(
                        np.max(trough_prices) - np.min(trough_prices)
                    ),
                    "trough_price_mean": float(np.mean(trough_prices)),
                }

            # å‚¾ãã®ç†ç”±åˆ†æ
            analysis["slope_reasons"] = {
                "price_stability": price_consistency["price_range_ratio"] < 0.01,
                "peak_uniformity": len(peaks) > 0
                and analysis.get("peak_analysis", {}).get("peak_price_std", 1) < 0.001,
                "trough_uniformity": len(troughs) > 0
                and analysis.get("trough_analysis", {}).get("trough_price_std", 1) < 0.001,
                "timeframe_effect": timeframe in ["1h", "1d"],
                "slope_magnitude": abs(slope) < 0.001,  # å‚¾ããŒéå¸¸ã«å°ã•ã„
            }

            return analysis

        except Exception as e:
            logger.error(f"å‚¾ãè©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_buffer_effectiveness(
        self, data: pd.DataFrame, pattern_data: Dict, settings: Dict
    ) -> Dict:
        """ãƒãƒƒãƒ•ã‚¡ã®åŠ¹æœåˆ†æ"""
        try:
            analysis = {}

            buffer_percentile = settings["buffer_percentile"]
            high_prices = data["High"].values
            low_prices = data["Low"].values

            # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã®åŠ¹æœ
            high_threshold = np.percentile(high_prices, 100 - buffer_percentile)
            low_threshold = np.percentile(low_prices, buffer_percentile)

            high_buffer_points = np.sum(high_prices >= high_threshold)
            low_buffer_points = np.sum(low_prices <= low_threshold)

            analysis["buffer_effectiveness"] = {
                "buffer_percentile": buffer_percentile,
                "high_threshold": float(high_threshold),
                "low_threshold": float(low_threshold),
                "high_buffer_points": int(high_buffer_points),
                "low_buffer_points": int(low_buffer_points),
                "high_buffer_ratio": float(high_buffer_points / len(high_prices)),
                "low_buffer_ratio": float(low_buffer_points / len(low_prices)),
                "total_buffer_points": int(high_buffer_points + low_buffer_points),
            }

            # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã¨æ¤œå‡ºå“è³ªã®é–¢ä¿‚
            peaks = pattern_data.get("peaks", [])
            troughs = pattern_data.get("troughs", [])
            
            analysis["detection_quality"] = {
                "peak_count": len(peaks),
                "trough_count": len(troughs),
                "total_extremums": len(peaks) + len(troughs),
                "buffer_efficiency": (
                    float(
                        (len(peaks) + len(troughs))
                        / (high_buffer_points + low_buffer_points)
                    )
                    if (high_buffer_points + low_buffer_points) > 0
                    else 0
                ),
            }

            return analysis

        except Exception as e:
            logger.error(f"ãƒãƒƒãƒ•ã‚¡åŠ¹æœåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_timeframe_statistics(self, timeframe_results: Dict) -> Dict:
        """æ™‚é–“è¶³åˆ¥çµ±è¨ˆåˆ†æ"""
        try:
            stats = {
                "total_periods": len(
                    [k for k in timeframe_results.keys() if k != "statistics"]
                ),
                "detection_count": 0,
                "detection_rate": 0.0,
                "period_detections": {},
                "confidence_by_period": {},
                "slope_by_period": {},
                "angle_by_period": {},
                "buffer_efficiency_by_period": {},
            }

            for period_name, result in timeframe_results.items():
                if period_name == "statistics":
                    continue

                if result.get("detected", False):
                    stats["detection_count"] += 1
                    stats["period_detections"][period_name] = True

                    # ä¿¡é ¼åº¦çµ±è¨ˆ
                    confidence = result["detection"].get("confidence_score", 0)
                    if period_name not in stats["confidence_by_period"]:
                        stats["confidence_by_period"][period_name] = []
                    stats["confidence_by_period"][period_name].append(confidence)

                    # å‚¾ãçµ±è¨ˆ
                    slope = result["analysis"]["mathematical"]["slope"]
                    if period_name not in stats["slope_by_period"]:
                        stats["slope_by_period"][period_name] = []
                    stats["slope_by_period"][period_name].append(slope)

                    # è§’åº¦çµ±è¨ˆ
                    angle = result["analysis"]["mathematical"]["angle"]
                    if period_name not in stats["angle_by_period"]:
                        stats["angle_by_period"][period_name] = []
                    stats["angle_by_period"][period_name].append(angle)

                    # ãƒãƒƒãƒ•ã‚¡åŠ¹ç‡çµ±è¨ˆ
                    buffer_efficiency = result["analysis"]["buffer_analysis"][
                        "detection_quality"
                    ]["buffer_efficiency"]
                    if period_name not in stats["buffer_efficiency_by_period"]:
                        stats["buffer_efficiency_by_period"][period_name] = []
                    stats["buffer_efficiency_by_period"][period_name].append(
                        buffer_efficiency
                    )
                else:
                    stats["period_detections"][period_name] = False

            # æ¤œå‡ºç‡è¨ˆç®—
            stats["detection_rate"] = stats["detection_count"] / stats["total_periods"]

            # æœŸé–“åˆ¥å¹³å‡å€¤è¨ˆç®—
            for period_name in stats["confidence_by_period"]:
                stats["confidence_by_period"][period_name] = sum(
                    stats["confidence_by_period"][period_name]
                ) / len(stats["confidence_by_period"][period_name])

            for period_name in stats["slope_by_period"]:
                stats["slope_by_period"][period_name] = sum(
                    stats["slope_by_period"][period_name]
                ) / len(stats["slope_by_period"][period_name])

            for period_name in stats["angle_by_period"]:
                stats["angle_by_period"][period_name] = sum(
                    stats["angle_by_period"][period_name]
                ) / len(stats["angle_by_period"][period_name])

            for period_name in stats["buffer_efficiency_by_period"]:
                stats["buffer_efficiency_by_period"][period_name] = sum(
                    stats["buffer_efficiency_by_period"][period_name]
                ) / len(stats["buffer_efficiency_by_period"][period_name])

            return stats

        except Exception as e:
            logger.error(f"æ™‚é–“è¶³åˆ¥çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _get_slope_description(self, slope: float) -> str:
        """å‚¾ãã®èª¬æ˜ã‚’å–å¾—"""
        abs_slope = abs(slope)
        if abs_slope < 0.0001:
            return "ã»ã¼æ°´å¹³"
        elif abs_slope < 0.001:
            return "ç·©ã‚„ã‹ãªä¸Šæ˜‡" if slope > 0 else "ç·©ã‚„ã‹ãªä¸‹é™"
        elif abs_slope < 0.01:
            return "ä¸­ç¨‹åº¦ã®ä¸Šæ˜‡" if slope > 0 else "ä¸­ç¨‹åº¦ã®ä¸‹é™"
        elif abs_slope < 0.1:
            return "æ€¥ãªä¸Šæ˜‡" if slope > 0 else "æ€¥ãªä¸‹é™"
        else:
            return "éå¸¸ã«æ€¥ãªä¸Šæ˜‡" if slope > 0 else "éå¸¸ã«æ€¥ãªä¸‹é™"

    def _get_angle_description(self, angle: float) -> str:
        """è§’åº¦ã®èª¬æ˜ã‚’å–å¾—"""
        abs_angle = abs(angle)
        if abs_angle < 5:
            return "ã»ã¼æ°´å¹³"
        elif abs_angle < 15:
            return "ç·©ã‚„ã‹ãªä¸Šæ˜‡" if angle > 0 else "ç·©ã‚„ã‹ãªä¸‹é™"
        elif abs_angle < 30:
            return "ä¸­ç¨‹åº¦ã®ä¸Šæ˜‡" if angle > 0 else "ä¸­ç¨‹åº¦ã®ä¸‹é™"
        elif abs_angle < 45:
            return "æ€¥ãªä¸Šæ˜‡" if angle > 0 else "æ€¥ãªä¸‹é™"
        else:
            return "éå¸¸ã«æ€¥ãªä¸Šæ˜‡" if angle > 0 else "éå¸¸ã«æ€¥ãªä¸‹é™"

    async def _fetch_market_data(self, days: int) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                query = text(
                    """
                    SELECT 
                        timestamp as Date,
                        open_price as Open,
                        high_price as High,
                        low_price as Low,
                        close_price as Close,
                        volume as Volume
                    FROM price_data 
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT :days
                    """
                )

                result = await session.execute(query, {"days": days})
                rows = result.fetchall()

                if not rows:
                    return pd.DataFrame()

                data = pd.DataFrame(
                    rows, columns=["Date", "Open", "High", "Low", "Close", "Volume"]
                )

                data = data.sort_values("Date").reset_index(drop=True)
                return data

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    analyzer = Pattern15V3SlopeAnalyzer()
    results = await analyzer.analyze_slope_patterns()
    
    if "error" in results:
        print(f"\nâŒ åˆ†æã‚¨ãƒ©ãƒ¼: {results['error']}")
        return
    
    print("\n=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V3 å‚¾ãåˆ†æã¨æœ€é©åŒ–çµæœ ===")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
    db_info = results.get("database_info", {})
    if "error" not in db_info:
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±:")
        print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {db_info.get('total_records', 0):,}ä»¶")
        print(f"  ãƒ‡ãƒ¼ã‚¿æœŸé–“: {db_info.get('start_date', 'N/A')} - {db_info.get('end_date', 'N/A')}")
        print(f"  ãƒ‡ãƒ¼ã‚¿æœŸé–“: {db_info.get('data_span_days', 0)}æ—¥")
    
    # å‚¾ãåˆ†æçµæœ
    slope_analysis = results.get("slope_analysis", {})
    if "error" not in slope_analysis:
        print(f"\nğŸ“ˆ å‚¾ãåˆ†æçµæœ:")
        
        # åŸºæœ¬çµ±è¨ˆ
        basic_stats = slope_analysis.get("basic_statistics", {})
        if basic_stats:
            print(f"  åŸºæœ¬çµ±è¨ˆ:")
            price_stats = basic_stats.get("price_statistics", {})
            high_stats = price_stats.get("high_prices", {})
            print(f"    é«˜å€¤ç¯„å›²: {high_stats.get('min', 0):.5f} - {high_stats.get('max', 0):.5f}")
            print(f"    ä¾¡æ ¼å¤‰å‹•ä¿‚æ•°: {high_stats.get('coefficient_of_variation', 0):.5f}")
            
            change_stats = basic_stats.get("change_statistics", {})
            print(f"    å¹³å‡å¤‰åŒ–ç‡: {change_stats.get('mean_change', 0):.6f}")
            print(f"    çµ¶å¯¾å¹³å‡å¤‰åŒ–ç‡: {change_stats.get('abs_mean_change', 0):.6f}")
            print(f"    ä¸Šæ˜‡ç‡: {change_stats.get('positive_changes_ratio', 0):.1%}")
        
        # å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³
        slope_patterns = slope_analysis.get("slope_patterns", {})
        if slope_patterns:
            print(f"  å‚¾ããƒ‘ã‚¿ãƒ¼ãƒ³:")
            
            # å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰
            overall_trend = slope_patterns.get("overall_trend", {})
            if overall_trend:
                print(f"    å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰:")
                print(f"      å‚¾ã: {overall_trend.get('slope', 0):.6f}")
                print(f"      æ–¹å‘: {overall_trend.get('trend_direction', '')}")
                print(f"      å¼·åº¦: {overall_trend.get('trend_strength', 0):.3f}")
                print(f"      æ—¥æ¬¡å¤‰åŒ–ç‡: {overall_trend.get('slope_percentage', 0):.4f}%")
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå‚¾ã
            segment_slopes = slope_patterns.get("segment_slopes", {})
            for seg_name, seg_data in segment_slopes.items():
                print(f"    {seg_name}:")
                print(f"      å‚¾ã: {seg_data.get('slope', 0):.6f}")
                print(f"      æ–¹å‘: {seg_data.get('trend_direction', '')}")
    
    # æœ€é©åŒ–çµæœ
    optimization_results = results.get("optimization_results", {})
    print(f"\nğŸ”§ æœ€é©åŒ–çµæœï¼ˆãƒãƒƒãƒ•ã‚¡ç¸®å°1æ¡ç”¨ï¼‰:")
    
    for timeframe, timeframe_data in optimization_results.items():
        print(f"\n  {timeframe}:")
        
        tf_stats = timeframe_data.get("statistics", {})
        print(f"    æ¤œå‡ºä»¶æ•°: {tf_stats.get('detection_count', 0)}")
        print(f"    æ¤œå‡ºç‡: {tf_stats.get('detection_rate', 0):.1%}")
        
        # è©³ç´°çµæœ
        for period_name, result in timeframe_data.items():
            if period_name == "statistics":
                continue
                
            if result.get("detected", False):
                analysis = result.get("analysis", {})
                slope_analysis = analysis.get("slope_analysis", {})
                buffer_analysis = analysis.get("buffer_analysis", {})
                
                print(f"      {period_name}:")
                print(f"        å‚¾ã: {analysis['mathematical']['slope']:.6f} ({analysis['mathematical']['slope_description']})")
                print(f"        è§’åº¦: {analysis['mathematical']['angle']:.2f}åº¦")
                print(f"        ãƒãƒƒãƒ•ã‚¡åŠ¹ç‡: {buffer_analysis.get('detection_quality', {}).get('buffer_efficiency', 0):.3f}")
                
                slope_reasons = slope_analysis.get("slope_reasons", {})
                print(f"        ä¾¡æ ¼å®‰å®šæ€§: {'âœ…' if slope_reasons.get('price_stability', False) else 'âŒ'}")
                print(f"        å‚¾ãã®å¤§ãã•: {'âœ…' if slope_reasons.get('slope_magnitude', False) else 'âŒ'}")


if __name__ == "__main__":
    asyncio.run(main())
