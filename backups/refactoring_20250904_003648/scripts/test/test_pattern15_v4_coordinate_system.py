"""
ãƒ‘ã‚¿ãƒ¼ãƒ³15 V4 åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºå™¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

TA-Libã‚’ä½¿ç”¨ã—ãŸåº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒãƒ¼ãƒˆ/ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ©ã‚¤ãƒ³æ¤œå‡ºãƒ†ã‚¹ãƒˆ
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict

import numpy as np
import pandas as pd
from sqlalchemy import text

from src.infrastructure.analysis.pattern_detectors.support_resistance_detector_v4 import (
    SupportResistanceDetectorV4,
)
from src.infrastructure.database.connection import db_manager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class Pattern15V4CoordinateSystemTester:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³15 V4 åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºå™¨ãƒ†ã‚¹ã‚¿ãƒ¼"""

    def __init__(self):
        self.timeframes = ["5m", "1h", "1d"]
        self.test_periods = [
            {"name": "1ãƒ¶æœˆ", "days": 30},
            {"name": "3ãƒ¶æœˆ", "days": 90},
            {"name": "6ãƒ¶æœˆ", "days": 180},
            {"name": "1å¹´", "days": 365},
        ]

    async def test_coordinate_system_detection(self) -> Dict:
        """åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V4 åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            await db_manager.initialize(
                "sqlite+aiosqlite:///./data/exchange_analytics.db"
            )
            logger.info("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")

            # å„æ™‚é–“è¶³ã§ã®ãƒ†ã‚¹ãƒˆ
            results = {}
            for timeframe in self.timeframes:
                logger.info(f"æ™‚é–“è¶³ãƒ†ã‚¹ãƒˆ: {timeframe}")
                timeframe_results = {}

                for period in self.test_periods:
                    logger.info(f"  æœŸé–“: {period['name']}")
                    result = await self._test_single_period(timeframe, period)
                    timeframe_results[period["name"]] = result

                # æ™‚é–“è¶³åˆ¥çµ±è¨ˆ
                timeframe_stats = self._analyze_timeframe_statistics(timeframe_results)
                timeframe_results["statistics"] = timeframe_stats

                results[timeframe] = timeframe_results

            # å…¨ä½“çµ±è¨ˆ
            overall_stats = self._analyze_overall_statistics(results)

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†
            await db_manager.close()

            return {
                "results": results,
                "overall_stats": overall_stats,
                "analysis_time": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            await db_manager.close()
            return {"error": str(e)}

    async def _test_single_period(self, timeframe: str, period: Dict) -> Dict:
        """å˜ä¸€æœŸé–“ã§ã®ãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            data = await self._fetch_market_data(period["days"])
            if data.empty:
                return {"error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}

            logger.info(f"    å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(data)}ä»¶")

            # åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºå™¨ä½œæˆ
            detector = SupportResistanceDetectorV4(timeframe)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            detection = detector.detect(data)

            if detection:
                # è©³ç´°åˆ†æ
                detailed_analysis = self._analyze_detection_with_details(
                    detection, data, timeframe, period
                )
                return {
                    "detected": True,
                    "detection": detection,
                    "analysis": detailed_analysis,
                    "data_points": len(data),
                    "period_days": period["days"],
                }
            else:
                return {
                    "detected": False,
                    "data_points": len(data),
                    "period_days": period["days"],
                }

        except Exception as e:
            logger.error(f"å˜ä¸€æœŸé–“ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_detection_with_details(
        self, detection: Dict, data: pd.DataFrame, timeframe: str, period: Dict
    ) -> Dict:
        """æ¤œå‡ºè©³ç´°åˆ†æ"""
        try:
            analysis = {}

            # åŸºæœ¬æƒ…å ±
            pattern_data = detection.get("pattern_data", {})
            equation = pattern_data.get("equation", {})

            analysis["basic_info"] = {
                "pattern_type": detection.get("pattern_type"),
                "confidence": detection.get("confidence_score"),
                "direction": detection.get("direction"),
                "strategy": detection.get("strategy"),
                "timeframe": timeframe,
                "period": period["name"],
            }

            # åº§æ¨™ç³»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            slope = equation.get("slope", 0)
            angle = equation.get("angle", 0)

            analysis["coordinate_system"] = {
                "slope": slope,
                "intercept": equation.get("intercept"),
                "angle": angle,
                "r_squared": equation.get("r_squared"),
                "line_length": pattern_data.get("line_length"),
                "points": pattern_data.get("points"),
                "slope_description": self._get_slope_description(slope),
                "angle_description": self._get_angle_description(angle),
            }

            # æ¤œå‡ºå“è³ªåˆ†æ
            analysis["detection_quality"] = self._analyze_detection_quality(
                data, pattern_data
            )

            return analysis

        except Exception as e:
            logger.error(f"æ¤œå‡ºè©³ç´°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_detection_quality(
        self, data: pd.DataFrame, pattern_data: Dict
    ) -> Dict:
        """æ¤œå‡ºå“è³ªåˆ†æ"""
        try:
            analysis = {}

            # ãƒ©ã‚¤ãƒ³å¼·åº¦
            strength = pattern_data.get("strength", 0)

            # æ±ºå®šä¿‚æ•°
            r_squared = pattern_data.get("equation", {}).get("r_squared", 0)

            # ç¾åœ¨ä¾¡æ ¼é–¢ä¿‚
            current_analysis = pattern_data.get("current_analysis", {})

            analysis["quality_metrics"] = {
                "line_strength": strength,
                "r_squared": r_squared,
                "current_relation": current_analysis.get("relation"),
                "breakout_strength": current_analysis.get("breakout_strength", 0),
                "price_distance": current_analysis.get("distance", 0),
            }

            # å“è³ªè©•ä¾¡
            quality_score = strength * r_squared
            analysis["quality_score"] = quality_score

            if quality_score >= 0.8:
                quality_rating = "Excellent"
            elif quality_score >= 0.6:
                quality_rating = "Good"
            elif quality_score >= 0.4:
                quality_rating = "Fair"
            else:
                quality_rating = "Poor"

            analysis["quality_rating"] = quality_rating

            return analysis

        except Exception as e:
            logger.error(f"æ¤œå‡ºå“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_timeframe_statistics(self, timeframe_results: Dict) -> Dict:
        """æ™‚é–“è¶³åˆ¥çµ±è¨ˆåˆ†æ"""
        try:
            stats = {
                "total_periods": len(
                    [k for k in timeframe_results.keys() if k != "statistics"]
                ),
                "detection_count": 0,
                "detection_rate": 0.0,
                "period_detections": {},
                "confidence_by_period": {},
                "slope_by_period": {},
                "angle_by_period": {},
                "quality_score_by_period": {},
                "line_types": {},
            }

            for period_name, result in timeframe_results.items():
                if period_name == "statistics":
                    continue

                if result.get("detected", False):
                    stats["detection_count"] += 1
                    stats["period_detections"][period_name] = True

                    # ä¿¡é ¼åº¦çµ±è¨ˆ
                    confidence = result["detection"].get("confidence_score", 0)
                    if period_name not in stats["confidence_by_period"]:
                        stats["confidence_by_period"][period_name] = []
                    stats["confidence_by_period"][period_name].append(confidence)

                    # å‚¾ãçµ±è¨ˆ
                    slope = result["analysis"]["coordinate_system"]["slope"]
                    if period_name not in stats["slope_by_period"]:
                        stats["slope_by_period"][period_name] = []
                    stats["slope_by_period"][period_name].append(slope)

                    # è§’åº¦çµ±è¨ˆ
                    angle = result["analysis"]["coordinate_system"]["angle"]
                    if period_name not in stats["angle_by_period"]:
                        stats["angle_by_period"][period_name] = []
                    stats["angle_by_period"][period_name].append(angle)

                    # å“è³ªã‚¹ã‚³ã‚¢çµ±è¨ˆ
                    quality_score = result["analysis"]["detection_quality"][
                        "quality_score"
                    ]
                    if period_name not in stats["quality_score_by_period"]:
                        stats["quality_score_by_period"][period_name] = []
                    stats["quality_score_by_period"][period_name].append(quality_score)

                    # ãƒ©ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—çµ±è¨ˆ
                    line_type = result["detection"]["pattern_type"]
                    stats["line_types"][line_type] = (
                        stats["line_types"].get(line_type, 0) + 1
                    )
                else:
                    stats["period_detections"][period_name] = False

            # æ¤œå‡ºç‡è¨ˆç®—
            stats["detection_rate"] = stats["detection_count"] / stats["total_periods"]

            # æœŸé–“åˆ¥å¹³å‡å€¤è¨ˆç®—
            for period_name in stats["confidence_by_period"]:
                stats["confidence_by_period"][period_name] = sum(
                    stats["confidence_by_period"][period_name]
                ) / len(stats["confidence_by_period"][period_name])

            for period_name in stats["slope_by_period"]:
                stats["slope_by_period"][period_name] = sum(
                    stats["slope_by_period"][period_name]
                ) / len(stats["slope_by_period"][period_name])

            for period_name in stats["angle_by_period"]:
                stats["angle_by_period"][period_name] = sum(
                    stats["angle_by_period"][period_name]
                ) / len(stats["angle_by_period"][period_name])

            for period_name in stats["quality_score_by_period"]:
                stats["quality_score_by_period"][period_name] = sum(
                    stats["quality_score_by_period"][period_name]
                ) / len(stats["quality_score_by_period"][period_name])

            return stats

        except Exception as e:
            logger.error(f"æ™‚é–“è¶³åˆ¥çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _analyze_overall_statistics(self, results: Dict) -> Dict:
        """å…¨ä½“çµ±è¨ˆåˆ†æ"""
        try:
            stats = {
                "total_timeframes": len(results),
                "total_detections": 0,
                "overall_detection_rate": 0.0,
                "timeframe_detection_summary": {},
                "best_performing_timeframe": None,
                "highest_confidence": 0.0,
                "average_slope": 0.0,
                "average_quality_score": 0.0,
                "line_type_distribution": {},
                "monthly_estimate": 0.0,
            }

            total_periods = 0
            timeframe_performance = {}
            all_slopes = []
            all_quality_scores = []
            all_line_types = {}

            for timeframe, timeframe_results in results.items():
                timeframe_stats = timeframe_results.get("statistics", {})
                detection_count = timeframe_stats.get("detection_count", 0)
                total_periods_tf = timeframe_stats.get("total_periods", 0)

                stats["total_detections"] += detection_count
                total_periods += total_periods_tf

                detection_rate = timeframe_stats.get("detection_rate", 0.0)
                timeframe_performance[timeframe] = detection_rate

                stats["timeframe_detection_summary"][timeframe] = {
                    "detection_count": detection_count,
                    "total_periods": total_periods_tf,
                    "detection_rate": detection_rate,
                }

                # å‚¾ãã¨å“è³ªã‚¹ã‚³ã‚¢ã®åé›†
                slope_by_period = timeframe_stats.get("slope_by_period", {})
                quality_score_by_period = timeframe_stats.get(
                    "quality_score_by_period", {}
                )
                line_types = timeframe_stats.get("line_types", {})

                for period_name, slopes in slope_by_period.items():
                    all_slopes.extend(slopes)

                for period_name, scores in quality_score_by_period.items():
                    all_quality_scores.extend(scores)

                for line_type, count in line_types.items():
                    all_line_types[line_type] = all_line_types.get(line_type, 0) + count

                # æœ€é«˜ä¿¡é ¼åº¦ã®è¿½è·¡
                confidence_by_period = timeframe_stats.get("confidence_by_period", {})
                for period_name, confidences in confidence_by_period.items():
                    if confidences and max(confidences) > stats["highest_confidence"]:
                        stats["highest_confidence"] = max(confidences)

            # å…¨ä½“æ¤œå‡ºç‡
            if total_periods > 0:
                stats["overall_detection_rate"] = (
                    stats["total_detections"] / total_periods
                )

            # æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ™‚é–“è¶³
            if timeframe_performance:
                stats["best_performing_timeframe"] = max(
                    timeframe_performance, key=timeframe_performance.get
                )

            # å¹³å‡å‚¾ãã¨å“è³ªã‚¹ã‚³ã‚¢
            if all_slopes:
                stats["average_slope"] = sum(all_slopes) / len(all_slopes)
            if all_quality_scores:
                stats["average_quality_score"] = sum(all_quality_scores) / len(
                    all_quality_scores
                )

            # ãƒ©ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
            stats["line_type_distribution"] = all_line_types

            # æœˆé–“æ¨å®š
            stats["monthly_estimate"] = stats["total_detections"] / 12

            return stats

        except Exception as e:
            logger.error(f"å…¨ä½“çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def _get_slope_description(self, slope: float) -> str:
        """å‚¾ãã®èª¬æ˜ã‚’å–å¾—"""
        abs_slope = abs(slope)
        if abs_slope < 0.0001:
            return "ã»ã¼æ°´å¹³"
        elif abs_slope < 0.001:
            return "ç·©ã‚„ã‹ãªä¸Šæ˜‡" if slope > 0 else "ç·©ã‚„ã‹ãªä¸‹é™"
        elif abs_slope < 0.01:
            return "ä¸­ç¨‹åº¦ã®ä¸Šæ˜‡" if slope > 0 else "ä¸­ç¨‹åº¦ã®ä¸‹é™"
        elif abs_slope < 0.1:
            return "æ€¥ãªä¸Šæ˜‡" if slope > 0 else "æ€¥ãªä¸‹é™"
        else:
            return "éå¸¸ã«æ€¥ãªä¸Šæ˜‡" if slope > 0 else "éå¸¸ã«æ€¥ãªä¸‹é™"

    def _get_angle_description(self, angle: float) -> str:
        """è§’åº¦ã®èª¬æ˜ã‚’å–å¾—"""
        abs_angle = abs(angle)
        if abs_angle < 5:
            return "ã»ã¼æ°´å¹³"
        elif abs_angle < 15:
            return "ç·©ã‚„ã‹ãªä¸Šæ˜‡" if angle > 0 else "ç·©ã‚„ã‹ãªä¸‹é™"
        elif abs_angle < 30:
            return "ä¸­ç¨‹åº¦ã®ä¸Šæ˜‡" if angle > 0 else "ä¸­ç¨‹åº¦ã®ä¸‹é™"
        elif abs_angle < 45:
            return "æ€¥ãªä¸Šæ˜‡" if angle > 0 else "æ€¥ãªä¸‹é™"
        else:
            return "éå¸¸ã«æ€¥ãªä¸Šæ˜‡" if angle > 0 else "éå¸¸ã«æ€¥ãªä¸‹é™"

    async def _fetch_market_data(self, days: int) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            async with db_manager.get_session() as session:
                query = text(
                    """
                    SELECT
                        timestamp as Date,
                        open_price as Open,
                        high_price as High,
                        low_price as Low,
                        close_price as Close,
                        volume as Volume
                    FROM price_data
                    WHERE currency_pair = 'USD/JPY'
                    ORDER BY timestamp DESC
                    LIMIT :days
                    """
                )

                result = await session.execute(query, {"days": days})
                rows = result.fetchall()

                if not rows:
                    return pd.DataFrame()

                data = pd.DataFrame(
                    rows, columns=["Date", "Open", "High", "Low", "Close", "Volume"]
                )

                data = data.sort_values("Date").reset_index(drop=True)
                return data

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    tester = Pattern15V4CoordinateSystemTester()
    results = await tester.test_coordinate_system_detection()

    if "error" in results:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {results['error']}")
        return

    print("\n=== ãƒ‘ã‚¿ãƒ¼ãƒ³15 V4 åº§æ¨™ç³»ãƒ™ãƒ¼ã‚¹æ¤œå‡ºãƒ†ã‚¹ãƒˆçµæœ ===")

    # å…¨ä½“çµ±è¨ˆ
    overall_stats = results.get("overall_stats", {})
    print(f"\nğŸ“Š å…¨ä½“çµ±è¨ˆ:")
    print(f"  ç·æ¤œå‡ºä»¶æ•°: {overall_stats.get('total_detections', 0)}")
    print(f"  å…¨ä½“æ¤œå‡ºç‡: {overall_stats.get('overall_detection_rate', 0):.1%}")
    print(f"  æœˆé–“æ¨å®š: {overall_stats.get('monthly_estimate', 0):.1f}ä»¶/æœˆ")
    print(f"  æœ€é«˜ä¿¡é ¼åº¦: {overall_stats.get('highest_confidence', 0):.3f}")
    print(f"  å¹³å‡å‚¾ã: {overall_stats.get('average_slope', 0):.6f}")
    print(f"  å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {overall_stats.get('average_quality_score', 0):.3f}")

    # ãƒ©ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ
    line_types = overall_stats.get("line_type_distribution", {})
    if line_types:
        print(f"  ãƒ©ã‚¤ãƒ³ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ:")
        for line_type, count in line_types.items():
            print(f"    {line_type}: {count}ä»¶")

    # æ™‚é–“è¶³åˆ¥çµæœ
    results_data = results.get("results", {})
    print(f"\nğŸ”§ æ™‚é–“è¶³åˆ¥çµæœ:")

    for timeframe, timeframe_data in results_data.items():
        tf_stats = timeframe_data.get("statistics", {})
        print(f"\n  {timeframe}:")
        print(f"    æ¤œå‡ºä»¶æ•°: {tf_stats.get('detection_count', 0)}")
        print(f"    æ¤œå‡ºç‡: {tf_stats.get('detection_rate', 0):.1%}")

        # è©³ç´°çµæœ
        for period_name, result in timeframe_data.items():
            if period_name == "statistics":
                continue

            if result.get("detected", False):
                analysis = result.get("analysis", {})
                coordinate_system = analysis.get("coordinate_system", {})
                detection_quality = analysis.get("detection_quality", {})

                print(f"      {period_name}:")
                print(f"        ãƒ‘ã‚¿ãƒ¼ãƒ³: {result['detection']['pattern_type']}")
                print(
                    f"        å‚¾ã: {coordinate_system['slope']:.6f} ({coordinate_system['slope_description']})"
                )
                print(f"        è§’åº¦: {coordinate_system['angle']:.2f}åº¦")
                print(f"        æ±ºå®šä¿‚æ•°: {coordinate_system['r_squared']:.3f}")
                print(
                    f"        å“è³ªã‚¹ã‚³ã‚¢: {detection_quality['quality_score']:.3f} ({detection_quality['quality_rating']})"
                )
                print(f"        ä¿¡é ¼åº¦: {result['detection']['confidence_score']:.3f}")
                print(f"        æˆ¦ç•¥: {result['detection']['strategy']}")


if __name__ == "__main__":
    asyncio.run(main())
