#!/usr/bin/env python3
"""
Four Hour Aggregator - 4æ™‚é–“è¶³é›†è¨ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è²¬ä»»:
- 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰4æ™‚é–“è¶³ã‚’é›†è¨ˆ
- PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°å‡ºåŠ›
"""

import asyncio
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Tuple

import pytz

# ç’°å¢ƒå¤‰æ•°ã‚’è‡ªå‹•è¨­å®š
os.environ["DATABASE_URL"] = (
    "postgresql+asyncpg://exchange_analytics_user:"
    "exchange_password@localhost:5432/exchange_analytics_production_db"
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from advanced_data.base_aggregator import (
    BaseAggregator, AggregationError, InsufficientDataError
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("/app/logs/four_hour_aggregator.log"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class FourHourAggregator(BaseAggregator):
    """
    4æ™‚é–“è¶³é›†è¨ˆã‚¯ãƒ©ã‚¹

    è²¬ä»»:
    - 4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ
    - å‰4æ™‚é–“ã®5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰OHLCVè¨ˆç®—
    - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¿å­˜
    """

    def __init__(self):
        super().__init__("4h", "yahoo_finance_4h_aggregated")

    async def get_aggregation_period(self) -> Tuple[datetime, datetime]:
        """
        é›†è¨ˆæœŸé–“ã‚’å–å¾—

        Returns:
            tuple: (start_time, end_time) å‰4æ™‚é–“ã®æœŸé–“
        """
        # 4æ™‚é–“å˜ä½ã§ã®æœŸé–“è¨ˆç®—
        now = datetime.now(pytz.timezone("Asia/Tokyo"))

        # 4æ™‚é–“å˜ä½ã§ã®é–‹å§‹æ™‚åˆ»ã‚’è¨ˆç®—
        hour = (now.hour // 4) * 4
        start_time = now.replace(hour=hour, minute=0, second=0, microsecond=0) - timedelta(hours=4)

        # 4æ™‚é–“å¾Œã®çµ‚äº†æ™‚åˆ»ï¼ˆ55åˆ†ã¾ã§ï¼‰
        end_time = start_time + timedelta(hours=4) - timedelta(minutes=5)

        logger.info(f"ğŸ“… 4æ™‚é–“è¶³é›†è¨ˆæœŸé–“: {start_time} - {end_time}")
        return start_time, end_time

    async def aggregate_and_save(self):
        """
        4æ™‚é–“è¶³é›†è¨ˆã¨ä¿å­˜ã‚’å®Ÿè¡Œ

        Workflow:
        1. é›†è¨ˆæœŸé–“ã®æ±ºå®š
        2. 5åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        3. OHLCVè¨ˆç®—
        4. é‡è¤‡ãƒã‚§ãƒƒã‚¯
        5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        """
        try:
            # Step 1: é›†è¨ˆæœŸé–“æ±ºå®š
            start_time, end_time = await self.get_aggregation_period()

            # Step 2: ãƒ‡ãƒ¼ã‚¿å–å¾—
            five_min_data = await self.get_five_min_data(start_time, end_time)
            if not five_min_data:
                logger.warning("âš ï¸ é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return

            # Step 3: é›†è¨ˆè¨ˆç®—
            aggregated_data = await self.calculate_ohlcv(five_min_data)

            # Step 4: é‡è¤‡ãƒã‚§ãƒƒã‚¯
            existing = await self.check_duplicate(aggregated_data.timestamp)
            if existing:
                logger.info("â„¹ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return

            # Step 5: ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            await self.save_aggregated_data(aggregated_data)
            logger.info(f"âœ… 4æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {aggregated_data.timestamp}")

        except InsufficientDataError:
            logger.warning("âš ï¸ é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            # æ­£å¸¸çµ‚äº†ï¼ˆã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ï¼‰
        except AggregationError as e:
            logger.error(f"âŒ é›†è¨ˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            raise


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    aggregator = None
    try:
        # åˆæœŸåŒ–
        aggregator = FourHourAggregator()
        await aggregator.initialize_database()

        # é›†è¨ˆå®Ÿè¡Œ
        await aggregator.aggregate_and_save()
        logger.info("âœ… 4æ™‚é–“è¶³é›†è¨ˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    except Exception as e:
        logger.error(f"âŒ 4æ™‚é–“è¶³é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if aggregator:
            await aggregator.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
