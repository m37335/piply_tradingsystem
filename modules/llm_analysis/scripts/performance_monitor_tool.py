#!/usr/bin/env python3
"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ„ãƒ¼ãƒ«

ä¸‰å±¤ã‚²ãƒ¼ãƒˆå¼ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç›£è¦–ã—ã€
æœ€é©åŒ–ã®ãŸã‚ã®è©³ç´°ãªåˆ†æã‚’æä¾›ã—ã¾ã™ã€‚
"""

import asyncio
import json
import logging
import sys
from datetime import datetime, timezone
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from modules.llm_analysis.core.performance_monitor import performance_monitor

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


class PerformanceMonitorTool:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ„ãƒ¼ãƒ«"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def display_performance_summary(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        try:
            summary = performance_monitor.get_performance_summary()
            
            print("=" * 80)
            print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚µãƒãƒªãƒ¼")
            print("=" * 80)
            print(f"â° æ›´æ–°æ™‚åˆ»: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ
            print("ğŸ“ˆ ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ:")
            for metric_name, stats in summary['stats'].items():
                print(f"   ğŸ”§ {stats['display_name']}:")
                print(f"      ğŸ“Š å®Ÿè¡Œå›æ•°: {stats['count']}")
                print(f"      âš¡ å¹³å‡æ™‚é–“: {stats['avg']:.4f}ç§’")
                print(f"      ğŸ“ˆ P95æ™‚é–“: {stats['p95']:.4f}ç§’")
                print(f"      ğŸ†• æœ€æ–°æ™‚é–“: {stats['last']:.4f}ç§’")
                print()
            
            # æ¨å¥¨äº‹é …
            if summary['recommendations']:
                print("ğŸ’¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„æ¨å¥¨äº‹é …:")
                for i, recommendation in enumerate(summary['recommendations'], 1):
                    print(f"   {i}. {recommendation}")
                print()
            else:
                print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")
                print()
            
            print("=" * 80)
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_detailed_stats(self):
        """è©³ç´°çµ±è¨ˆã‚’è¡¨ç¤º"""
        try:
            all_stats = performance_monitor.get_all_stats()
            
            print("=" * 80)
            print("ğŸ“Š è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
            print("=" * 80)
            print(f"â° æ›´æ–°æ™‚åˆ»: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print()
            
            for metric_name, stats in all_stats.items():
                print(f"ğŸ”§ {metric_name}:")
                print(f"   ğŸ“Š å®Ÿè¡Œå›æ•°: {stats.count}")
                print(f"   ğŸ“ˆ æœ€å°æ™‚é–“: {stats.min_value:.4f}ç§’")
                print(f"   ğŸ“ˆ æœ€å¤§æ™‚é–“: {stats.max_value:.4f}ç§’")
                print(f"   âš¡ å¹³å‡æ™‚é–“: {stats.avg_value:.4f}ç§’")
                print(f"   ğŸ“Š ä¸­å¤®å€¤: {stats.median_value:.4f}ç§’")
                print(f"   ğŸ“ˆ P95æ™‚é–“: {stats.p95_value:.4f}ç§’")
                print(f"   ğŸ“ˆ P99æ™‚é–“: {stats.p99_value:.4f}ç§’")
                print(f"   ğŸ†• æœ€æ–°æ™‚é–“: {stats.last_value:.4f}ç§’")
                print(f"   â° æœ€çµ‚æ›´æ–°: {stats.last_updated.strftime('%Y-%m-%d %H:%M:%S')} UTC")
                print()
            
            print("=" * 80)
            
        except Exception as e:
            self.logger.error(f"âŒ è©³ç´°çµ±è¨ˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_performance_data(self, output_file: str = None):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            if output_file is None:
                timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')
                output_file = f"/app/performance_data_{timestamp}.json"
            
            export_data = performance_monitor.export_stats()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {output_file}")
            return output_file
            
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def clear_performance_data(self, metric_name: str = None):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
        try:
            performance_monitor.clear_history(metric_name)
            
            if metric_name:
                self.logger.info(f"âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹ '{metric_name}' ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            else:
                self.logger.info("âœ… ã™ã¹ã¦ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                
        except Exception as e:
            self.logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def display_help(self):
        """ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º"""
        print("=" * 80)
        print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ„ãƒ¼ãƒ«")
        print("=" * 80)
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python performance_monitor_tool.py [ã‚³ãƒãƒ³ãƒ‰] [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]")
        print()
        print("ã‚³ãƒãƒ³ãƒ‰:")
        print("  summary          - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º")
        print("  detailed         - è©³ç´°çµ±è¨ˆã‚’è¡¨ç¤º")
        print("  export [ãƒ•ã‚¡ã‚¤ãƒ«] - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        print("  clear [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢")
        print("  help             - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º")
        print()
        print("ä¾‹:")
        print("  python performance_monitor_tool.py summary")
        print("  python performance_monitor_tool.py detailed")
        print("  python performance_monitor_tool.py export /tmp/performance.json")
        print("  python performance_monitor_tool.py clear gate1_evaluation_time")
        print()
        print("=" * 80)


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('command', nargs='?', default='summary', 
                       choices=['summary', 'detailed', 'export', 'clear', 'help'],
                       help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰')
    parser.add_argument('argument', nargs='?', help='ã‚³ãƒãƒ³ãƒ‰ã®å¼•æ•°')
    
    args = parser.parse_args()
    
    tool = PerformanceMonitorTool()
    
    try:
        if args.command == 'summary':
            tool.display_performance_summary()
        elif args.command == 'detailed':
            tool.display_detailed_stats()
        elif args.command == 'export':
            output_file = tool.export_performance_data(args.argument)
            if output_file:
                print(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {output_file}")
        elif args.command == 'clear':
            tool.clear_performance_data(args.argument)
        elif args.command == 'help':
            tool.display_help()
        else:
            tool.display_help()
            
    except Exception as e:
        logger.error(f"âŒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    # ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
    asyncio.run(main())
